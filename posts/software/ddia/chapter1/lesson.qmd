---
title: "Designing Data Intensive Applications: Part 1"
description: "Data Systems"
date: "2025-01-17"
# image: "deep_learning_model.png"
categories: [DataEngineering, Engineering, Software]
---

# Reliable, Scalable, and Maintainable Applications

# 1. Data Systems

Modern applications are often **data**-intensive rather than **compute**-intensive. That is to say, the bottleneck is not the CPU speed, but some aspect of data, whether that be storage, throughput or some other factor.

These applications are often built by assembling building blocks of well-established **data systems**. For example, database, caches, search indexes, stream processing, batch processing. 
The application is essentially a new, special purpose data system built from generic components.

These are often so well abstracted that we do not think too deeply about the internals of their operation. But this is key to how our overall application will perform.

This chapter serves as a gentle introduction to establish some of the key terminology in this field. Later chapters dive deeper into individual data systems that form the layers of an application.


There are three main focuses when designing software systems:

- **Reliability** - the system should continue to work correctly in the face of adversity
- **Scalability** - the system can deal with growth
- **Maintainability** - the system can be operated and extended


# 2. Reliability

The application "working correctly" broadly means that it meets its functional and non-functional requirements.

> Reliability roughly means "the application should work correctly, and continue to work correctly when things go wrong"

The "things that go wrong" are **faults**; a system that can cope with faults is **fault-tolerant** or **resilient**. 
In practice, we can't account for every possible fault (what happens if an asteroid hits the Earth) so we specify what types of faults we are tolerant of.

A fault is different from a **failure**. A *fault* is where one component of the system deviates from the spec. A *failure* is when the system as a whole stops provided the required service to the user. There are diminishing returns which means it is generally not possible to reduce the proability of fault to zero, so instead we focus our attention on **ensuring faults do not cause failures**.

To ensure the fault tolerance of a system is well-exercised, we may (counterintuitively) want to induce faults intentionally to periodically assess the impact on the overall system.
This is the idea behind Netflix's [Chaos Monkey](https://netflixtechblog.com/the-netflix-simian-army-16e57fbab116) approach, where production services are disabled at random to ensure the system as a whole remains functional in such an event.

Categories of faults:

- Hardware faults
- Software faults
- Human errors

*human errors* can be minimised with well-designed abstractions that "make it easy to do the right think and make it hard to do the wrong thing".
This can be a tricky balance to get right, as interfaces that are too restrictive will force people to work around them.
*sandbox envrionments* and making *rollbacks* of config changes fast can also help mitigate risk.  


# 3. Scalability


# 4. Maintainability


# References

- Chapter 1 of Designing Data Intensive Applications by Martin Kleppmann