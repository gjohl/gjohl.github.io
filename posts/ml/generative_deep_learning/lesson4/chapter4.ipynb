{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Generative AI Part 4: GANs\"\n",
    "description: \"Generative Adversarial Networks\"\n",
    "date: \"2024-04-01\"\n",
    "# image: \"deep_learning_model.png\"\n",
    "categories: [AI, Engineering, GenerativeAI, GAN]\n",
    "format:\n",
    "  html:\n",
    "    code-fold: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GANs\n",
    "\n",
    "Notes on Generative Adversarial Networks (GANs).\n",
    "\n",
    "::: {.callout-tip title=\"Story Time\"}\n",
    "Imagine a forger trying to forge Â£20 notes and the popo trying to stop them.\n",
    "\n",
    "The popo learn to spot the fakes.\n",
    "But then the forger learns to improve their forging skills to make better fakes.\n",
    "\n",
    "This goes back and forth. With each iteration, the forger keeps getting better but then the popo learn to spot these more sophisticated fakes.\n",
    "\n",
    "The results in a forger (generator) learning to create convincing fakes and the popo (discriminator) learning to spot fakes.\n",
    ":::\n",
    "\n",
    "\n",
    "## 1. GANs\n",
    "The idea of GANs is that we can train two competing models:\n",
    "\n",
    "- The **generator** tries to convert random noise into convincing observations.\n",
    "- The **discriminator** tries to predict whether an observation came from the original training dataset or is a \"fake\".\n",
    "\n",
    "We initialise both as random models; the generator outputs noise and the discriminator predicts randomly.\n",
    "We then alternate the training of the two networks so that the generator gets incrementally better at fooling the discriminator, then the discriminator gets incrementally better at spotting fakes.\n",
    "\n",
    "\n",
    "```{mermaid}\n",
    "flowchart LR\n",
    "\n",
    "  A([Random noise]) --> B[Generator] --> C([Generated image]) \n",
    "\n",
    "  D([Image]) --> E[Discriminator] --> F([Prediction of realness probability])\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "## 2. Building a Deep Convolutional GAN\n",
    "We will implement a GAN to generate [pictures of bricks](https://www.kaggle.com/datasets/joosthazelzet/lego-brick-images).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Chapter 4 of Generative Deep Learning by David Foster.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
