{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Generative AI: Chapter 3\"\n",
    "description: \"Variational Autoencoders\"\n",
    "date: \"2024-02-28\"\n",
    "# image: \"deep_learning_model.png\"\n",
    "categories: [AI, Engineering, GenerativeAI]\n",
    "format:\n",
    "  html:\n",
    "    code-fold: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoders\n",
    "These are notes from chapter 3 of Generative Deep Learning by David Foster.\n",
    "\n",
    "::: {.callout-tip title=\"Story Time\"}\n",
    "Imagine an infinite wardrobe organised by \"type\" of clothing. \n",
    "\n",
    "Shoes would be close together, but formal shoes might be closer to the suits and trainers closer to the sports gear. Shirts and t-shirts would be close together. Coats might be nearby; the shirt->coat vector applied to t-shirts might lead you to \"invent\" gilets.\n",
    "\n",
    "This encapsulates the idea of using a lower dimensional (2D in this case) latent space to **encode** the representation of more complex objects.\n",
    "\n",
    "We could *sample* from some of the empty spaces to invent new hybrids of clothing. This generative step is **decoding** the latent space.\n",
    ":::\n",
    "\n",
    "\n",
    "## 1. Autoencoders\n",
    "The idea of autoencoders (read: self-encoders) is that they learn to simplify the input then reconstruct it; the input and target output are the same.\n",
    "\n",
    "- The **encoder** learns a lower dimensional representation of the image called the *embedding*.\n",
    "- The **decoder** takes an embedding and recreates a higher-dimensional image. This should be an accurate reconstruction of the input.\n",
    "\n",
    "This can be used as a generative model because we can the sample and decode *new* points from the latent space to generate novel outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-practice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
