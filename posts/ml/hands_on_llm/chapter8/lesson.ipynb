{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Hands-On LLMs: Semantic Search and Retrieval-Augmented Generation\"\n",
    "description: \"Part 8: RAG Time\"\n",
    "date: \"2025-03-06\"\n",
    "# image: \"deep_learning_model.png\"\n",
    "categories: [AI, Engineering, GenerativeAI, LLM]\n",
    "draft: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Search and Retrieval-Augmented Generation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# 1. Applications of Semantic Search \n",
    "\n",
    "**Semantic search** is when we want to retrieve results that have a similar **meaning** to our query.\n",
    "\n",
    "Contrast this with *keyword search*, where we retrieve results that have the same **words** as our query.\n",
    "\n",
    "As an example, say our query is \"dog\".\n",
    "A keyword search might retrieve results related to dogs, hot dogs, and dogging.\n",
    "Whereas a semantic search would results related to dogs, chihuahuas, dachshunds and puppies.\n",
    "\n",
    "Semantic search is helpful in the contexts of:\n",
    "\n",
    "- **Dense retrieval** - where we want to retrieve a small number of relevant documents from a large corpus based on the nearest neighbours in embedding space.\n",
    "- **Re-ranking** - where we already have a list of results from another step in the pipelines (e.g. keyword search) and want to re-order the results based on relevance.\n",
    "-  **Retrieval-Augmented Generation (RAG)**, where a user's prompt to an LLM is used to determine\n",
    "related documents, and those documents are fed to the LLM to generate an improved response.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# 2. Dense Retrieval\n",
    "\n",
    "When we create an embedding for a document, we are essentially creating a vector that in some way encodes its meaning.\n",
    "Each dimension corresponds to some aspect of the document. We can think of N-dimensional embedding vectors as points in N-dimensional space.\n",
    "\n",
    "Points which are close together are similar in some way, and points which are far apart are different.\n",
    "\n",
    "This is the premise behind semantic search systems. We **embed the query**, then find the **documents which are the nearest neighbors** to the query in the embedding space.\n",
    "These are our search results as they should be similar in meaning.\n",
    "\n",
    "![Query embedding](query_embedding.png)\n",
    "\n",
    "Some points worth noting on this nearest neighbours approach:\n",
    "\n",
    "- We may want to apply a minimum threshold to the similarity score to account for cases when there are no relevant documents in the corpus.\n",
    "- Queries and their answers aren't always semantically similar. This is why language models need ot be trained on question-answer pairs.\n",
    "\n",
    "The steps to create a dense retrieval system are:\n",
    "\n",
    "1. Collect and pre-process the text data.\n",
    "2. **Chunk** it into *documents*\n",
    "3. Create **embeddings** for each document\n",
    "4. Build a search index\n",
    "5. Search for results (nearest neighbours)\n",
    "\n",
    "\n",
    "# TODO: from page 323"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# References\n",
    "\n",
    "- Chapter 8 of Hands-On Large Language Models by Jay Alammar & Marten Grootendoorst\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thellmbook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
