{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Hands-On LLMs: Attention Mechanism\"\n",
    "description: \"Pay attention\"\n",
    "date: \"2024-11-28\"\n",
    "# image: \"deep_learning_model.png\"\n",
    "categories: [AI, Engineering, GenerativeAI, LLM]\n",
    "draft: True\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention\n",
    "\n",
    "\n",
    "# 1. Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "- Chapter 3 of Hands-On Large Language Models by Jay Alammar & Marten Grootendoorst\n",
    "- [https://jalammar.github.io/illustrated-transformer/](https://jalammar.github.io/illustrated-transformer/)\n",
    "- [Dive into Deep Learning Chapter 11](https://d2l.ai/chapter_attention-mechanisms-and-transformers/index.html)\n",
    "- [Andrej Karpathy \"Let's build GPT\" tutorial](https://www.youtube.com/watch?v=kCc8FmEb1nY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
