{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6d3089f5",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Machine Learning Fundamentals\"\n",
    "description: \"Machine Learning Fundamentals\"\n",
    "date: \"2024-05-30\"\n",
    "categories: [Engineering, AI, InterviewPrep]\n",
    "# draft: true\n",
    "# format:\n",
    "#   html:\n",
    "#     code-fold: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0e9ed2",
   "metadata": {},
   "source": [
    "# ML\n",
    "\n",
    "## 1. Taxonomy\n",
    "\n",
    "Supervised vs unsupervised\n",
    "\n",
    "\n",
    "## 2. The Training Loop\n",
    "Model produces a prediction\n",
    "Loss function f(prediction, label)\n",
    "Backprop gradients of loss\n",
    "Optimiser adjusts weights based on gradients.\n",
    "\n",
    "\n",
    "## 3. Loss Functions\n",
    "Draw a flowchart:\n",
    "\n",
    "Classification: (Binary) cross entropy\n",
    "REgression: MSE, MAE\n",
    "\n",
    "Write mathemetical definitions of each an intuitive explanation.\n",
    "\n",
    "## 4. Optimisers\n",
    "\n",
    "Convex optimisation boils down to having some function that we want to find the minimum of.\n",
    "\n",
    "This is often described intuitively rolling a ball down a hill to try to find the lowest valley. \n",
    "\n",
    "But this can be confusing - I can look over there and see it's lower, why don't I just walk straight there?\n",
    "\n",
    "The analogy is missing a few caveats:\n",
    "1. **You're blindfolded**: The \"function\" learned by our model isn't one that has a neat closed form solution that we can plot to see at every point. It's got so many dimensions the best we can do is sample one point at a time.\n",
    "2. **You're teleporting**. Each \"step\" that you take isn't a smooth continuous roll; you don't learn anything about the points in between your start point and end point when you take a step, you only know where you started and where you finished. If you happened to \"step over\" a minimum, you'd have no way of knowing.\n",
    "\n",
    "\n",
    "1. SGD\n",
    "2. RMSProp\n",
    "3. AdaProp\n",
    "4. Adam\n",
    "\n",
    "\n",
    "## 5. Regularisation\n",
    "\n",
    "### 5.1. Overfitting vs underfitting\n",
    "- bias/variance trade off\n",
    "\n",
    "### 5.2. Weight regularisation penalty terms\n",
    "Norms:\n",
    ">= 1 encourages convexity\n",
    "<= 1 encourages sparsity of weights\n",
    "Link youtube video\n",
    "\n",
    "### 5.3. Other forms of regularisation\n",
    "\n",
    "Dropout in NN\n",
    "\n",
    "Randomised actions in RL\n",
    "\n",
    "\n",
    "## 6. Boosting, Bagging\n",
    "\n",
    "\n",
    "## 7. Common Supervised Algorithms\n",
    "Understand and know when to apply.\n",
    "\n",
    "Ridge/Lasso regression\n",
    "Logistic regression\n",
    "Decision trees\n",
    "SVM - duality\n",
    "\n",
    "\n",
    "## 8. Common Unsupervised Algorithms\n",
    "PCA\n",
    "K-means\n",
    "t-SNE\n",
    "Understand and know when to apply.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c573f6ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
