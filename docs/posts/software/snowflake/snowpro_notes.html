<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Gurpreet Johl">
<meta name="dcterms.date" content="2025-02-02">
<meta name="description" content="Snowflake? Snow Problem.">

<title>Gurpreet Johl - Snowflake: SnowPro Core</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="../../../site_libs/quarto-diagram/mermaid.min.js"></script>
<script src="../../../site_libs/quarto-diagram/mermaid-init.js"></script>
<link href="../../../site_libs/quarto-diagram/mermaid.css" rel="stylesheet">


<link rel="stylesheet" href="../../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Gurpreet Johl</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../projects.html"> 
<span class="menu-text">Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../blog.html"> 
<span class="menu-text">Notes</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/gjohl"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/gurpreetjohl"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/gurpreetjohl"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Snowflake: SnowPro Core</h1>
                  <div>
        <div class="description">
          Snowflake? Snow Problem.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">Software</div>
                <div class="quarto-category">DataEngineering</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Gurpreet Johl </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">February 2, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">1. Overview</a></li>
  <li><a href="#snowflake-architecture" id="toc-snowflake-architecture" class="nav-link" data-scroll-target="#snowflake-architecture">2. Snowflake Architecture</a>
  <ul class="collapse">
  <li><a href="#multi-cluster-shared-disk" id="toc-multi-cluster-shared-disk" class="nav-link" data-scroll-target="#multi-cluster-shared-disk">2.1. Multi-cluster Shared Disk</a></li>
  <li><a href="#layers-of-snowflake" id="toc-layers-of-snowflake" class="nav-link" data-scroll-target="#layers-of-snowflake">2.2. Layers of Snowflake</a></li>
  <li><a href="#loading-data-into-snowflake" id="toc-loading-data-into-snowflake" class="nav-link" data-scroll-target="#loading-data-into-snowflake">2.3. Loading Data into Snowflake</a></li>
  <li><a href="#snowflake-editions" id="toc-snowflake-editions" class="nav-link" data-scroll-target="#snowflake-editions">2.4. Snowflake Editions</a></li>
  <li><a href="#compute-costs" id="toc-compute-costs" class="nav-link" data-scroll-target="#compute-costs">2.5. Compute Costs</a>
  <ul class="collapse">
  <li><a href="#overview-of-cost-categories" id="toc-overview-of-cost-categories" class="nav-link" data-scroll-target="#overview-of-cost-categories">2.5.1. Overview of Cost Categories</a></li>
  <li><a href="#calculating-number-of-credits-consumed-" id="toc-calculating-number-of-credits-consumed-" class="nav-link" data-scroll-target="#calculating-number-of-credits-consumed-">2.5.2. Calculating Number of Credits Consumed-</a></li>
  </ul></li>
  <li><a href="#storage-and-data-costs" id="toc-storage-and-data-costs" class="nav-link" data-scroll-target="#storage-and-data-costs">2.6 Storage and Data Costs</a>
  <ul class="collapse">
  <li><a href="#storage-types-and-costs" id="toc-storage-types-and-costs" class="nav-link" data-scroll-target="#storage-types-and-costs">2.6.1. Storage Types and Costs</a></li>
  <li><a href="#transfer-costs" id="toc-transfer-costs" class="nav-link" data-scroll-target="#transfer-costs">2.6.2. Transfer Costs</a></li>
  </ul></li>
  <li><a href="#storage-monitoring" id="toc-storage-monitoring" class="nav-link" data-scroll-target="#storage-monitoring">2.7. Storage Monitoring</a></li>
  <li><a href="#resource-monitors" id="toc-resource-monitors" class="nav-link" data-scroll-target="#resource-monitors">2.8. Resource Monitors</a></li>
  <li><a href="#warehouses-and-multi-clustering" id="toc-warehouses-and-multi-clustering" class="nav-link" data-scroll-target="#warehouses-and-multi-clustering">2.9. Warehouses and Multi Clustering</a>
  <ul class="collapse">
  <li><a href="#warehouse-properties" id="toc-warehouse-properties" class="nav-link" data-scroll-target="#warehouse-properties">2.9.1. Warehouse Properties</a></li>
  <li><a href="#creating-a-warehouse" id="toc-creating-a-warehouse" class="nav-link" data-scroll-target="#creating-a-warehouse">2.9.2. Creating a Warehouse</a></li>
  </ul></li>
  <li><a href="#snowflake-objects" id="toc-snowflake-objects" class="nav-link" data-scroll-target="#snowflake-objects">2.10. Snowflake Objects</a></li>
  <li><a href="#snowsql" id="toc-snowsql" class="nav-link" data-scroll-target="#snowsql">2.11. SnowSQL</a></li>
  </ul></li>
  <li><a href="#loading-and-unloading-data" id="toc-loading-and-unloading-data" class="nav-link" data-scroll-target="#loading-and-unloading-data">3. Loading and Unloading Data</a>
  <ul class="collapse">
  <li><a href="#stages" id="toc-stages" class="nav-link" data-scroll-target="#stages">3.1. Stages</a>
  <ul class="collapse">
  <li><a href="#internal-stage" id="toc-internal-stage" class="nav-link" data-scroll-target="#internal-stage">3.1.1. Internal Stage</a></li>
  <li><a href="#external-stage" id="toc-external-stage" class="nav-link" data-scroll-target="#external-stage">3.1.2. External Stage</a></li>
  <li><a href="#commands-for-stages" id="toc-commands-for-stages" class="nav-link" data-scroll-target="#commands-for-stages">3.1.3. Commands For Stages</a></li>
  </ul></li>
  <li><a href="#copy-into" id="toc-copy-into" class="nav-link" data-scroll-target="#copy-into">3.2. COPY INTO</a>
  <ul class="collapse">
  <li><a href="#loading-data" id="toc-loading-data" class="nav-link" data-scroll-target="#loading-data">3.2.1. Loading Data</a></li>
  <li><a href="#unloading-data" id="toc-unloading-data" class="nav-link" data-scroll-target="#unloading-data">3.2.2. Unloading Data</a></li>
  </ul></li>
  <li><a href="#file-format" id="toc-file-format" class="nav-link" data-scroll-target="#file-format">3.3. File Format</a></li>
  <li><a href="#insert-and-update" id="toc-insert-and-update" class="nav-link" data-scroll-target="#insert-and-update">3.4. Insert and Update</a></li>
  <li><a href="#storage-integration-object" id="toc-storage-integration-object" class="nav-link" data-scroll-target="#storage-integration-object">3.5. Storage Integration Object</a></li>
  <li><a href="#snowpipe" id="toc-snowpipe" class="nav-link" data-scroll-target="#snowpipe">3.6. Snowpipe</a></li>
  <li><a href="#copy-options" id="toc-copy-options" class="nav-link" data-scroll-target="#copy-options">3.7. Copy Options</a>
  <ul class="collapse">
  <li><a href="#on_error" id="toc-on_error" class="nav-link" data-scroll-target="#on_error">3.7.1. ON_ERROR</a></li>
  <li><a href="#size_limit" id="toc-size_limit" class="nav-link" data-scroll-target="#size_limit">3.7.2. SIZE_LIMIT</a></li>
  <li><a href="#purge" id="toc-purge" class="nav-link" data-scroll-target="#purge">3.7.3. PURGE</a></li>
  <li><a href="#match_by_column_name" id="toc-match_by_column_name" class="nav-link" data-scroll-target="#match_by_column_name">3.7.4. MATCH_BY_COLUMN_NAME</a></li>
  <li><a href="#enforce_length" id="toc-enforce_length" class="nav-link" data-scroll-target="#enforce_length">3.7.5. ENFORCE_LENGTH</a></li>
  <li><a href="#force" id="toc-force" class="nav-link" data-scroll-target="#force">3.7.6. FORCE</a></li>
  <li><a href="#load_uncertain_files" id="toc-load_uncertain_files" class="nav-link" data-scroll-target="#load_uncertain_files">3.7.7. LOAD_UNCERTAIN_FILES</a></li>
  <li><a href="#validation_mode" id="toc-validation_mode" class="nav-link" data-scroll-target="#validation_mode">3.7.8. VALIDATION_MODE</a></li>
  </ul></li>
  <li><a href="#validate" id="toc-validate" class="nav-link" data-scroll-target="#validate">3.8. VALIDATE</a></li>
  <li><a href="#unloading" id="toc-unloading" class="nav-link" data-scroll-target="#unloading">3.9. Unloading</a></li>
  </ul></li>
  <li><a href="#data-transformation" id="toc-data-transformation" class="nav-link" data-scroll-target="#data-transformation">4. Data Transformation</a></li>
  <li><a href="#snowflake-tools-and-connectors" id="toc-snowflake-tools-and-connectors" class="nav-link" data-scroll-target="#snowflake-tools-and-connectors">5. Snowflake Tools and Connectors</a></li>
  <li><a href="#continuous-data-protection" id="toc-continuous-data-protection" class="nav-link" data-scroll-target="#continuous-data-protection">6. Continuous Data Protection</a></li>
  <li><a href="#zero-copy-cloning-and-sharing" id="toc-zero-copy-cloning-and-sharing" class="nav-link" data-scroll-target="#zero-copy-cloning-and-sharing">7. Zero-Copy Cloning and Sharing</a></li>
  <li><a href="#account-and-security" id="toc-account-and-security" class="nav-link" data-scroll-target="#account-and-security">8. Account and Security</a></li>
  <li><a href="#performance-concepts" id="toc-performance-concepts" class="nav-link" data-scroll-target="#performance-concepts">9. Performance Concepts</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="overview" class="level1">
<h1>1. Overview</h1>
<p>The <strong>Snowsight</strong> interface is the GUI through which we interact with Snowflake.</p>
<p>When querying a Snowflake table, a <strong>fully qualified table name</strong> means <code>database_name + schema_name + table_name</code>. For example, “DERIVED_DB.PUBLIC.TRADES_DATA”</p>
<p><strong>Worksheets</strong> are associated with a <strong>role</strong>.</p>
<p>A <strong>warehouse</strong> is needed for <strong>compute</strong> to execute a query.</p>
<p>Snowflake is a “self-managed cloud data platform”. It is cloud only. No on premise option.</p>
<p>“Self-managed” service means:</p>
<ul>
<li>No hardware</li>
<li>No software</li>
<li>No maintenance</li>
</ul>
<p>“Data platform” means it can function as:</p>
<ul>
<li>Data warehouse</li>
<li>Data lake - mix of structured and semi structured data</li>
<li>Data science - use yourpreferred language via <em>Snowpark</em></li>
</ul>
</section>
<section id="snowflake-architecture" class="level1">
<h1>2. Snowflake Architecture</h1>
<section id="multi-cluster-shared-disk" class="level2">
<h2 class="anchored" data-anchor-id="multi-cluster-shared-disk">2.1. Multi-cluster Shared Disk</h2>
<p>In general, there are two approaches to designing a dsitributed data / compute platform: shared-disk and shared-nothing.</p>
<p><strong>Shared-disk</strong> uses <em>central data storage</em> connected to <em>multiple compute nodes</em>.</p>
<ul>
<li>Pros: simple, easy data management since their is only one database/disk</li>
<li>Cons: limited scalability (bottleneck of the central disk), single point of failure</li>
</ul>
<p><strong>Shared-nothing</strong> keeps <em>each node independent</em>. Each node is a <em>separate processor, memory and disk</em>.</p>
<ul>
<li>Pros: scalability, availability</li>
<li>Cons: complicated, expensive</li>
</ul>
<p>Snowflake uses a <strong>hybrid approach</strong>: “multi-cluster shared-data”.</p>
<ul>
<li>There is a <em>single data repository like shared-disk</em>.</li>
<li>There are <em>multiple clusters or nodes</em> that store a <strong>portion</strong> of the data <strong>locally</strong>, like shared-nothing.</li>
</ul>
<p>This combines the pros of both: simplicity and scalability.</p>
</section>
<section id="layers-of-snowflake" class="level2">
<h2 class="anchored" data-anchor-id="layers-of-snowflake">2.2. Layers of Snowflake</h2>
<p>There are three distinct layers of Snowflake:</p>
<ol type="1">
<li>Database storage
<ol type="a">
<li>Compressed columnar storage.</li>
<li>This is stored as blobs in AWS, Azure, GCP etc.</li>
<li><strong>Snowflake abstracts this away</strong> so we just interact with it like a table.</li>
<li>This is optimised for OLAP (analytical purposes) which is <strong>read-heavy</strong>, rather than OLTP which is write-heavy.</li>
</ol></li>
<li>Compute
<ol type="a">
<li>“The <strong>muscle</strong> of the system”.</li>
<li>Query processing.</li>
<li>Queries are processed using <strong>“virtual warehouses”</strong>. These are massive parallel processing compute clusters, e.g.&nbsp;EC2 on AWS.</li>
</ol></li>
<li>Cloud services
<ol type="a">
<li>“The <strong>brain</strong> of the system”.</li>
<li>Collection of services to manage and coordinate components, e.g.&nbsp;the S3 and EC2 instances used in the other two layers.</li>
<li>The cloud services layer also runs on a compute instance of the cloud provider and is <em>completely handled by Snowflake</em>.</li>
<li>This layer handles: <strong>authentication, access control, metadata management, infrastructure management, query parsing and optimisation</strong>. The query <strong>execution</strong> happens in the compute layer.</li>
</ol></li>
</ol>
</section>
<section id="loading-data-into-snowflake" class="level2">
<h2 class="anchored" data-anchor-id="loading-data-into-snowflake">2.3. Loading Data into Snowflake</h2>
<p>This is covered more extensivelyt in its own section, but this sub-section serves as a brief introduction.</p>
<p>The usual SQL commands can be used to create databases and tables.</p>
<pre><code>CREATE DATABASE myfirstdb
ALTER DATABASE myfirstdb RENAME firstdb
CREATE TABLE loan_payments (
    col1 string,
    col2 string,
);</code></pre>
<p>We can specify a database to use with the <code>USE DATABASE</code> command to switch the active database. This avoids having to use the <em>fully qualified table name</em> everywhere.</p>
<pre><code>USE DATABASE firstdb

COPY INTO loan_payments
FROM s3/… -- The URL to copy from
file_format = (delimiter = “,”,
               skip rows=1,
               type=csv);</code></pre>
</section>
<section id="snowflake-editions" class="level2">
<h2 class="anchored" data-anchor-id="snowflake-editions">2.4. Snowflake Editions</h2>
<p>The different Snowflake editions vary by <em>features and pricing</em>. The feature matrix is available on the <a href="https://docs.snowflake.com/en/user-guide/intro-editions">Snowflake docs</a>.</p>
<ul>
<li>Standard
<ul>
<li>Complete DWH, automatic data encryption, support for standard and special data types, time travel 1 day, disaster recovery for 7 days beyond time travel, network policies, federated auth and SSO, 24/7 support</li>
</ul></li>
<li>Enterprise
<ul>
<li>Multi cluster warehouse, time travel 90 days, materialised views, search optimisation, column-level security, 24 hour early access to new releases</li>
</ul></li>
<li>Business critical
<ul>
<li>Additional security features such as customer managed encryption, support for data specific regulation, database failover and fallback</li>
</ul></li>
<li>Virtual private
<ul>
<li>Dedicated virtual servers and warehouse, dedicated metadata store. Isolated from all other snowflake accounts.</li>
</ul></li>
</ul>
</section>
<section id="compute-costs" class="level2">
<h2 class="anchored" data-anchor-id="compute-costs">2.5. Compute Costs</h2>
<section id="overview-of-cost-categories" class="level3">
<h3 class="anchored" data-anchor-id="overview-of-cost-categories">2.5.1. Overview of Cost Categories</h3>
<p>Compute costs and storage costs are decoupled and can be scaled separately. “Pay for what you need”.</p>
<ul>
<li><strong>Active warehouses</strong>
<ul>
<li>Used for standard query processing.</li>
<li>Billed per second (minimum 1 minute).</li>
<li>Depends on <em>size of warehouse, time and number of warehouses</em>.</li>
</ul></li>
<li><strong>Cloud services</strong>
<ul>
<li>Behind-the-scenes cloud service tasks.</li>
<li><em>Only charged if &gt;10% of warehouse consumption</em>, which is not the case for most customers.</li>
</ul></li>
<li><strong>Serverless</strong>
<ul>
<li>Used for <em>search optimisation</em> and <em>Snowpipe</em>.</li>
<li>This is compute that is managed by snowflake, e.g.&nbsp;event-based processing.</li>
</ul></li>
</ul>
<p>These are charged in <strong>Snowflake credits</strong>.</p>
</section>
<section id="calculating-number-of-credits-consumed-" class="level3">
<h3 class="anchored" data-anchor-id="calculating-number-of-credits-consumed-">2.5.2. Calculating Number of Credits Consumed-</h3>
<p>The warehouses consume the following number of credits per hour:</p>
<table class="table">
<thead>
<tr class="header">
<th>Warehouse Size</th>
<th>Number of Credits</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>XS</td>
<td>1</td>
</tr>
<tr class="even">
<td>S</td>
<td>2</td>
</tr>
<tr class="odd">
<td>M</td>
<td>4</td>
</tr>
<tr class="even">
<td>L</td>
<td>8</td>
</tr>
<tr class="odd">
<td>XL</td>
<td>16</td>
</tr>
<tr class="even">
<td>4XL</td>
<td>128</td>
</tr>
</tbody>
</table>
<p><strong>Credits cost different amounts per edition.</strong> It also depends on the <em>cloud provider</em> (AWS) and <em>region</em> (US-East-1). Indicative costs for AWS US-East-1 are:</p>
<table class="table">
<thead>
<tr class="header">
<th>Edition</th>
<th>$ / Credit</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Standard</td>
<td>2</td>
</tr>
<tr class="even">
<td>Enterprise</td>
<td>3</td>
</tr>
<tr class="odd">
<td>Business Critical</td>
<td>4</td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="storage-and-data-costs" class="level2">
<h2 class="anchored" data-anchor-id="storage-and-data-costs">2.6 Storage and Data Costs</h2>
<section id="storage-types-and-costs" class="level3">
<h3 class="anchored" data-anchor-id="storage-types-and-costs">2.6.1. Storage Types and Costs</h3>
<p>Monthly storage costs are based on <strong>average storage used per month</strong>. Also depends on <strong>cloud provider and region</strong>. Cost is calculated <strong>AFTER Snowflake’s data compression</strong>.</p>
<p>There are two options for storage pricing:</p>
<ul>
<li><strong>On demand storage</strong>: Pay for what you use.</li>
<li><strong>Capacity storage</strong>: Pay upfront for defined capacity.</li>
</ul>
<p>Typically start with on demand until we understand our actual usage, then shift to capacity storage once this is stable.</p>
</section>
<section id="transfer-costs" class="level3">
<h3 class="anchored" data-anchor-id="transfer-costs">2.6.2. Transfer Costs</h3>
<p>This depends on data <strong>ingress vs egress</strong>.</p>
<ul>
<li><strong>Data IN is free</strong>
<ul>
<li>Snowflake wants to remove friction to getting your data in.</li>
</ul></li>
<li><strong>Data OUT is charged</strong>
<ul>
<li>Snowflake wants to add friction to leaving.</li>
<li>Depends on <em>cloud provider and region</em>. <strong>In-region transfers are free</strong>. Cross-region or cross-providers are charged.</li>
</ul></li>
</ul>
</section>
</section>
<section id="storage-monitoring" class="level2">
<h2 class="anchored" data-anchor-id="storage-monitoring">2.7. Storage Monitoring</h2>
<p>We can monitor storage for <em>individual tables</em>.</p>
<p><code>SHOW TABLES</code> gives general table storage stats and properties.</p>
<p>We get more detailed views with <code>TABLE_STORAGE_METRICS</code>. We can run this against the information schema or the account storage. These split the sizes into active bytes, time travel bytes and failsafe bytes.</p>
<p>For the information schema metrics:</p>
<pre><code>SELECT * FROM DB_NAME.INFORMATION_SCHEMA.TABLE_STORAGE_METRICS;</code></pre>
<p>For the account admin metrics, this needs to use the correct account admin role <code>USE ROLE ACCOUNTADMIN</code>.</p>
<pre><code>SELECT * FROM SNOWFLAKE.ACCOUNT_USAGE.TABLE_STORAGE_METRICS;</code></pre>
<p>We can also look at the <code>Admin -&gt; Usage</code> screen in the Snowflake GUI.</p>
</section>
<section id="resource-monitors" class="level2">
<h2 class="anchored" data-anchor-id="resource-monitors">2.8. Resource Monitors</h2>
<p>Resource monitors help us <strong>control and monitor credit usage</strong> of individual warehouses and the entire account.</p>
<p>We can set a <strong>credit quota</strong> which limit the credits used per period. For example, the maximim number of credits that can be spent per month.</p>
<p>We can set <strong>actions</strong> based on when a percentage of the credit limit is reached. These percentages can be &gt;100%. There are three options for the choice of action:</p>
<ul>
<li>Notify</li>
<li>Suspend and notify (but continue running tasks that have already started)</li>
<li>Suspend immediately (aborting any running queries) and notify.</li>
</ul>
<p>We set this using the Usage tab in the ACCOUNTADMIN role in the snowsight UI under <code>Admin -&gt; Usage</code>. Other roles can be granted MONITOR and MODIFY privileges.</p>
<p>We can select a warehouse then filter on different dimensions, for example, distinguishing storage vs compute vs data transfer costs.</p>
<p>To set up a new resource monitor, we give it:</p>
<ul>
<li>Name</li>
<li>Credit quota: how many credits to limit to</li>
<li>Monitor type: specific warehouse, group of warehouses, or overall account</li>
<li>Schedule</li>
<li>Actions</li>
</ul>
</section>
<section id="warehouses-and-multi-clustering" class="level2">
<h2 class="anchored" data-anchor-id="warehouses-and-multi-clustering">2.9. Warehouses and Multi Clustering</h2>
<section id="warehouse-properties" class="level3">
<h3 class="anchored" data-anchor-id="warehouse-properties">2.9.1. Warehouse Properties</h3>
<p>There are different <em>types</em> and <em>sizes</em> of warehouse and they can be <em>multi-clustered</em>.</p>
<p><strong>Types</strong>: standard and snowpark-optimised (for memeory-intensive tasks like ML)</p>
<p><strong>Size</strong>: XS to XXL. Snowpark type is only M or bigger and consumes 50% more credits</p>
<p><strong>Multi-clustering</strong> is good for more queries, i.e.&nbsp;more concurrent users. We scale horizontally so there are multiple small warehouses rather than one big one. They can be in <strong>maximised mode</strong> (set size) or <strong>autoscaled mode</strong> (number of nodes scales between predefined min and max)</p>
<p>The <em>autoscaler</em> decides to add warehouses based on the queue, according to the <strong>scaling policy</strong>.</p>
<ul>
<li>Standard
<ul>
<li>Favours starting extra clusters.</li>
<li>Starts a new cluster <strong>as soon as there is a query queued</strong>.</li>
<li>Cluster shuts down after 2 to 3 successful checks. A “check” is when the load on the least used node could be redistributed to other nodes.</li>
</ul></li>
<li>Economy
<ul>
<li>Favours <strong>conserving credits</strong>.</li>
<li>Starts a new cluster once the workload for the cluster would keep it <strong>running for &gt; 6 mins</strong>.</li>
<li>Cluster shuts down after 5-6 successful checks.</li>
</ul></li>
</ul>
</section>
<section id="creating-a-warehouse" class="level3">
<h3 class="anchored" data-anchor-id="creating-a-warehouse">2.9.2. Creating a Warehouse</h3>
<p>To create a warehouse, we need to use the ACCOUNTADMIN, SECURTIYADMIN or SYSADMIN role.</p>
<p>Warehouses can either be created through UI or SQL.</p>
<pre><code>CREATE WAREHOUSE my_wh
WITH
WAREHOUSE_SIZE = XSMALL
MIN_CLUSTER_COUNT = 1
MAX_CLUSTER_COUNT = 3
AUTO_RESUME = TRUE
AUTO_SUSPEND = 300
COMMENT = 'This is the first warehouse'</code></pre>
<p>We can also <code>ALTER</code> or <code>DROP</code> a warehouse in SQL, just like we normally would with <code>DROP TABLE</code>.</p>
<pre><code>DROP WAREHOUSE my_wh;</code></pre>
</section>
</section>
<section id="snowflake-objects" class="level2">
<h2 class="anchored" data-anchor-id="snowflake-objects">2.10. Snowflake Objects</h2>
<p>There is a hierarchy of objects in Snowflake.</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart TD


  A(Organisation) --&gt; B1(Account 1)
  A(Organisation) --&gt; B2(Account 2)


  B1 --&gt; C1(Users)
  B1 --&gt; C2(Roles)
  B1 --&gt; C3(Databases)
  B1 --&gt; C4(Warehouses)
  B1 --&gt; C5(Other account objects)
  
  C3 --&gt; D1(Schemas)

  D1 --&gt; E1(UDFs)
  D1 --&gt; E2(Views)
  D1 --&gt; E3(Tables)
  D1 --&gt; E4(Stages)
  D1 --&gt; E5(Other database objects)
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>An <strong>organisation</strong> (managed by ORGADMIN) can have multiple <strong>accounts</strong> (each managed by am ACCOUNTADMIN). These accounts might be by cloud region or department.</p>
<p>Within each <strong>account</strong> we have multiple account objects: <strong>users, roles, databases, warehouses, other objects</strong>.</p>
<p><strong>Databases</strong> can have multiple <strong>schemas</strong>.</p>
<p><strong>Schemas</strong> can have multiples <strong>UDFs, views, tables, stages, other objects</strong>.</p>
</section>
<section id="snowsql" class="level2">
<h2 class="anchored" data-anchor-id="snowsql">2.11. SnowSQL</h2>
<p>SnowSQL is used to connect to Snowflake via the <strong>command line</strong>. It needs to be installed on your local machine.</p>
<p>We can execute queries, load and unload data, etc.</p>
</section>
</section>
<section id="loading-and-unloading-data" class="level1">
<h1>3. Loading and Unloading Data</h1>
<section id="stages" class="level2">
<h2 class="anchored" data-anchor-id="stages">3.1. Stages</h2>
<p>Stages are <strong>locations used to store data</strong>.</p>
<p>From the stage, say an S3 bucket, we can <strong>load</strong> data from stage -&gt; database. Likewise, we can <strong>unload</strong> data from database -&gt; stage (S3 bucket).</p>
<p>Stages can be <strong>internal</strong> (managed by Snowflake) or <strong>external</strong> (managed by your cloud provider, eg AWS S3).</p>
<section id="internal-stage" class="level3">
<h3 class="anchored" data-anchor-id="internal-stage">3.1.1. Internal Stage</h3>
<p>An internal stage is managed by Snowflake.</p>
<p>We <strong>upload data into an internal stage</strong> using the <code>PUT</code> command. By default, files are compressed with gzip and encrypted.</p>
<p>We <strong>load</strong> it into the database using the <code>COPY INTO</code> command. We can also <strong>unload</strong> using the <code>COPY INTO</code> command by varying the destination.</p>
<p>There are three types of stage:</p>
<ul>
<li>User stage
<ul>
<li>Can only be accessed by <strong>one user</strong></li>
<li>Every user has one by default</li>
<li>Cannot be altered or dropped</li>
<li>Accessed with <code>@~</code></li>
</ul></li>
<li>Table stage
<ul>
<li>Can only be accessed by <strong>one table</strong></li>
<li>Cannot be altered or dropped</li>
<li>Use this to load to a specific table</li>
<li>Accessed with <code>@%</code></li>
</ul></li>
<li>Named stage
<ul>
<li><code>CREATE STAGE</code> to create your own</li>
<li>This is then just like any other database object, so you can modify it or grant privileges</li>
<li>Most commonly used stage</li>
<li>Accessed with <code>@</code></li>
</ul></li>
</ul>
<p>A typical use case for an internal stage is when we have a file on our local system that we want to load into Snowflake, but we don’t have an external cloud provider set up.</p>
</section>
<section id="external-stage" class="level3">
<h3 class="anchored" data-anchor-id="external-stage">3.1.2. External Stage</h3>
<p>An external stage connects to an external cloud provider, such as an S3 bucket.</p>
<p>We create it with the <code>CREATE STAGE</code> command as with an internal stage. This creates a Snowflake object that we can modify and grant privileges to.</p>
<pre><code>CREATE STAGE stage_name 
  URL='s3://bucket/path/'</code></pre>
<p>We <em>can</em> add <code>CREDENTIALS</code> argument but this would store them in plain text. A better practice is to pass a <code>STORAGE_INTEGRATION</code> argument that points to credentials.</p>
<p>We can also specify the <code>FILE_FORMAT</code>.</p>
</section>
<section id="commands-for-stages" class="level3">
<h3 class="anchored" data-anchor-id="commands-for-stages">3.1.3. Commands For Stages</h3>
<p>Some of the most common commands for stages:</p>
<ul>
<li><code>LIST</code>
<ul>
<li>List all files (and additional properties) in the stage.</li>
</ul></li>
<li><code>COPY INTO</code>
<ul>
<li>Load data into the stage, or unload data from the stage.</li>
</ul></li>
<li><code>SELECT</code>
<ul>
<li>Query from stage</li>
</ul></li>
<li><code>DESC</code>
<ul>
<li>Describe the stage. Shows the default values or arguments.</li>
</ul></li>
</ul>
</section>
</section>
<section id="copy-into" class="level2">
<h2 class="anchored" data-anchor-id="copy-into">3.2. COPY INTO</h2>
<p>This can <strong>bulk load or unload data</strong>.</p>
<p>A <em>warehouse is needed</em>. Data transfer costs may apply if moving across regions or cloud providers.</p>
<section id="loading-data" class="level3">
<h3 class="anchored" data-anchor-id="loading-data">3.2.1. Loading Data</h3>
<p>Load data from a stage to a table with:</p>
<pre><code>COPY INTO table_name 
FROM stage_name</code></pre>
<p>We can specify a file or list of files with the <code>FILES</code> argument.</p>
<p>Supported file formats are:</p>
<ul>
<li>csv (default)</li>
<li>json</li>
<li>avro</li>
<li>orc</li>
<li>parquet</li>
<li>xml</li>
</ul>
<p>We can also use the <code>PATTERN</code> argument to match a file pattern with wildcards, e.g.&nbsp;<code>order*.csv</code></p>
</section>
<section id="unloading-data" class="level3">
<h3 class="anchored" data-anchor-id="unloading-data">3.2.2. Unloading Data</h3>
<p>Unloading data from the table to a stage uses the same syntax:</p>
<pre><code>COPY INTO stage_name 
FROM table_name</code></pre>
<p>As with loading, we can specify a file format with the <code>FILE_FORMAT</code> arg, or pass a reusable <code>FILE_FORMAT</code> object.</p>
<pre><code>COPY INTO stage_name 
FROM table_name
FILE_FORMAT = ( FORMAT_NAME = 'file_format_name' |
                TYPE = CSV )</code></pre>
</section>
</section>
<section id="file-format" class="level2">
<h2 class="anchored" data-anchor-id="file-format">3.3. File Format</h2>
<p>If the file format is not specified, it defaults to csv. You can see this and other default values by describing the stage with:</p>
<pre><code>DESC STAGE stage_name</code></pre>
<p>We can overrule the defaults by specifying <code>FILE_FORMAT</code> argument in the <code>COPY INTO</code> command.</p>
<p>A better practice is to use the file_format arg to pass a file_format object such as</p>
<pre><code>FILE_FORMAT = (TYPE = CSV)</code></pre>
<p>We create this object with</p>
<pre><code>CREATE FILE FORMAT file_format_name
TYPE = CSV
FIELD_DELIMITER = ‘,’
SKIP_HEADER = 1</code></pre>
<p>We write this file format to a table like <code>manage_db</code>. Then we can reuse it in multiple places when creating the stage or table, loading or unloading data, etc.</p>
</section>
<section id="insert-and-update" class="level2">
<h2 class="anchored" data-anchor-id="insert-and-update">3.4. Insert and Update</h2>
<p><strong>Insert</strong> is the same as standard SQL:</p>
<pre><code>INSERT INTO table_name
VALUES (1, 0.5, 'string')</code></pre>
<p>To only insert <em>specific columns</em>:</p>
<pre><code>INSERT INTO table_name (col1, col2)
VALUES (1, 0.5)</code></pre>
<p><code>INSERT OVERWRITE</code> will <strong>truncate any existing data</strong> and insert <strong>only</strong> the given values. <strong>Use with caution!</strong> Any previous data is dropped, the table with only have the rows in this command.</p>
<p><strong>Update</strong> also works like standard SQL:</p>
<pre><code>UPDATE table_name
SET col1=10
WHERE col1=1</code></pre>
<p><code>TRUNCATE</code> removes all of the values in the table.</p>
<p><code>DROP</code> removes the entire table object and its contents.</p>
</section>
<section id="storage-integration-object" class="level2">
<h2 class="anchored" data-anchor-id="storage-integration-object">3.5. Storage Integration Object</h2>
<p>This object stores a <strong>generated identity for external cloud storage</strong>.</p>
<p>We create it as a Snowflake object which constrains the allowed location and grant permissions to it in AWS, Azure etc.</p>
</section>
<section id="snowpipe" class="level2">
<h2 class="anchored" data-anchor-id="snowpipe">3.6. Snowpipe</h2>
<p>The discussion so far has focused on <strong>bulk loading</strong>, i.e.&nbsp;manual loading of a batch of data.</p>
<p>Snowpipe is used for <strong>continuous data loading</strong>.</p>
<p>A <strong>pipe</strong> is a Snowflake object. It <em>loads data immediately when a file appears in blob storage</em>. It triggers a predefined <code>COPY</code> command. This is useful <strong>when data needs to be available immediately</strong>.</p>
<p>Snowpipe uses <strong>serverless</strong> features rather than warehouses.</p>
<p>When files are uploaded to an S3 bucket, it sends an event notification to a serverless process which executes the copy command into the Snowflake database.</p>
<pre><code>CREATE PIPE pipe_name
AUTO_INGEST = TRUE
INGESTION = notification integration from cloud storage 
COMMENT = string
AS COPY INTO table_name
FROM stage_name</code></pre>
<p>Snowpipe can be triggered by <strong>cloud messages</strong> or <strong>REST API</strong>. Cloud messages are for external stages only with that cloud provider. REST API can be internal or external stage.</p>
<ul>
<li><strong>Cost</strong> is based on “per second per core” of the serverless process.</li>
<li><strong>Time</strong> depends on size and number of files.</li>
<li><strong>Ideal file size</strong> is between 100-250 MB.</li>
</ul>
<p>Snowflake stores metadata about the file loading. Old history is retained for 14 days. The location of the pipe is stored in a schema in the database.</p>
<p>The <strong>schedule can be paused or resumed</strong> by altering the pipe.</p>
<pre><code>ALTER PIPE pipe_name
SET PIPE_EXECUTION_PAUSED = True</code></pre>
</section>
<section id="copy-options" class="level2">
<h2 class="anchored" data-anchor-id="copy-options">3.7. Copy Options</h2>
<p>These are arguments we can pass to <code>COPY INTO</code> for loading and unloading. Some options only apply to loading and do not apply to unloading.</p>
<p>They are <em>properties of the stage object</em>, so if the arguments are not passed Snowflake will fall back to these default values.</p>
<section id="on_error" class="level3">
<h3 class="anchored" data-anchor-id="on_error">3.7.1. ON_ERROR</h3>
<ul>
<li><strong>Data Type</strong>: String</li>
<li><strong>Description</strong>: Only for data loading. How to handle errors in files.</li>
<li><strong>Possible Values</strong>:
<ul>
<li><code>CONTINUE</code> - Continue loading file if errors are found.</li>
<li><code>SKIP_FILE</code> - Skip loading this file if errors are found. This is the <strong>default for Snowpipe</strong>.</li>
<li><code>SKIP_FILE_&lt;num&gt;</code> - Skip if <code>&gt;= num</code> errors are found (absolute).</li>
<li><code>SKIP_FILE_&lt;pct&gt;%</code> - Skip if <code>&gt;= pct</code> errors are found (percentage).</li>
<li><code>ABORT_STATEMENT</code> - Abort loading if an error is found. This is the <strong>default for bulk load</strong>.</li>
</ul></li>
</ul>
</section>
<section id="size_limit" class="level3">
<h3 class="anchored" data-anchor-id="size_limit">3.7.2. SIZE_LIMIT</h3>
<ul>
<li><strong>Data Type</strong>: Int</li>
<li><strong>Description</strong>: Maximum <em>cumulative size</em>, in bytes, to load. Once this amount of data has been loaded, skip any remaining files.</li>
<li><strong>Possible Values</strong>: Int bytes.</li>
</ul>
</section>
<section id="purge" class="level3">
<h3 class="anchored" data-anchor-id="purge">3.7.3. PURGE</h3>
<ul>
<li><strong>Data Type</strong>: Bool</li>
<li><strong>Description</strong>: Remove files from the stage after they have been loaded.</li>
<li><strong>Possible Values</strong>: <code>FALSE</code> (default) | <code>TRUE</code></li>
</ul>
</section>
<section id="match_by_column_name" class="level3">
<h3 class="anchored" data-anchor-id="match_by_column_name">3.7.4. MATCH_BY_COLUMN_NAME</h3>
<ul>
<li><strong>Data Type</strong>: String</li>
<li><strong>Description</strong>: Load semi structured data by matching field names.</li>
<li><strong>Possible Values</strong>: <code>NONE</code> (default) | <code>CASE_SENSITIVE</code> | <code>CASE_INSENSITIVE</code></li>
</ul>
</section>
<section id="enforce_length" class="level3">
<h3 class="anchored" data-anchor-id="enforce_length">3.7.5. ENFORCE_LENGTH</h3>
<ul>
<li><strong>Data Type</strong>: Bool</li>
<li><strong>Description</strong>: If we have a varchar(10) field, how should we handle data that is too long?</li>
<li><strong>Possible Values</strong>:
<ul>
<li><code>TRUE</code> (default) - Raise an error</li>
<li><code>FALSE</code> - Automatically truncate strings</li>
</ul></li>
</ul>
<p><code>TRUNCATECOLUMNS</code> is an alternative arg that does the <strong>opposite</strong>.</p>
</section>
<section id="force" class="level3">
<h3 class="anchored" data-anchor-id="force">3.7.6. FORCE</h3>
<ul>
<li><strong>Data Type</strong>: Bool</li>
<li><strong>Description</strong>: If we have loaded this file before, should we load it again?</li>
<li><strong>Possible Values</strong>: <code>False</code> (default) | <code>TRUE</code></li>
</ul>
</section>
<section id="load_uncertain_files" class="level3">
<h3 class="anchored" data-anchor-id="load_uncertain_files">3.7.7. LOAD_UNCERTAIN_FILES</h3>
<ul>
<li><strong>Data Type</strong>: Bool</li>
<li><strong>Description</strong>: Should we load files if the load status is unknown?</li>
<li><strong>Possible Values</strong>: <code>False</code> (default) | <code>TRUE</code></li>
</ul>
</section>
<section id="validation_mode" class="level3">
<h3 class="anchored" data-anchor-id="validation_mode">3.7.8. VALIDATION_MODE</h3>
<ul>
<li><strong>Data Type</strong>: String</li>
<li><strong>Description</strong>: Validate the data instead of actually loading it.</li>
<li><strong>Possible Values</strong>:
<ul>
<li><code>RETURN_N_ROWS</code> - Validate the first N rows and returns them (like a SELECT statement would). If there is one or more errors in those rows, raise the first.</li>
<li><code>RETURN_ERRORS</code> - Return all errors in the file.</li>
</ul></li>
</ul>
</section>
</section>
<section id="validate" class="level2">
<h2 class="anchored" data-anchor-id="validate">3.8. VALIDATE</h2>
<p>The <code>VALIDATE</code> function validates the files loaded in a <strong>previous COPY INTO</strong>.</p>
<p>Returns a list of errors from that bulk load. This is a <em>table function</em>, which means it returns multiple rows.</p>
<pre><code>SELECT * 
FROM TABLE(VALIDATE(table_name, JOB_ID =&gt; ‘_last’))</code></pre>
<p>We can pass a query ID instead of _last to use a specific job run rather than the last run.</p>
</section>
<section id="unloading" class="level2">
<h2 class="anchored" data-anchor-id="unloading">3.9. Unloading</h2>
<p>The syntax for unloading data from a table into a stage is the same as loading, we just swap the source and target.</p>
<pre><code>COPY INTO stage_name FROM table_name</code></pre>
<p>We can unload specific rows or columns by using a <code>SELECT</code> statement:</p>
<pre><code>COPY INTO stage_name 
FROM (SELECT col1, col2 FROM table_name)</code></pre>
<p>We can pass a <code>FILE_FORMAT</code> object and <code>HEADER</code> args.</p>
<p>We can also specify the <strong>prefix</strong> or <strong>suffix</strong> for each file. By default the prefix is data_ and the suffix is _0, _1, etc.</p>
<pre><code>COPY INTO stage_name/myprefix</code></pre>
<p>This is the default behaviour to <strong>split the output into multiple files</strong> once <code>MAX_FILE_SIZE</code> is reached, setting an upper limit on the output. The <code>SINGLE</code> parameter can be passed to override this, to force the unloading task to keep the output to a single file without splitting.</p>
<p>If unloading to an <em>internal stage</em>, to get the data on your local machine use SnowSQL to run a GET command on the internal stage after unloading.</p>
<p>You can then use the <code>REMOVE</code> command to delete from the internal stage.</p>
</section>
</section>
<section id="data-transformation" class="level1">
<h1>4. Data Transformation</h1>
</section>
<section id="snowflake-tools-and-connectors" class="level1">
<h1>5. Snowflake Tools and Connectors</h1>
</section>
<section id="continuous-data-protection" class="level1">
<h1>6. Continuous Data Protection</h1>
</section>
<section id="zero-copy-cloning-and-sharing" class="level1">
<h1>7. Zero-Copy Cloning and Sharing</h1>
</section>
<section id="account-and-security" class="level1">
<h1>8. Account and Security</h1>
</section>
<section id="performance-concepts" class="level1">
<h1>9. Performance Concepts</h1>
</section>
<section id="references" class="level1">
<h1>References</h1>
<ul>
<li><a href="https://www.udemy.com/course/snowflake-certification-snowpro-core-exam-prep">“Snowflake Certification: SnowPro Core COF-C02 Exam Prep” Udemy course</a></li>
<li><a href="https://docs.snowflake.com/en/user-guide/intro-editions">Snowflake feature matrix</a></li>
</ul>


</section>

<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>