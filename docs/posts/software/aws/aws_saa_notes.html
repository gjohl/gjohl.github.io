<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Gurpreet Johl">
<meta name="dcterms.date" content="2025-09-24">
<meta name="description" content="Cloud Strife">

<title>Gurpreet Johl - AWS Solutions Architect</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Gurpreet Johl</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../projects.html"> 
<span class="menu-text">Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../blog.html"> 
<span class="menu-text">Notes</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/gjohl"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/gurpreetjohl"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/gurpreetjohl"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">AWS Solutions Architect</h1>
                  <div>
        <div class="description">
          Cloud Strife
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">DataEngineering</div>
                <div class="quarto-category">Engineering</div>
                <div class="quarto-category">Software</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Gurpreet Johl </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">September 24, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#getting-started" id="toc-getting-started" class="nav-link active" data-scroll-target="#getting-started">1. Getting Started</a>
  <ul class="collapse">
  <li><a href="#aws-global-infrastructure" id="toc-aws-global-infrastructure" class="nav-link" data-scroll-target="#aws-global-infrastructure">1.1. AWS Global Infrastructure</a></li>
  <li><a href="#tour-of-the-console" id="toc-tour-of-the-console" class="nav-link" data-scroll-target="#tour-of-the-console">1.2. Tour of the Console</a></li>
  <li><a href="#aws-billing" id="toc-aws-billing" class="nav-link" data-scroll-target="#aws-billing">1.3. AWS Billing</a></li>
  </ul></li>
  <li><a href="#iam" id="toc-iam" class="nav-link" data-scroll-target="#iam">2. IAM</a>
  <ul class="collapse">
  <li><a href="#overview" id="toc-overview" class="nav-link" data-scroll-target="#overview">2.1. Overview</a></li>
  <li><a href="#permissions" id="toc-permissions" class="nav-link" data-scroll-target="#permissions">2.2. Permissions</a></li>
  <li><a href="#creating-users-and-groups" id="toc-creating-users-and-groups" class="nav-link" data-scroll-target="#creating-users-and-groups">2.3. Creating Users and Groups</a></li>
  <li><a href="#iam-policies" id="toc-iam-policies" class="nav-link" data-scroll-target="#iam-policies">2.4. IAM Policies</a></li>
  <li><a href="#mfa" id="toc-mfa" class="nav-link" data-scroll-target="#mfa">2.5. MFA</a></li>
  <li><a href="#access-keys" id="toc-access-keys" class="nav-link" data-scroll-target="#access-keys">2.6. Access Keys</a></li>
  <li><a href="#aws-cloudshell" id="toc-aws-cloudshell" class="nav-link" data-scroll-target="#aws-cloudshell">2.7. AWS CloudShell</a></li>
  <li><a href="#iam-roles-for-services" id="toc-iam-roles-for-services" class="nav-link" data-scroll-target="#iam-roles-for-services">2.8. IAM Roles for Services</a></li>
  <li><a href="#iam-security-tools" id="toc-iam-security-tools" class="nav-link" data-scroll-target="#iam-security-tools">2.9. IAM Security Tools</a></li>
  <li><a href="#iam-guidelines-and-best-practices" id="toc-iam-guidelines-and-best-practices" class="nav-link" data-scroll-target="#iam-guidelines-and-best-practices">2.10 IAM Guidelines and Best Practices</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">2.11. Summary</a></li>
  </ul></li>
  <li><a href="#ec2" id="toc-ec2" class="nav-link" data-scroll-target="#ec2">3. EC2</a>
  <ul class="collapse">
  <li><a href="#ec2-overview" id="toc-ec2-overview" class="nav-link" data-scroll-target="#ec2-overview">3.1. EC2 Overview</a></li>
  <li><a href="#creating-an-ec2-instance" id="toc-creating-an-ec2-instance" class="nav-link" data-scroll-target="#creating-an-ec2-instance">3.2. Creating an EC2 Instance</a></li>
  <li><a href="#ec2-instance-types" id="toc-ec2-instance-types" class="nav-link" data-scroll-target="#ec2-instance-types">3.3. EC2 Instance Types</a></li>
  <li><a href="#security-groups" id="toc-security-groups" class="nav-link" data-scroll-target="#security-groups">3.4. Security Groups</a></li>
  <li><a href="#connecting-to-instances" id="toc-connecting-to-instances" class="nav-link" data-scroll-target="#connecting-to-instances">3.5. Connecting to Instances</a>
  <ul class="collapse">
  <li><a href="#linux-via-ssh" id="toc-linux-via-ssh" class="nav-link" data-scroll-target="#linux-via-ssh">3.5.1. Linux via SSH</a></li>
  <li><a href="#ec2-instance-connect" id="toc-ec2-instance-connect" class="nav-link" data-scroll-target="#ec2-instance-connect">3.5.2. EC2 Instance Connect</a></li>
  </ul></li>
  <li><a href="#ec2-instance-roles" id="toc-ec2-instance-roles" class="nav-link" data-scroll-target="#ec2-instance-roles">3.6. EC2 Instance Roles</a></li>
  <li><a href="#ec2-instance-purchase-options" id="toc-ec2-instance-purchase-options" class="nav-link" data-scroll-target="#ec2-instance-purchase-options">3.7. EC2 Instance Purchase Options</a>
  <ul class="collapse">
  <li><a href="#purchase-options" id="toc-purchase-options" class="nav-link" data-scroll-target="#purchase-options">3.7.1. Purchase Options</a></li>
  <li><a href="#ipv4-charges" id="toc-ipv4-charges" class="nav-link" data-scroll-target="#ipv4-charges">3.7.2. IPv4 Charges</a></li>
  <li><a href="#spot-instances" id="toc-spot-instances" class="nav-link" data-scroll-target="#spot-instances">3.7.3. Spot Instances</a></li>
  </ul></li>
  <li><a href="#spot-fleets" id="toc-spot-fleets" class="nav-link" data-scroll-target="#spot-fleets">3.7.4. Spot Fleets</a></li>
  </ul></li>
  <li><a href="#ec2-networking" id="toc-ec2-networking" class="nav-link" data-scroll-target="#ec2-networking">4. EC2 Networking</a>
  <ul class="collapse">
  <li><a href="#private-vs-public-ip" id="toc-private-vs-public-ip" class="nav-link" data-scroll-target="#private-vs-public-ip">4.1. Private vs Public IP</a></li>
  <li><a href="#elastic-ip" id="toc-elastic-ip" class="nav-link" data-scroll-target="#elastic-ip">4.2. Elastic IP</a></li>
  <li><a href="#placement-groups" id="toc-placement-groups" class="nav-link" data-scroll-target="#placement-groups">4.3. Placement Groups</a>
  <ul class="collapse">
  <li><a href="#creating-a-placement-group" id="toc-creating-a-placement-group" class="nav-link" data-scroll-target="#creating-a-placement-group">Creating a Placement Group</a></li>
  </ul></li>
  <li><a href="#elastic-network-interfaces" id="toc-elastic-network-interfaces" class="nav-link" data-scroll-target="#elastic-network-interfaces">4.4. Elastic Network Interfaces</a>
  <ul class="collapse">
  <li><a href="#what-is-an-eni" id="toc-what-is-an-eni" class="nav-link" data-scroll-target="#what-is-an-eni">4.4.1. What is an ENI?</a></li>
  <li><a href="#creating-an-eni" id="toc-creating-an-eni" class="nav-link" data-scroll-target="#creating-an-eni">4.4.2. Creating an ENI</a></li>
  <li><a href="#attaching-an-eni-to-an-instance" id="toc-attaching-an-eni-to-an-instance" class="nav-link" data-scroll-target="#attaching-an-eni-to-an-instance">4.4.3 Attaching an ENI to an Instance</a></li>
  </ul></li>
  <li><a href="#ec2-hibernate" id="toc-ec2-hibernate" class="nav-link" data-scroll-target="#ec2-hibernate">4.5. EC2 Hibernate</a>
  <ul class="collapse">
  <li><a href="#why-hibernate" id="toc-why-hibernate" class="nav-link" data-scroll-target="#why-hibernate">4.5.1. Why Hibernate?</a></li>
  <li><a href="#enable-hibernation-on-an-instance" id="toc-enable-hibernation-on-an-instance" class="nav-link" data-scroll-target="#enable-hibernation-on-an-instance">4.5.2. Enable Hibernation on an Instance</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#ec2-instance-storage" id="toc-ec2-instance-storage" class="nav-link" data-scroll-target="#ec2-instance-storage">5. EC2 Instance Storage</a>
  <ul class="collapse">
  <li><a href="#ebs" id="toc-ebs" class="nav-link" data-scroll-target="#ebs">5.1. EBS</a>
  <ul class="collapse">
  <li><a href="#what-is-an-ebs-volume" id="toc-what-is-an-ebs-volume" class="nav-link" data-scroll-target="#what-is-an-ebs-volume">5.1.1. What is an EBS Volume?</a></li>
  <li><a href="#creating-an-ebs-volume-on-an-instance" id="toc-creating-an-ebs-volume-on-an-instance" class="nav-link" data-scroll-target="#creating-an-ebs-volume-on-an-instance">5.1.2. Creating an EBS Volume on an Instance</a></li>
  <li><a href="#ebs-snapshots" id="toc-ebs-snapshots" class="nav-link" data-scroll-target="#ebs-snapshots">5.1.3. EBS Snapshots</a></li>
  <li><a href="#ebs-features-hands-on" id="toc-ebs-features-hands-on" class="nav-link" data-scroll-target="#ebs-features-hands-on">5.1.4. EBS Features Hands On</a></li>
  <li><a href="#ebs-volume-types" id="toc-ebs-volume-types" class="nav-link" data-scroll-target="#ebs-volume-types">5.1.5. EBS Volume Types</a></li>
  <li><a href="#ebs-multi-attach" id="toc-ebs-multi-attach" class="nav-link" data-scroll-target="#ebs-multi-attach">5.1.6. EBS Multi Attach</a></li>
  <li><a href="#ebs-encryption" id="toc-ebs-encryption" class="nav-link" data-scroll-target="#ebs-encryption">5.1.7. EBS Encryption</a></li>
  </ul></li>
  <li><a href="#ami" id="toc-ami" class="nav-link" data-scroll-target="#ami">5.2. AMI</a></li>
  <li><a href="#ec2-instance-store" id="toc-ec2-instance-store" class="nav-link" data-scroll-target="#ec2-instance-store">5.3. EC2 Instance Store</a></li>
  <li><a href="#elastic-file-system-efs" id="toc-elastic-file-system-efs" class="nav-link" data-scroll-target="#elastic-file-system-efs">5.4. Elastic File System (EFS)</a>
  <ul class="collapse">
  <li><a href="#what-is-efs" id="toc-what-is-efs" class="nav-link" data-scroll-target="#what-is-efs">5.4.1. What is EFS?</a></li>
  <li><a href="#performance-modes" id="toc-performance-modes" class="nav-link" data-scroll-target="#performance-modes">5.4.2. Performance Modes</a></li>
  <li><a href="#storage-classes" id="toc-storage-classes" class="nav-link" data-scroll-target="#storage-classes">5.4.3. Storage classes</a></li>
  </ul></li>
  <li><a href="#ebs-vs-efs" id="toc-ebs-vs-efs" class="nav-link" data-scroll-target="#ebs-vs-efs">5.5. EBS vs EFS</a></li>
  </ul></li>
  <li><a href="#elb-and-asg" id="toc-elb-and-asg" class="nav-link" data-scroll-target="#elb-and-asg">6. ELB and ASG</a>
  <ul class="collapse">
  <li><a href="#scalability-and-availability" id="toc-scalability-and-availability" class="nav-link" data-scroll-target="#scalability-and-availability">6.1. Scalability and Availability</a></li>
  <li><a href="#elb" id="toc-elb" class="nav-link" data-scroll-target="#elb">6.2. ELB</a>
  <ul class="collapse">
  <li><a href="#load-balancing" id="toc-load-balancing" class="nav-link" data-scroll-target="#load-balancing">6.2.1. Load balancing</a></li>
  <li><a href="#security-groups-1" id="toc-security-groups-1" class="nav-link" data-scroll-target="#security-groups-1">6.2.2. Security Groups</a></li>
  <li><a href="#application-load-balancer-alb" id="toc-application-load-balancer-alb" class="nav-link" data-scroll-target="#application-load-balancer-alb">6.2.3. Application Load Balancer (ALB)</a></li>
  <li><a href="#network-load-balancer-nlb" id="toc-network-load-balancer-nlb" class="nav-link" data-scroll-target="#network-load-balancer-nlb">6.2.4. Network Load Balancer (NLB)</a></li>
  <li><a href="#gateway-load-balancer-gwlb" id="toc-gateway-load-balancer-gwlb" class="nav-link" data-scroll-target="#gateway-load-balancer-gwlb">6.2.5. Gateway Load Balancer (GWLB)</a></li>
  <li><a href="#sticky-sessions" id="toc-sticky-sessions" class="nav-link" data-scroll-target="#sticky-sessions">6.2.6. Sticky Sessions</a></li>
  <li><a href="#cross-zone-load-balancing" id="toc-cross-zone-load-balancing" class="nav-link" data-scroll-target="#cross-zone-load-balancing">6.2.7. Cross-Zone Load Balancing</a></li>
  <li><a href="#connection-draining" id="toc-connection-draining" class="nav-link" data-scroll-target="#connection-draining">6.2.8. Connection Draining</a></li>
  </ul></li>
  <li><a href="#ssl-certificates" id="toc-ssl-certificates" class="nav-link" data-scroll-target="#ssl-certificates">6.3. SSL Certificates</a>
  <ul class="collapse">
  <li><a href="#ssl-and-tls" id="toc-ssl-and-tls" class="nav-link" data-scroll-target="#ssl-and-tls">6.3.1. SSL and TLS</a></li>
  <li><a href="#sni" id="toc-sni" class="nav-link" data-scroll-target="#sni">6.3.2. SNI</a></li>
  </ul></li>
  <li><a href="#auto-scaling-groups-asg" id="toc-auto-scaling-groups-asg" class="nav-link" data-scroll-target="#auto-scaling-groups-asg">6.4. Auto Scaling Groups (ASG)</a>
  <ul class="collapse">
  <li><a href="#what-is-an-asg" id="toc-what-is-an-asg" class="nav-link" data-scroll-target="#what-is-an-asg">6.4.1. What is an ASG?</a></li>
  <li><a href="#scaling-policies" id="toc-scaling-policies" class="nav-link" data-scroll-target="#scaling-policies">6.4.2. Scaling Policies</a></li>
  <li><a href="#scaling-cooldown" id="toc-scaling-cooldown" class="nav-link" data-scroll-target="#scaling-cooldown">6.4.3. Scaling Cooldown</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#relational-databases" id="toc-relational-databases" class="nav-link" data-scroll-target="#relational-databases">7. Relational Databases</a>
  <ul class="collapse">
  <li><a href="#rds" id="toc-rds" class="nav-link" data-scroll-target="#rds">7.1. RDS</a>
  <ul class="collapse">
  <li><a href="#what-is-relational-database-service" id="toc-what-is-relational-database-service" class="nav-link" data-scroll-target="#what-is-relational-database-service">7.1.1 What is Relational Database Service?</a></li>
  <li><a href="#storage-auto-scaling" id="toc-storage-auto-scaling" class="nav-link" data-scroll-target="#storage-auto-scaling">7.1.2. Storage Auto-Scaling</a></li>
  <li><a href="#read-replicas" id="toc-read-replicas" class="nav-link" data-scroll-target="#read-replicas">7.1.3. Read Replicas</a></li>
  <li><a href="#multi-az" id="toc-multi-az" class="nav-link" data-scroll-target="#multi-az">7.1.4. Multi-AZ</a></li>
  <li><a href="#rds-custom" id="toc-rds-custom" class="nav-link" data-scroll-target="#rds-custom">7.1.5. RDS Custom</a></li>
  <li><a href="#rds-proxy" id="toc-rds-proxy" class="nav-link" data-scroll-target="#rds-proxy">7.1.6. RDS Proxy</a></li>
  </ul></li>
  <li><a href="#amazon-aurora" id="toc-amazon-aurora" class="nav-link" data-scroll-target="#amazon-aurora">7.2. Amazon Aurora</a>
  <ul class="collapse">
  <li><a href="#what-is-aurora" id="toc-what-is-aurora" class="nav-link" data-scroll-target="#what-is-aurora">7.2.1. What is Aurora?</a></li>
  <li><a href="#advanced-concepts" id="toc-advanced-concepts" class="nav-link" data-scroll-target="#advanced-concepts">7.2.2. Advanced Concepts</a></li>
  </ul></li>
  <li><a href="#backups-and-monitoring" id="toc-backups-and-monitoring" class="nav-link" data-scroll-target="#backups-and-monitoring">7.3. Backups and Monitoring</a>
  <ul class="collapse">
  <li><a href="#rds-1" id="toc-rds-1" class="nav-link" data-scroll-target="#rds-1">7.3.1. RDS</a></li>
  <li><a href="#aurora" id="toc-aurora" class="nav-link" data-scroll-target="#aurora">7.3.2. Aurora</a></li>
  <li><a href="#restore-options" id="toc-restore-options" class="nav-link" data-scroll-target="#restore-options">7.3.3. Restore Options</a></li>
  <li><a href="#aurora-database-cloning" id="toc-aurora-database-cloning" class="nav-link" data-scroll-target="#aurora-database-cloning">7.3.4 Aurora Database Cloning</a></li>
  </ul></li>
  <li><a href="#encryption" id="toc-encryption" class="nav-link" data-scroll-target="#encryption">7.4. Encryption</a></li>
  <li><a href="#elasticache" id="toc-elasticache" class="nav-link" data-scroll-target="#elasticache">7.5. ElastiCache</a>
  <ul class="collapse">
  <li><a href="#what-is-elasticache" id="toc-what-is-elasticache" class="nav-link" data-scroll-target="#what-is-elasticache">7.5.1. What is ElastiCache?</a></li>
  <li><a href="#redis-vs-memcached" id="toc-redis-vs-memcached" class="nav-link" data-scroll-target="#redis-vs-memcached">7.5.2. Redis vs Memcached</a></li>
  <li><a href="#elasticache-security" id="toc-elasticache-security" class="nav-link" data-scroll-target="#elasticache-security">7.5.3. ElastiCache Security</a></li>
  <li><a href="#common-port-numbers" id="toc-common-port-numbers" class="nav-link" data-scroll-target="#common-port-numbers">7.5.4. Common Port Numbers</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#route-53" id="toc-route-53" class="nav-link" data-scroll-target="#route-53">8. Route 53</a>
  <ul class="collapse">
  <li><a href="#dns" id="toc-dns" class="nav-link" data-scroll-target="#dns">8.1. DNS</a>
  <ul class="collapse">
  <li><a href="#what-is-dns" id="toc-what-is-dns" class="nav-link" data-scroll-target="#what-is-dns">8.1.1. What is DNS?</a></li>
  <li><a href="#how-dns-works" id="toc-how-dns-works" class="nav-link" data-scroll-target="#how-dns-works">8.1.2. How DNS Works</a></li>
  </ul></li>
  <li><a href="#route-53-1" id="toc-route-53-1" class="nav-link" data-scroll-target="#route-53-1">8.2. Route 53</a>
  <ul class="collapse">
  <li><a href="#records" id="toc-records" class="nav-link" data-scroll-target="#records">8.2.1. Records</a></li>
  <li><a href="#hosted-zones" id="toc-hosted-zones" class="nav-link" data-scroll-target="#hosted-zones">8.2.2. Hosted Zones</a></li>
  <li><a href="#creating-a-record" id="toc-creating-a-record" class="nav-link" data-scroll-target="#creating-a-record">8.2.3. Creating a Record</a></li>
  <li><a href="#ttl" id="toc-ttl" class="nav-link" data-scroll-target="#ttl">8.2.4. TTL</a></li>
  <li><a href="#cname-vs-alias-records" id="toc-cname-vs-alias-records" class="nav-link" data-scroll-target="#cname-vs-alias-records">8.2.5. CNAME vs Alias Records</a></li>
  </ul></li>
  <li><a href="#routing-policies" id="toc-routing-policies" class="nav-link" data-scroll-target="#routing-policies">8.3. Routing Policies</a></li>
  <li><a href="#health-checks" id="toc-health-checks" class="nav-link" data-scroll-target="#health-checks">8.4 Health Checks</a></li>
  <li><a href="#domain-registrar-vs-dns-service" id="toc-domain-registrar-vs-dns-service" class="nav-link" data-scroll-target="#domain-registrar-vs-dns-service">8.5. Domain Registrar vs DNS Service</a></li>
  </ul></li>
  <li><a href="#solutions-architect" id="toc-solutions-architect" class="nav-link" data-scroll-target="#solutions-architect">9. Solutions Architect</a>
  <ul class="collapse">
  <li><a href="#instantiating-applications-quickly" id="toc-instantiating-applications-quickly" class="nav-link" data-scroll-target="#instantiating-applications-quickly">9.1. Instantiating Applications Quickly</a></li>
  <li><a href="#elastic-beanstalk" id="toc-elastic-beanstalk" class="nav-link" data-scroll-target="#elastic-beanstalk">9.2. Elastic Beanstalk</a></li>
  <li><a href="#web-server-environment-vs-worker-environment" id="toc-web-server-environment-vs-worker-environment" class="nav-link" data-scroll-target="#web-server-environment-vs-worker-environment">9.3. Web Server Environment vs Worker Environment</a></li>
  <li><a href="#deployment-modes" id="toc-deployment-modes" class="nav-link" data-scroll-target="#deployment-modes">9.4. Deployment Modes</a></li>
  </ul></li>
  <li><a href="#s3" id="toc-s3" class="nav-link" data-scroll-target="#s3">10. S3</a>
  <ul class="collapse">
  <li><a href="#security" id="toc-security" class="nav-link" data-scroll-target="#security">10.2. Security</a></li>
  <li><a href="#s3-website" id="toc-s3-website" class="nav-link" data-scroll-target="#s3-website">10.3. S3 Website</a></li>
  <li><a href="#s3-versioning" id="toc-s3-versioning" class="nav-link" data-scroll-target="#s3-versioning">10.4. S3 Versioning</a></li>
  <li><a href="#replication" id="toc-replication" class="nav-link" data-scroll-target="#replication">10.5. Replication</a></li>
  <li><a href="#s3-storage-classes" id="toc-s3-storage-classes" class="nav-link" data-scroll-target="#s3-storage-classes">10.6. S3 Storage Classes</a></li>
  <li><a href="#lifecycle-rules" id="toc-lifecycle-rules" class="nav-link" data-scroll-target="#lifecycle-rules">10.7. Lifecycle Rules</a></li>
  <li><a href="#s3-requester-pays" id="toc-s3-requester-pays" class="nav-link" data-scroll-target="#s3-requester-pays">10.8. S3 Requester Pays</a></li>
  <li><a href="#s3-event-notifications" id="toc-s3-event-notifications" class="nav-link" data-scroll-target="#s3-event-notifications">10.9. S3 Event Notifications</a></li>
  <li><a href="#s3-performance" id="toc-s3-performance" class="nav-link" data-scroll-target="#s3-performance">10.10 S3 Performance</a></li>
  <li><a href="#s3-batch-operations" id="toc-s3-batch-operations" class="nav-link" data-scroll-target="#s3-batch-operations">10.11 S3 Batch Operations</a></li>
  <li><a href="#s3-storage-lens" id="toc-s3-storage-lens" class="nav-link" data-scroll-target="#s3-storage-lens">10.12 S3 Storage Lens</a></li>
  </ul></li>
  <li><a href="#s3-security" id="toc-s3-security" class="nav-link" data-scroll-target="#s3-security">11. S3 Security</a>
  <ul class="collapse">
  <li><a href="#object-encryption" id="toc-object-encryption" class="nav-link" data-scroll-target="#object-encryption">11.1. Object Encryption</a></li>
  <li><a href="#cors" id="toc-cors" class="nav-link" data-scroll-target="#cors">11.2. CORS</a></li>
  <li><a href="#mfa-delete" id="toc-mfa-delete" class="nav-link" data-scroll-target="#mfa-delete">11.3. MFA Delete</a></li>
  <li><a href="#s3-access-logs" id="toc-s3-access-logs" class="nav-link" data-scroll-target="#s3-access-logs">11.4 S3 Access Logs</a></li>
  <li><a href="#pre-signed-url" id="toc-pre-signed-url" class="nav-link" data-scroll-target="#pre-signed-url">11.5. Pre-signed URL</a></li>
  <li><a href="#s3-glacier-vault-lock" id="toc-s3-glacier-vault-lock" class="nav-link" data-scroll-target="#s3-glacier-vault-lock">11.6. S3 Glacier Vault Lock</a></li>
  <li><a href="#s3-object-lock" id="toc-s3-object-lock" class="nav-link" data-scroll-target="#s3-object-lock">11.7. S3 Object Lock</a></li>
  <li><a href="#s3-access-points" id="toc-s3-access-points" class="nav-link" data-scroll-target="#s3-access-points">11.8. S3 Access Points</a></li>
  <li><a href="#s3-object-lambda" id="toc-s3-object-lambda" class="nav-link" data-scroll-target="#s3-object-lambda">11.9. S3 Object Lambda</a></li>
  </ul></li>
  <li><a href="#cloudfront" id="toc-cloudfront" class="nav-link" data-scroll-target="#cloudfront">12. CloudFront</a>
  <ul class="collapse">
  <li><a href="#cloudfront-overview" id="toc-cloudfront-overview" class="nav-link" data-scroll-target="#cloudfront-overview">12.1 CloudFront Overview</a></li>
  <li><a href="#origin" id="toc-origin" class="nav-link" data-scroll-target="#origin">12.2. Origin</a></li>
  <li><a href="#cloudfront-geo-restriction" id="toc-cloudfront-geo-restriction" class="nav-link" data-scroll-target="#cloudfront-geo-restriction">12.3. CloudFront Geo Restriction</a></li>
  <li><a href="#price-classes" id="toc-price-classes" class="nav-link" data-scroll-target="#price-classes">12.4. Price Classes</a></li>
  <li><a href="#cache-invalidation" id="toc-cache-invalidation" class="nav-link" data-scroll-target="#cache-invalidation">12.5. Cache Invalidation</a></li>
  <li><a href="#aws-global-accelerator" id="toc-aws-global-accelerator" class="nav-link" data-scroll-target="#aws-global-accelerator">12.6 AWS Global Accelerator</a>
  <ul class="collapse">
  <li><a href="#unicast-ip-vs-anycast-ip" id="toc-unicast-ip-vs-anycast-ip" class="nav-link" data-scroll-target="#unicast-ip-vs-anycast-ip">12.6.1. Unicast IP vs Anycast IP</a></li>
  <li><a href="#how-global-accelerator-works" id="toc-how-global-accelerator-works" class="nav-link" data-scroll-target="#how-global-accelerator-works">12.6.2. How Global Accelerator Works</a></li>
  <li><a href="#global-accelerator-vs-cloudfront" id="toc-global-accelerator-vs-cloudfront" class="nav-link" data-scroll-target="#global-accelerator-vs-cloudfront">12.6.3. Global Accelerator vs CloudFront</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#aws-storage-extras" id="toc-aws-storage-extras" class="nav-link" data-scroll-target="#aws-storage-extras">13. AWS Storage Extras</a>
  <ul class="collapse">
  <li><a href="#aws-snowball" id="toc-aws-snowball" class="nav-link" data-scroll-target="#aws-snowball">13.1. AWS Snowball</a></li>
  <li><a href="#amazon-fsx" id="toc-amazon-fsx" class="nav-link" data-scroll-target="#amazon-fsx">13.2 Amazon FSx</a></li>
  <li><a href="#storage-gateway" id="toc-storage-gateway" class="nav-link" data-scroll-target="#storage-gateway">13.3. Storage Gateway</a></li>
  <li><a href="#aws-transfer-family" id="toc-aws-transfer-family" class="nav-link" data-scroll-target="#aws-transfer-family">13.4. AWS Transfer Family</a></li>
  <li><a href="#aws-datasync" id="toc-aws-datasync" class="nav-link" data-scroll-target="#aws-datasync">13.5. AWS DataSync</a></li>
  <li><a href="#comparison-of-storage-options" id="toc-comparison-of-storage-options" class="nav-link" data-scroll-target="#comparison-of-storage-options">13.6. Comparison of Storage Options</a></li>
  </ul></li>
  <li><a href="#messaging-and-integration" id="toc-messaging-and-integration" class="nav-link" data-scroll-target="#messaging-and-integration">14. Messaging and Integration</a>
  <ul class="collapse">
  <li><a href="#simple-queuing-service-sqs" id="toc-simple-queuing-service-sqs" class="nav-link" data-scroll-target="#simple-queuing-service-sqs">14.1. Simple Queuing Service (SQS)</a>
  <ul class="collapse">
  <li><a href="#overview-1" id="toc-overview-1" class="nav-link" data-scroll-target="#overview-1">14.1.1. Overview</a></li>
  <li><a href="#message-visibility-timeout" id="toc-message-visibility-timeout" class="nav-link" data-scroll-target="#message-visibility-timeout">14.1.2. Message Visibility Timeout</a></li>
  <li><a href="#long-polling" id="toc-long-polling" class="nav-link" data-scroll-target="#long-polling">14.1.3. Long Polling</a></li>
  <li><a href="#fifo-queues" id="toc-fifo-queues" class="nav-link" data-scroll-target="#fifo-queues">14.1.4. FIFO Queues</a></li>
  <li><a href="#sqs-with-asg" id="toc-sqs-with-asg" class="nav-link" data-scroll-target="#sqs-with-asg">14.1.5. SQS with ASG</a></li>
  </ul></li>
  <li><a href="#simple-notification-service-sns" id="toc-simple-notification-service-sns" class="nav-link" data-scroll-target="#simple-notification-service-sns">14.2. Simple Notification Service (SNS)</a>
  <ul class="collapse">
  <li><a href="#overview-2" id="toc-overview-2" class="nav-link" data-scroll-target="#overview-2">14.2.1. Overview</a></li>
  <li><a href="#fan-out-pattern" id="toc-fan-out-pattern" class="nav-link" data-scroll-target="#fan-out-pattern">14.2.2. Fan Out Pattern</a></li>
  <li><a href="#message-filtering" id="toc-message-filtering" class="nav-link" data-scroll-target="#message-filtering">14.2.3. Message Filtering</a></li>
  </ul></li>
  <li><a href="#kinesis-data-streams" id="toc-kinesis-data-streams" class="nav-link" data-scroll-target="#kinesis-data-streams">14.3. Kinesis Data Streams</a></li>
  <li><a href="#amazon-data-firehose" id="toc-amazon-data-firehose" class="nav-link" data-scroll-target="#amazon-data-firehose">14.4. Amazon Data Firehose</a>
  <ul class="collapse">
  <li><a href="#overview-3" id="toc-overview-3" class="nav-link" data-scroll-target="#overview-3">14.4.1. Overview</a></li>
  </ul></li>
  <li><a href="#comparison-of-messaging-and-integration-services" id="toc-comparison-of-messaging-and-integration-services" class="nav-link" data-scroll-target="#comparison-of-messaging-and-integration-services">14.5. Comparison of Messaging and Integration Services</a>
  <ul class="collapse">
  <li><a href="#kinesis-data-streams-vs-amazon-data-firehose" id="toc-kinesis-data-streams-vs-amazon-data-firehose" class="nav-link" data-scroll-target="#kinesis-data-streams-vs-amazon-data-firehose">14.5.1. Kinesis Data Streams vs Amazon Data Firehose</a></li>
  <li><a href="#sqs-vs-sns-vs-kinesis" id="toc-sqs-vs-sns-vs-kinesis" class="nav-link" data-scroll-target="#sqs-vs-sns-vs-kinesis">14.5.2. SQS vs SNS vs Kinesis</a></li>
  </ul></li>
  <li><a href="#amazon-mq" id="toc-amazon-mq" class="nav-link" data-scroll-target="#amazon-mq">14.6. Amazon MQ</a></li>
  </ul></li>
  <li><a href="#containers-on-aws" id="toc-containers-on-aws" class="nav-link" data-scroll-target="#containers-on-aws">15. Containers on AWS</a>
  <ul class="collapse">
  <li><a href="#docker" id="toc-docker" class="nav-link" data-scroll-target="#docker">15.1. Docker</a></li>
  <li><a href="#ecs" id="toc-ecs" class="nav-link" data-scroll-target="#ecs">15.2. ECS</a>
  <ul class="collapse">
  <li><a href="#ec2-launch-type" id="toc-ec2-launch-type" class="nav-link" data-scroll-target="#ec2-launch-type">15.2.1. EC2 Launch Type</a></li>
  <li><a href="#fargate-launch-type" id="toc-fargate-launch-type" class="nav-link" data-scroll-target="#fargate-launch-type">15.2.2. Fargate Launch Type</a></li>
  <li><a href="#ecs-service-auto-scaling" id="toc-ecs-service-auto-scaling" class="nav-link" data-scroll-target="#ecs-service-auto-scaling">15.2.3. ECS Service Auto Scaling</a></li>
  </ul></li>
  <li><a href="#common-ecs-architectures" id="toc-common-ecs-architectures" class="nav-link" data-scroll-target="#common-ecs-architectures">15.2.4. Common ECS Architectures</a></li>
  <li><a href="#ecr" id="toc-ecr" class="nav-link" data-scroll-target="#ecr">15.3. ECR</a></li>
  <li><a href="#eks" id="toc-eks" class="nav-link" data-scroll-target="#eks">15.4. EKS</a></li>
  <li><a href="#aws-app-runner" id="toc-aws-app-runner" class="nav-link" data-scroll-target="#aws-app-runner">15.5. AWS App Runner</a></li>
  <li><a href="#aws-app2container-a2c" id="toc-aws-app2container-a2c" class="nav-link" data-scroll-target="#aws-app2container-a2c">15.6. AWS App2Container (A2C)</a></li>
  </ul></li>
  <li><a href="#serverless" id="toc-serverless" class="nav-link" data-scroll-target="#serverless">16. Serverless</a>
  <ul class="collapse">
  <li><a href="#aws-lambda" id="toc-aws-lambda" class="nav-link" data-scroll-target="#aws-lambda">16.1. AWS Lambda</a>
  <ul class="collapse">
  <li><a href="#lambda-limits" id="toc-lambda-limits" class="nav-link" data-scroll-target="#lambda-limits">16.1.2. Lambda Limits</a></li>
  <li><a href="#lambda-concurrency-and-throttling" id="toc-lambda-concurrency-and-throttling" class="nav-link" data-scroll-target="#lambda-concurrency-and-throttling">16.1.3. Lambda Concurrency and Throttling</a></li>
  <li><a href="#cold-starts" id="toc-cold-starts" class="nav-link" data-scroll-target="#cold-starts">16.1.4. Cold Starts</a></li>
  <li><a href="#lambda-snapstart" id="toc-lambda-snapstart" class="nav-link" data-scroll-target="#lambda-snapstart">16.1.5. Lambda SnapStart</a></li>
  <li><a href="#customisation-at-the-edge" id="toc-customisation-at-the-edge" class="nav-link" data-scroll-target="#customisation-at-the-edge">16.1.6. Customisation at the Edge</a></li>
  <li><a href="#vpc" id="toc-vpc" class="nav-link" data-scroll-target="#vpc">16.1.7. VPC</a></li>
  </ul></li>
  <li><a href="#dynamodb" id="toc-dynamodb" class="nav-link" data-scroll-target="#dynamodb">16.2. DynamoDB</a>
  <ul class="collapse">
  <li><a href="#overview-5" id="toc-overview-5" class="nav-link" data-scroll-target="#overview-5">16.2.1. Overview</a></li>
  <li><a href="#dynamodb-accelerator-dax" id="toc-dynamodb-accelerator-dax" class="nav-link" data-scroll-target="#dynamodb-accelerator-dax">16.2.2. DynamoDB Accelerator (DAX)</a></li>
  <li><a href="#stream-processing" id="toc-stream-processing" class="nav-link" data-scroll-target="#stream-processing">16.2.3. Stream Processing</a></li>
  <li><a href="#global-tables" id="toc-global-tables" class="nav-link" data-scroll-target="#global-tables">16.2.4. Global Tables</a></li>
  <li><a href="#ttl-1" id="toc-ttl-1" class="nav-link" data-scroll-target="#ttl-1">16.2.5. TTL</a></li>
  <li><a href="#backups-for-disaster-recovery" id="toc-backups-for-disaster-recovery" class="nav-link" data-scroll-target="#backups-for-disaster-recovery">16.2.6. Backups for Disaster Recovery</a></li>
  <li><a href="#integration-with-s3" id="toc-integration-with-s3" class="nav-link" data-scroll-target="#integration-with-s3">16.2.7. Integration with S3</a></li>
  </ul></li>
  <li><a href="#api-gateway" id="toc-api-gateway" class="nav-link" data-scroll-target="#api-gateway">16.3. API Gateway</a>
  <ul class="collapse">
  <li><a href="#overview-6" id="toc-overview-6" class="nav-link" data-scroll-target="#overview-6">16.3.1. Overview</a></li>
  <li><a href="#security-1" id="toc-security-1" class="nav-link" data-scroll-target="#security-1">16.3.2. Security</a></li>
  </ul></li>
  <li><a href="#step-functions" id="toc-step-functions" class="nav-link" data-scroll-target="#step-functions">16.4. Step Functions</a></li>
  <li><a href="#cognito" id="toc-cognito" class="nav-link" data-scroll-target="#cognito">16.5. Cognito</a></li>
  </ul></li>
  <li><a href="#serverless-architecture-examples" id="toc-serverless-architecture-examples" class="nav-link" data-scroll-target="#serverless-architecture-examples">17. Serverless Architecture Examples</a>
  <ul class="collapse">
  <li><a href="#rest-api" id="toc-rest-api" class="nav-link" data-scroll-target="#rest-api">17.1. REST API</a></li>
  <li><a href="#giving-mobile-users-access-to-an-s3-bucket" id="toc-giving-mobile-users-access-to-an-s3-bucket" class="nav-link" data-scroll-target="#giving-mobile-users-access-to-an-s3-bucket">17.2. Giving Mobile Users Access to an S3 Bucket</a></li>
  <li><a href="#high-throughput-example" id="toc-high-throughput-example" class="nav-link" data-scroll-target="#high-throughput-example">17.3. High Throughput Example</a></li>
  </ul></li>
  <li><a href="#databases" id="toc-databases" class="nav-link" data-scroll-target="#databases">18. Databases</a>
  <ul class="collapse">
  <li><a href="#database-overview" id="toc-database-overview" class="nav-link" data-scroll-target="#database-overview">18.1. Database Overview</a></li>
  <li><a href="#rds-2" id="toc-rds-2" class="nav-link" data-scroll-target="#rds-2">18.2. RDS</a></li>
  <li><a href="#aurora-1" id="toc-aurora-1" class="nav-link" data-scroll-target="#aurora-1">18.3. Aurora</a></li>
  <li><a href="#elasticache-1" id="toc-elasticache-1" class="nav-link" data-scroll-target="#elasticache-1">18.4. ElastiCache</a></li>
  <li><a href="#dynamodb-1" id="toc-dynamodb-1" class="nav-link" data-scroll-target="#dynamodb-1">18.5. DynamoDB</a></li>
  <li><a href="#s3-1" id="toc-s3-1" class="nav-link" data-scroll-target="#s3-1">18.6. S3</a></li>
  <li><a href="#documentdb" id="toc-documentdb" class="nav-link" data-scroll-target="#documentdb">18.7. DocumentDB</a></li>
  <li><a href="#neptune" id="toc-neptune" class="nav-link" data-scroll-target="#neptune">18.8. Neptune</a></li>
  <li><a href="#amazon-keyspaces" id="toc-amazon-keyspaces" class="nav-link" data-scroll-target="#amazon-keyspaces">18.9. Amazon Keyspaces</a></li>
  <li><a href="#amazon-timestream" id="toc-amazon-timestream" class="nav-link" data-scroll-target="#amazon-timestream">18.10. Amazon Timestream</a></li>
  </ul></li>
  <li><a href="#data-analytics" id="toc-data-analytics" class="nav-link" data-scroll-target="#data-analytics">19. Data Analytics</a>
  <ul class="collapse">
  <li><a href="#athena" id="toc-athena" class="nav-link" data-scroll-target="#athena">19.1. Athena</a>
  <ul class="collapse">
  <li><a href="#overview-7" id="toc-overview-7" class="nav-link" data-scroll-target="#overview-7">19.1.1. Overview</a></li>
  <li><a href="#athena-performance-improvements" id="toc-athena-performance-improvements" class="nav-link" data-scroll-target="#athena-performance-improvements">19.1.2. Athena Performance Improvements</a></li>
  <li><a href="#federated-query" id="toc-federated-query" class="nav-link" data-scroll-target="#federated-query">19.1.3. Federated Query</a></li>
  </ul></li>
  <li><a href="#redshift" id="toc-redshift" class="nav-link" data-scroll-target="#redshift">19.2. Redshift</a>
  <ul class="collapse">
  <li><a href="#overview-8" id="toc-overview-8" class="nav-link" data-scroll-target="#overview-8">19.2.1. Overview</a></li>
  <li><a href="#disaster-recovery" id="toc-disaster-recovery" class="nav-link" data-scroll-target="#disaster-recovery">19.2.2. Disaster Recovery</a></li>
  <li><a href="#loading-data-into-redshift" id="toc-loading-data-into-redshift" class="nav-link" data-scroll-target="#loading-data-into-redshift">19.2.2. Loading Data into Redshift</a></li>
  <li><a href="#redshift-spectrum" id="toc-redshift-spectrum" class="nav-link" data-scroll-target="#redshift-spectrum">19.2.3. Redshift Spectrum</a></li>
  </ul></li>
  <li><a href="#amazon-opensearch" id="toc-amazon-opensearch" class="nav-link" data-scroll-target="#amazon-opensearch">19.3. Amazon OpenSearch</a></li>
  <li><a href="#emr" id="toc-emr" class="nav-link" data-scroll-target="#emr">19.4. EMR</a></li>
  <li><a href="#quicksight" id="toc-quicksight" class="nav-link" data-scroll-target="#quicksight">19.5. QuickSight</a>
  <ul class="collapse">
  <li><a href="#overview-9" id="toc-overview-9" class="nav-link" data-scroll-target="#overview-9">19.5.1. Overview</a></li>
  <li><a href="#dashboard-and-analysis" id="toc-dashboard-and-analysis" class="nav-link" data-scroll-target="#dashboard-and-analysis">19.5.2. Dashboard and Analysis</a></li>
  </ul></li>
  <li><a href="#aws-glue" id="toc-aws-glue" class="nav-link" data-scroll-target="#aws-glue">19.6. AWS Glue</a>
  <ul class="collapse">
  <li><a href="#overview-10" id="toc-overview-10" class="nav-link" data-scroll-target="#overview-10">19.6.1. Overview</a></li>
  <li><a href="#glue-data-catalog" id="toc-glue-data-catalog" class="nav-link" data-scroll-target="#glue-data-catalog">19.6.2. Glue Data Catalog</a></li>
  </ul></li>
  <li><a href="#aws-lake-formation" id="toc-aws-lake-formation" class="nav-link" data-scroll-target="#aws-lake-formation">19.7. AWS Lake Formation</a></li>
  <li><a href="#amazon-managed-service-for-apache-flink" id="toc-amazon-managed-service-for-apache-flink" class="nav-link" data-scroll-target="#amazon-managed-service-for-apache-flink">19.8. Amazon Managed Service for Apache Flink</a></li>
  <li><a href="#amazon-managed-streaming-for-apache-kafka" id="toc-amazon-managed-streaming-for-apache-kafka" class="nav-link" data-scroll-target="#amazon-managed-streaming-for-apache-kafka">19.9. Amazon Managed Streaming for Apache Kafka</a></li>
  <li><a href="#big-data-ingestion-pipeline" id="toc-big-data-ingestion-pipeline" class="nav-link" data-scroll-target="#big-data-ingestion-pipeline">19.10. Big Data Ingestion Pipeline</a></li>
  </ul></li>
  <li><a href="#machine-learning" id="toc-machine-learning" class="nav-link" data-scroll-target="#machine-learning">20. Machine Learning</a>
  <ul class="collapse">
  <li><a href="#amazon-rekognition" id="toc-amazon-rekognition" class="nav-link" data-scroll-target="#amazon-rekognition">20.1. Amazon Rekognition</a></li>
  <li><a href="#amazon-transcribe" id="toc-amazon-transcribe" class="nav-link" data-scroll-target="#amazon-transcribe">20.2. Amazon Transcribe</a></li>
  <li><a href="#polly" id="toc-polly" class="nav-link" data-scroll-target="#polly">20.3. Polly</a></li>
  <li><a href="#translate" id="toc-translate" class="nav-link" data-scroll-target="#translate">20.4. Translate</a></li>
  <li><a href="#lex-and-connect" id="toc-lex-and-connect" class="nav-link" data-scroll-target="#lex-and-connect">20.5. Lex and Connect</a></li>
  <li><a href="#amazon-comprehend" id="toc-amazon-comprehend" class="nav-link" data-scroll-target="#amazon-comprehend">20.6. Amazon Comprehend</a></li>
  <li><a href="#sagemaker-ai" id="toc-sagemaker-ai" class="nav-link" data-scroll-target="#sagemaker-ai">20.7. SageMaker AI</a></li>
  <li><a href="#amazon-kendra" id="toc-amazon-kendra" class="nav-link" data-scroll-target="#amazon-kendra">20.8. Amazon Kendra</a></li>
  <li><a href="#amazon-personalize" id="toc-amazon-personalize" class="nav-link" data-scroll-target="#amazon-personalize">20.9. Amazon Personalize</a></li>
  <li><a href="#amazon-textract" id="toc-amazon-textract" class="nav-link" data-scroll-target="#amazon-textract">20.10 Amazon Textract</a></li>
  </ul></li>
  <li><a href="#monitoring" id="toc-monitoring" class="nav-link" data-scroll-target="#monitoring">21. Monitoring</a>
  <ul class="collapse">
  <li><a href="#cloudwatch" id="toc-cloudwatch" class="nav-link" data-scroll-target="#cloudwatch">21.1. CloudWatch</a>
  <ul class="collapse">
  <li><a href="#cloudwatch-metrics" id="toc-cloudwatch-metrics" class="nav-link" data-scroll-target="#cloudwatch-metrics">21.1.1. CloudWatch Metrics</a></li>
  <li><a href="#cloudwatch-logs" id="toc-cloudwatch-logs" class="nav-link" data-scroll-target="#cloudwatch-logs">21.1.3. CloudWatch Logs</a></li>
  <li><a href="#cloudwatch-agent" id="toc-cloudwatch-agent" class="nav-link" data-scroll-target="#cloudwatch-agent">21.1.4. CloudWatch Agent</a></li>
  <li><a href="#cloudwatch-alarms" id="toc-cloudwatch-alarms" class="nav-link" data-scroll-target="#cloudwatch-alarms">21.1.5. CloudWatch Alarms</a></li>
  <li><a href="#amazon-eventbridge" id="toc-amazon-eventbridge" class="nav-link" data-scroll-target="#amazon-eventbridge">21.1.6. Amazon EventBridge</a></li>
  <li><a href="#cloudwatch-insights" id="toc-cloudwatch-insights" class="nav-link" data-scroll-target="#cloudwatch-insights">21.1.7. CloudWatch Insights</a></li>
  </ul></li>
  <li><a href="#cloudtrail" id="toc-cloudtrail" class="nav-link" data-scroll-target="#cloudtrail">21.2. CloudTrail</a></li>
  <li><a href="#aws-config" id="toc-aws-config" class="nav-link" data-scroll-target="#aws-config">21.3. AWS Config</a>
  <ul class="collapse">
  <li><a href="#config-rules" id="toc-config-rules" class="nav-link" data-scroll-target="#config-rules">21.3.1. Config Rules</a></li>
  <li><a href="#remediations" id="toc-remediations" class="nav-link" data-scroll-target="#remediations">21.3.2. Remediations</a></li>
  </ul></li>
  <li><a href="#cloudwatch-vs-cloudtrail-vs-config" id="toc-cloudwatch-vs-cloudtrail-vs-config" class="nav-link" data-scroll-target="#cloudwatch-vs-cloudtrail-vs-config">21.4. CloudWatch vs CloudTrail vs Config</a></li>
  </ul></li>
  <li><a href="#advanced-iam" id="toc-advanced-iam" class="nav-link" data-scroll-target="#advanced-iam">22. Advanced IAM</a>
  <ul class="collapse">
  <li><a href="#aws-organisations" id="toc-aws-organisations" class="nav-link" data-scroll-target="#aws-organisations">22.1. AWS Organisations</a>
  <ul class="collapse">
  <li><a href="#tag-policies" id="toc-tag-policies" class="nav-link" data-scroll-target="#tag-policies">22.1.1. Tag Policies</a></li>
  <li><a href="#iam-conditions" id="toc-iam-conditions" class="nav-link" data-scroll-target="#iam-conditions">22.1.2. IAM Conditions</a></li>
  <li><a href="#iam-roles-vs-resource-based-policies" id="toc-iam-roles-vs-resource-based-policies" class="nav-link" data-scroll-target="#iam-roles-vs-resource-based-policies">22.1.3. IAM roles vs Resource-Based Policies</a></li>
  <li><a href="#iam-permission-boundaries" id="toc-iam-permission-boundaries" class="nav-link" data-scroll-target="#iam-permission-boundaries">22.1.4. IAM Permission Boundaries</a></li>
  </ul></li>
  <li><a href="#aws-iam-identity-centre" id="toc-aws-iam-identity-centre" class="nav-link" data-scroll-target="#aws-iam-identity-centre">22.2. AWS IAM Identity Centre</a></li>
  <li><a href="#aws-directory-services" id="toc-aws-directory-services" class="nav-link" data-scroll-target="#aws-directory-services">22.3. AWS Directory Services</a>
  <ul class="collapse">
  <li><a href="#active-directory" id="toc-active-directory" class="nav-link" data-scroll-target="#active-directory">22.3.1. Active Directory</a></li>
  <li><a href="#aws-directory-services-1" id="toc-aws-directory-services-1" class="nav-link" data-scroll-target="#aws-directory-services-1">22.3.2. AWS Directory Services</a></li>
  <li><a href="#integrating-ad-with-iam-identity-centre" id="toc-integrating-ad-with-iam-identity-centre" class="nav-link" data-scroll-target="#integrating-ad-with-iam-identity-centre">22.3.3. Integrating AD with IAM Identity Centre</a></li>
  </ul></li>
  <li><a href="#aws-control-tower" id="toc-aws-control-tower" class="nav-link" data-scroll-target="#aws-control-tower">22.4. AWS Control Tower</a></li>
  </ul></li>
  <li><a href="#security-and-encryption" id="toc-security-and-encryption" class="nav-link" data-scroll-target="#security-and-encryption">23. Security and Encryption</a>
  <ul class="collapse">
  <li><a href="#encryption-1" id="toc-encryption-1" class="nav-link" data-scroll-target="#encryption-1">23.1. Encryption</a>
  <ul class="collapse">
  <li><a href="#encryption-101" id="toc-encryption-101" class="nav-link" data-scroll-target="#encryption-101">23.1.1 Encryption 101</a></li>
  </ul></li>
  <li><a href="#kms" id="toc-kms" class="nav-link" data-scroll-target="#kms">23.2. KMS</a>
  <ul class="collapse">
  <li><a href="#kms-overview" id="toc-kms-overview" class="nav-link" data-scroll-target="#kms-overview">23.2.1. KMS Overview</a></li>
  <li><a href="#kms-key-policies" id="toc-kms-key-policies" class="nav-link" data-scroll-target="#kms-key-policies">23.2.2. KMS Key Policies</a></li>
  <li><a href="#multi-region-keys" id="toc-multi-region-keys" class="nav-link" data-scroll-target="#multi-region-keys">23.2.3. Multi-region Keys</a></li>
  <li><a href="#s3-replication-encryption-considerations" id="toc-s3-replication-encryption-considerations" class="nav-link" data-scroll-target="#s3-replication-encryption-considerations">23.3.4. S3 Replication Encryption Considerations</a></li>
  <li><a href="#sharing-an-ami-encrypted-with-kms" id="toc-sharing-an-ami-encrypted-with-kms" class="nav-link" data-scroll-target="#sharing-an-ami-encrypted-with-kms">23.3.5. Sharing an AMI Encrypted with KMS</a></li>
  </ul></li>
  <li><a href="#ssm-parameter-store" id="toc-ssm-parameter-store" class="nav-link" data-scroll-target="#ssm-parameter-store">23.3. SSM Parameter Store</a>
  <ul class="collapse">
  <li><a href="#overview-11" id="toc-overview-11" class="nav-link" data-scroll-target="#overview-11">23.3.1. Overview</a></li>
  <li><a href="#parameter-policies" id="toc-parameter-policies" class="nav-link" data-scroll-target="#parameter-policies">23.3.2. Parameter Policies</a></li>
  </ul></li>
  <li><a href="#aws-secrets-manager" id="toc-aws-secrets-manager" class="nav-link" data-scroll-target="#aws-secrets-manager">23.4. AWS Secrets Manager</a>
  <ul class="collapse">
  <li><a href="#overview-12" id="toc-overview-12" class="nav-link" data-scroll-target="#overview-12">23.4.1. Overview</a></li>
  <li><a href="#multi-region-secrets" id="toc-multi-region-secrets" class="nav-link" data-scroll-target="#multi-region-secrets">24.4.2. Multi-region Secrets</a></li>
  </ul></li>
  <li><a href="#aws-certificate-manager-acm" id="toc-aws-certificate-manager-acm" class="nav-link" data-scroll-target="#aws-certificate-manager-acm">23.5. AWS Certificate Manager (ACM)</a>
  <ul class="collapse">
  <li><a href="#overview-13" id="toc-overview-13" class="nav-link" data-scroll-target="#overview-13">23.5.1. Overview</a></li>
  <li><a href="#requesting-public-certificates" id="toc-requesting-public-certificates" class="nav-link" data-scroll-target="#requesting-public-certificates">23.5.2. Requesting Public Certificates</a></li>
  </ul></li>
  <li><a href="#web-application-firewall-waf" id="toc-web-application-firewall-waf" class="nav-link" data-scroll-target="#web-application-firewall-waf">23.6. Web Application Firewall (WAF)</a>
  <ul class="collapse">
  <li><a href="#overview-14" id="toc-overview-14" class="nav-link" data-scroll-target="#overview-14">23.6.1. Overview</a></li>
  <li><a href="#web-acl" id="toc-web-acl" class="nav-link" data-scroll-target="#web-acl">23.6.2. Web ACL</a></li>
  </ul></li>
  <li><a href="#aws-shield" id="toc-aws-shield" class="nav-link" data-scroll-target="#aws-shield">23.7. AWS Shield</a></li>
  <li><a href="#aws-firewall-manager" id="toc-aws-firewall-manager" class="nav-link" data-scroll-target="#aws-firewall-manager">23.8. AWS Firewall Manager</a></li>
  <li><a href="#best-practices-for-ddos-resiliency" id="toc-best-practices-for-ddos-resiliency" class="nav-link" data-scroll-target="#best-practices-for-ddos-resiliency">23.9. Best Practices for DDoS Resiliency</a></li>
  <li><a href="#amazon-guardduty" id="toc-amazon-guardduty" class="nav-link" data-scroll-target="#amazon-guardduty">23.10. Amazon GuardDuty</a></li>
  <li><a href="#amazon-inspector" id="toc-amazon-inspector" class="nav-link" data-scroll-target="#amazon-inspector">23.11. Amazon Inspector</a></li>
  <li><a href="#amazon-macie" id="toc-amazon-macie" class="nav-link" data-scroll-target="#amazon-macie">23.12. Amazon Macie</a></li>
  </ul></li>
  <li><a href="#vpc-1" id="toc-vpc-1" class="nav-link" data-scroll-target="#vpc-1">24. VPC</a>
  <ul class="collapse">
  <li><a href="#cidr-private-ip-public-ip" id="toc-cidr-private-ip-public-ip" class="nav-link" data-scroll-target="#cidr-private-ip-public-ip">24.1. CIDR, Private IP, Public IP</a>
  <ul class="collapse">
  <li><a href="#cidr" id="toc-cidr" class="nav-link" data-scroll-target="#cidr">24.1.1. CIDR</a></li>
  <li><a href="#public-vs-private-ipv4" id="toc-public-vs-private-ipv4" class="nav-link" data-scroll-target="#public-vs-private-ipv4">24.1.2. Public vs Private IPv4</a></li>
  </ul></li>
  <li><a href="#default-vpc" id="toc-default-vpc" class="nav-link" data-scroll-target="#default-vpc">24.2. Default VPC</a>
  <ul class="collapse">
  <li><a href="#overview-15" id="toc-overview-15" class="nav-link" data-scroll-target="#overview-15">24.2.1. Overview</a></li>
  <li><a href="#creating-our-own-vpc" id="toc-creating-our-own-vpc" class="nav-link" data-scroll-target="#creating-our-own-vpc">24.2.2. Creating Our Own VPC</a></li>
  <li><a href="#adding-subnets" id="toc-adding-subnets" class="nav-link" data-scroll-target="#adding-subnets">24.2.3. Adding Subnets</a></li>
  <li><a href="#internet-gateway-igw" id="toc-internet-gateway-igw" class="nav-link" data-scroll-target="#internet-gateway-igw">24.2.4. Internet Gateway (IGW)</a></li>
  <li><a href="#bastion-hosts" id="toc-bastion-hosts" class="nav-link" data-scroll-target="#bastion-hosts">24.2.3. Bastion Hosts</a></li>
  </ul></li>
  <li><a href="#nat" id="toc-nat" class="nav-link" data-scroll-target="#nat">24.3. NAT</a>
  <ul class="collapse">
  <li><a href="#nat-instances" id="toc-nat-instances" class="nav-link" data-scroll-target="#nat-instances">24.3.1. NAT Instances</a></li>
  <li><a href="#nat-gateway" id="toc-nat-gateway" class="nav-link" data-scroll-target="#nat-gateway">24.3.2. NAT Gateway</a></li>
  </ul></li>
  <li><a href="#security-groups-and-network-acl" id="toc-security-groups-and-network-acl" class="nav-link" data-scroll-target="#security-groups-and-network-acl">24.4. Security Groups and Network ACL</a>
  <ul class="collapse">
  <li><a href="#overview-16" id="toc-overview-16" class="nav-link" data-scroll-target="#overview-16">24.4.1. Overview</a></li>
  <li><a href="#default-nacl" id="toc-default-nacl" class="nav-link" data-scroll-target="#default-nacl">24.4.2. Default NACL</a></li>
  <li><a href="#ephemeral-ports" id="toc-ephemeral-ports" class="nav-link" data-scroll-target="#ephemeral-ports">24.4.3. Ephemeral Ports</a></li>
  </ul></li>
  <li><a href="#vpc-peering" id="toc-vpc-peering" class="nav-link" data-scroll-target="#vpc-peering">24.5. VPC Peering</a></li>
  <li><a href="#vpc-endpoints" id="toc-vpc-endpoints" class="nav-link" data-scroll-target="#vpc-endpoints">24.6. VPC Endpoints</a></li>
  <li><a href="#vpc-flow-logs" id="toc-vpc-flow-logs" class="nav-link" data-scroll-target="#vpc-flow-logs">24.7. VPC Flow Logs</a></li>
  <li><a href="#aws-site-to-site-vpn" id="toc-aws-site-to-site-vpn" class="nav-link" data-scroll-target="#aws-site-to-site-vpn">24.8. AWS Site-to-Site VPN</a>
  <ul class="collapse">
  <li><a href="#overview-17" id="toc-overview-17" class="nav-link" data-scroll-target="#overview-17">24.8.1. Overview</a></li>
  <li><a href="#aws-vpn-cloudhub" id="toc-aws-vpn-cloudhub" class="nav-link" data-scroll-target="#aws-vpn-cloudhub">24.8.2. AWS VPN CloudHub</a></li>
  </ul></li>
  <li><a href="#direct-connect-dx" id="toc-direct-connect-dx" class="nav-link" data-scroll-target="#direct-connect-dx">24.9. Direct Connect (DX)</a>
  <ul class="collapse">
  <li><a href="#overview-18" id="toc-overview-18" class="nav-link" data-scroll-target="#overview-18">24.9.1. Overview</a></li>
  <li><a href="#encryption-2" id="toc-encryption-2" class="nav-link" data-scroll-target="#encryption-2">24.9.2. Encryption</a></li>
  <li><a href="#resiliency" id="toc-resiliency" class="nav-link" data-scroll-target="#resiliency">24.9.3. Resiliency</a></li>
  <li><a href="#direct-connect-gateway" id="toc-direct-connect-gateway" class="nav-link" data-scroll-target="#direct-connect-gateway">24.9.4. Direct Connect Gateway</a></li>
  <li><a href="#dx-site-to-site-vpn" id="toc-dx-site-to-site-vpn" class="nav-link" data-scroll-target="#dx-site-to-site-vpn">24.9.5. DX + Site-to-Site VPN</a></li>
  </ul></li>
  <li><a href="#transit-gateway" id="toc-transit-gateway" class="nav-link" data-scroll-target="#transit-gateway">24.10. Transit Gateway</a></li>
  <li><a href="#vpc-traffic-mirroring" id="toc-vpc-traffic-mirroring" class="nav-link" data-scroll-target="#vpc-traffic-mirroring">24.11. VPC Traffic Mirroring</a></li>
  <li><a href="#ipv6-for-vpc" id="toc-ipv6-for-vpc" class="nav-link" data-scroll-target="#ipv6-for-vpc">24.12. IPv6 for VPC</a>
  <ul class="collapse">
  <li><a href="#overview-19" id="toc-overview-19" class="nav-link" data-scroll-target="#overview-19">24.12.1. Overview</a></li>
  <li><a href="#egress-only-internet-gateway" id="toc-egress-only-internet-gateway" class="nav-link" data-scroll-target="#egress-only-internet-gateway">24.12.2. Egress-only Internet Gateway</a></li>
  </ul></li>
  <li><a href="#aws-network-firewall" id="toc-aws-network-firewall" class="nav-link" data-scroll-target="#aws-network-firewall">24.13. AWS Network Firewall</a></li>
  </ul></li>
  <li><a href="#disaster-recovery-and-migrations" id="toc-disaster-recovery-and-migrations" class="nav-link" data-scroll-target="#disaster-recovery-and-migrations">25. Disaster Recovery and Migrations</a>
  <ul class="collapse">
  <li><a href="#disaster-recovery-overview" id="toc-disaster-recovery-overview" class="nav-link" data-scroll-target="#disaster-recovery-overview">25.1. Disaster Recovery Overview</a></li>
  <li><a href="#disaster-recovery---practical-tips" id="toc-disaster-recovery---practical-tips" class="nav-link" data-scroll-target="#disaster-recovery---practical-tips">25.2. Disaster Recovery - Practical Tips</a></li>
  <li><a href="#database-migration-service-dms" id="toc-database-migration-service-dms" class="nav-link" data-scroll-target="#database-migration-service-dms">25.3. Database Migration Service (DMS)</a>
  <ul class="collapse">
  <li><a href="#overview-20" id="toc-overview-20" class="nav-link" data-scroll-target="#overview-20">25.3.1 Overview</a></li>
  <li><a href="#aws-schema-conversion-tool-sct" id="toc-aws-schema-conversion-tool-sct" class="nav-link" data-scroll-target="#aws-schema-conversion-tool-sct">25.3.2. AWS Schema Conversion Tool (SCT)</a></li>
  <li><a href="#continuous-replication" id="toc-continuous-replication" class="nav-link" data-scroll-target="#continuous-replication">25.3.3. Continuous Replication</a></li>
  <li><a href="#multi-az-deployment" id="toc-multi-az-deployment" class="nav-link" data-scroll-target="#multi-az-deployment">25.3.4. Multi-AZ Deployment</a></li>
  <li><a href="#rds-and-aurora-mysql-migrations" id="toc-rds-and-aurora-mysql-migrations" class="nav-link" data-scroll-target="#rds-and-aurora-mysql-migrations">25.3.5. RDS and Aurora MySQL Migrations</a></li>
  </ul></li>
  <li><a href="#on-premises-strategy-with-aws" id="toc-on-premises-strategy-with-aws" class="nav-link" data-scroll-target="#on-premises-strategy-with-aws">25.4. On-Premises Strategy with AWS</a></li>
  <li><a href="#aws-backup" id="toc-aws-backup" class="nav-link" data-scroll-target="#aws-backup">25.5. AWS Backup</a></li>
  <li><a href="#aws-migration-service-mgn" id="toc-aws-migration-service-mgn" class="nav-link" data-scroll-target="#aws-migration-service-mgn">25.6. AWS Migration Service (MGN)</a>
  <ul class="collapse">
  <li><a href="#aws-application-discovery-service" id="toc-aws-application-discovery-service" class="nav-link" data-scroll-target="#aws-application-discovery-service">25.6.1. AWS Application Discovery Service</a></li>
  <li><a href="#aws-migration-service" id="toc-aws-migration-service" class="nav-link" data-scroll-target="#aws-migration-service">25.6.2. AWS Migration Service</a></li>
  <li><a href="#transfer-large-amounts-of-data-into-aws" id="toc-transfer-large-amounts-of-data-into-aws" class="nav-link" data-scroll-target="#transfer-large-amounts-of-data-into-aws">25.6.3. Transfer Large Amounts of Data into AWS</a></li>
  <li><a href="#vmware-cloud-on-aws" id="toc-vmware-cloud-on-aws" class="nav-link" data-scroll-target="#vmware-cloud-on-aws">25.6.4 VMWare Cloud on AWS</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#more-solution-architectures" id="toc-more-solution-architectures" class="nav-link" data-scroll-target="#more-solution-architectures">26. More Solution Architectures</a>
  <ul class="collapse">
  <li><a href="#event-processing" id="toc-event-processing" class="nav-link" data-scroll-target="#event-processing">26.1. Event Processing</a></li>
  <li><a href="#caching-strategies" id="toc-caching-strategies" class="nav-link" data-scroll-target="#caching-strategies">26.2. Caching Strategies</a></li>
  <li><a href="#blocking-an-ip-address" id="toc-blocking-an-ip-address" class="nav-link" data-scroll-target="#blocking-an-ip-address">26.3. Blocking an IP Address</a></li>
  <li><a href="#high-performance-computing" id="toc-high-performance-computing" class="nav-link" data-scroll-target="#high-performance-computing">26.4. High Performance Computing</a></li>
  <li><a href="#creating-a-highly-available-ec2-instance" id="toc-creating-a-highly-available-ec2-instance" class="nav-link" data-scroll-target="#creating-a-highly-available-ec2-instance">26.5. Creating a Highly Available EC2 Instance</a></li>
  </ul></li>
  <li><a href="#other-services" id="toc-other-services" class="nav-link" data-scroll-target="#other-services">27. Other Services</a>
  <ul class="collapse">
  <li><a href="#cloudformation" id="toc-cloudformation" class="nav-link" data-scroll-target="#cloudformation">27.1. CloudFormation</a>
  <ul class="collapse">
  <li><a href="#overview-21" id="toc-overview-21" class="nav-link" data-scroll-target="#overview-21">27.1.1. Overview</a></li>
  <li><a href="#cloudformation-service-roles" id="toc-cloudformation-service-roles" class="nav-link" data-scroll-target="#cloudformation-service-roles">27.1.2. CloudFormation Service Roles</a></li>
  </ul></li>
  <li><a href="#simple-email-service-ses" id="toc-simple-email-service-ses" class="nav-link" data-scroll-target="#simple-email-service-ses">27.2. Simple Email Service (SES)</a></li>
  <li><a href="#amazon-pinpoint" id="toc-amazon-pinpoint" class="nav-link" data-scroll-target="#amazon-pinpoint">27.3. Amazon Pinpoint</a></li>
  <li><a href="#system-manager-ssm" id="toc-system-manager-ssm" class="nav-link" data-scroll-target="#system-manager-ssm">27.4. System Manager (SSM)</a>
  <ul class="collapse">
  <li><a href="#ssm-session-manager" id="toc-ssm-session-manager" class="nav-link" data-scroll-target="#ssm-session-manager">27.4.1. SSM Session Manager</a></li>
  <li><a href="#other-ssm-commands" id="toc-other-ssm-commands" class="nav-link" data-scroll-target="#other-ssm-commands">27.4.2. Other SSM Commands</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="getting-started" class="level1">
<h1>1. Getting Started</h1>
<section id="aws-global-infrastructure" class="level2">
<h2 class="anchored" data-anchor-id="aws-global-infrastructure">1.1. AWS Global Infrastructure</h2>
<p><strong>Regions</strong> are geographic locations, e.g.&nbsp;europe-west-3, us-east-1, etc.</p>
<p>How should we choose a region?</p>
<ul>
<li>Compliance - data governance rules may require data within a certain location</li>
<li>Proximity to reduce latency</li>
<li>Available services vary by region</li>
<li>Pricing varies by region</li>
</ul>
<p>Each region can have multiple <strong>Availability Zones</strong>. There are usually between 3 and 6, e.g.&nbsp;ap-southeast-2a, ap-southeast-2b and ap-southeast-2c.</p>
<p>Each AZ contains multiple <strong>data centers</strong> with redundant power, networking and connectivity.</p>
<p>There are multiple <strong>Edge Locations/Points of Presence</strong>; 400 locations around the world.</p>
</section>
<section id="tour-of-the-console" class="level2">
<h2 class="anchored" data-anchor-id="tour-of-the-console">1.2. Tour of the Console</h2>
<p>Some services are <em>global</em>: IAM, Route 53, CloudFront, WAF</p>
<p>Most are <em>region-scoped</em>: EC2, Elastic Beanstalk, Lambda, Rekognition</p>
<p>The <strong>region selector</strong> is in the top right. The <strong>service selector</strong> in top left, or alternatively use search bar.</p>
</section>
<section id="aws-billing" class="level2">
<h2 class="anchored" data-anchor-id="aws-billing">1.3. AWS Billing</h2>
<p>Click on <strong>Billing and Cost Management</strong> in the top right of the screen.</p>
<p>This needs to first be activated for administrator IAM users. From the root account: <code>Account (top right) -&gt; IAM user and role access to billing information -&gt; tick the Activate IAM Access checkbox</code>.</p>
<ul>
<li><strong>Bills</strong> tab - You can see bills per service and per region.</li>
<li><strong>Free Tier</strong> tab - Check what the free tier quotas are, and your current and forecasted usage.</li>
<li><strong>Budgets</strong> tab - set a budget. <code>Use a template -&gt; Zero spend budget -&gt; Budget name and email recipients</code>. This will alert as soon as you spend any money. There is also a monthly cost budget for regular reporting.</li>
</ul>
</section>
</section>
<section id="iam" class="level1">
<h1>2. IAM</h1>
<section id="overview" class="level2">
<h2 class="anchored" data-anchor-id="overview">2.1. Overview</h2>
<p>Identity and access management. This is a <em>global</em> service.</p>
<p>The root account is created by default. It shouldnt be used or shared; just use it to create users.</p>
<p><strong>Users</strong> are people within the org and can be grouped. <strong>Groups</strong> cannot contain other groups. A user can belong to multiple groups (or none, but this is generally not best practice).</p>
</section>
<section id="permissions" class="level2">
<h2 class="anchored" data-anchor-id="permissions">2.2. Permissions</h2>
<p>Users or groups can be assigned <strong>policies</strong> which are specified as a JSON document.</p>
<p><strong>Least privilege principle</strong> means you shouldnt give a user more permissions than they need.</p>
</section>
<section id="creating-users-and-groups" class="level2">
<h2 class="anchored" data-anchor-id="creating-users-and-groups">2.3. Creating Users and Groups</h2>
<p>In the IAM dashboard, there is a <code>Users</code> tab.</p>
<p>There is a <code>Create User</code> button. We give them a user name and can choose a password (or autogenerate a password if this is for another user).</p>
<p>Then we can add permissions directly, or create a group and add the user.</p>
<p>To <strong>create a group</strong>, specify the name and permissions policy.</p>
<p><strong>Tags</strong> are optional key-value pairs we can add to assign custom metadata to different resources.</p>
<p>We can also create an <strong>account alias</strong> in IAM to simplify the account sign in, rather than having to remember the account ID.</p>
<p>When signing in to the AWS console, you can choose to log in as root user or IAM user.</p>
</section>
<section id="iam-policies" class="level2">
<h2 class="anchored" data-anchor-id="iam-policies">2.4. IAM Policies</h2>
<p>Policies can be <strong>attached to groups</strong>, or assigned as <strong>inline policies</strong> to a specific user. Groups are best practice.</p>
<p>Components of JSON document:</p>
<ul>
<li>Version: Policy language version (date)</li>
<li>Id: Identifier for the policy</li>
<li>Statement: Specifies the permissions</li>
</ul>
<p>Each statement consists of:</p>
<ul>
<li>Sid: Optional identifier for the statement</li>
<li>Effect: Allow or Deny</li>
<li>Principal: The account/user/role that this policy applies to</li>
<li>Action: List of actions that this policy allows or denies</li>
<li>Resource: What the actions apply to, eg a bucket</li>
<li>Condition: Optional, conditions when this policy should apply</li>
</ul>
<p>* is a wildcard that matches anything.</p>
</section>
<section id="mfa" class="level2">
<h2 class="anchored" data-anchor-id="mfa">2.5. MFA</h2>
<p><strong>Password policy</strong> can have different settings: minimum length, specific characters, password expiration, prevent password re-use.</p>
<p><strong>Multi-factor authentication</strong> requires the password you <em>know</em> and the device you <em>own</em> to log in.<br>
A hacker needs both to compromise the account.</p>
<p>MFA devices:</p>
<ul>
<li>Virtual MFA devices - Google Authenticator, Authy. Support for multiple tokens on a single device.</li>
<li>Universal 2nd Factor Security Key (U2F) - eg YubiKey. Support for multiple root and IAM users on a single security key.<br>
</li>
<li>Hardware key fob MFA device</li>
<li>Hardware key fob MFA device for AWS GovCloud</li>
</ul>
</section>
<section id="access-keys" class="level2">
<h2 class="anchored" data-anchor-id="access-keys">2.6. Access Keys</h2>
<p>There are 3 approaches to access AWS:</p>
<ul>
<li>Management console (web UI) - password + MFA</li>
<li>Command line interface (CLI) - access keys</li>
<li>Software Developer Kit (SDK) - access keys</li>
</ul>
<p>Access keys are generated through the console and managed by the user. <strong>Access Key ID</strong> is like a username. <strong>Secret access key</strong> is like a password. Do not share access keys.</p>
<p>AWS CLI gives programmatic access to public APIs of AWS. It is open source. Configure access keys in the CLI using <code>aws configure</code>.</p>
<p>AWS SDK is for language-specific APIs.</p>
</section>
<section id="aws-cloudshell" class="level2">
<h2 class="anchored" data-anchor-id="aws-cloudshell">2.7. AWS CloudShell</h2>
<p>Access using the <strong>terminal icon</strong> in the toolbar next to the search bar.</p>
<p>This is an alternative to using your own terminal to access the AWS CLI. It is a cloud-based terminal.</p>
<p>You can pass <code>--region</code> to a command to run in a region other than the region selected in the AWS console.</p>
<p>CloudShell has a file system attached so we can upload and download files.</p>
</section>
<section id="iam-roles-for-services" class="level2">
<h2 class="anchored" data-anchor-id="iam-roles-for-services">2.8. IAM Roles for Services</h2>
<p>Some AWS services can perform actions on your behalf. To do so, they need the correct permissions, which we can grant with an IAM role.</p>
<p>For example, EC2 instance roles, Lambda Function roles, CloudFormation roles.</p>
<p>In IAM, select Roles. Choose AWS Service and select the use case, e.g.&nbsp;EC2. Then we attach a permissions policy, such as IAMReadOnlyAccess.</p>
</section>
<section id="iam-security-tools" class="level2">
<h2 class="anchored" data-anchor-id="iam-security-tools">2.9. IAM Security Tools</h2>
<ul>
<li><strong>IAM Credentials Report</strong>. Account-level report on all users and their credentials.</li>
<li><strong>IAM Access Advisor</strong>. User-level report on the service permissions granted to a user and when they were last accessed. This can help to see unused permissions to enforce principle of least privilege. This is in the <em>Access Advisor</em> tab under Users in IAM.</li>
</ul>
</section>
<section id="iam-guidelines-and-best-practices" class="level2">
<h2 class="anchored" data-anchor-id="iam-guidelines-and-best-practices">2.10 IAM Guidelines and Best Practices</h2>
<ul>
<li>Dont use root account except for account set up</li>
<li>One physical user = One AWS user</li>
<li>Assign users to groups and assign permissions to groups</li>
<li>Create a strong password policy and use MFA</li>
<li>Use Roles to give permissions to AWS services</li>
<li>Use Access Keys for programmatic access via CLI and SDK</li>
<li>Audit permissions using credentials report and access advisor</li>
<li>Never share IAM users or access keys</li>
</ul>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">2.11. Summary</h2>
<ul>
<li><strong>Users</strong> map to a physical user</li>
<li><strong>Groups</strong> contain users. They cant contain other groups.</li>
<li><strong>Policies</strong> are JSON documents denoting the permissions for a user / group</li>
<li><strong>Roles</strong> grant permissions for AWS services like EC2 instances</li>
<li><strong>Security</strong> use MFA and password policy</li>
<li><strong>Programmatic</strong> use of services via CLI or SDK. <strong>Access keys</strong> manage permissions for these.</li>
<li><strong>Audit</strong> usage via credentials report or access advisor</li>
</ul>
</section>
</section>
<section id="ec2" class="level1">
<h1>3. EC2</h1>
<section id="ec2-overview" class="level2">
<h2 class="anchored" data-anchor-id="ec2-overview">3.1. EC2 Overview</h2>
<p><strong>Elastic Compute Cloud</strong> used for infrastructure-as-a-service.</p>
<p>Encompasses a few different use cases:</p>
<ul>
<li>Renting virtual machines (EC2)</li>
<li>Storing data on virtual drives (EBS)</li>
<li>Distributing load across machines (ELB)</li>
<li>Scaling services using an auto-scaling group (ASG)</li>
</ul>
<p>Sizing and configuration options:</p>
<ul>
<li>OS</li>
<li>CPU</li>
<li>RAM</li>
<li>Storage - This can be network-attached (EBS and EFS) or hardware (EC2 Instance Store)</li>
<li>Network Card - Speed of card and IP address</li>
<li>Firewall rules - Security group</li>
<li>Bootstrap script - Configure a script to run at first launch using and EC2 User Data script. This runs as the root user so has sudo access.</li>
</ul>
<p>There are different instance types that have different combinations of the configuration options above.</p>
</section>
<section id="creating-an-ec2-instance" class="level2">
<h2 class="anchored" data-anchor-id="creating-an-ec2-instance">3.2. Creating an EC2 Instance</h2>
<ol type="1">
<li>Specify a name tag for the instance and any other optional tags.</li>
<li>Choose a base image. OS.</li>
<li>Choose an instance type.</li>
<li>Key pair. This is optional and allows you to ssh into your instance.</li>
<li>Configure network settings. Public IP address, checkboxes to allow ssh access, http access</li>
<li>Configure storage amount and type. <em>Delete on termination</em> is an important selection to delete the EBS volume once the corresponding EC2 instance is terminated.</li>
<li>The user data box allows us to pass a bootstrap shell script.</li>
<li>Check the summary and click Launch Instance.</li>
</ol>
<p>The <strong>Instance Details</strong> tab tells you the Instance ID, public IP address (to access from the internet) and the private IP address (to access from within AWS).</p>
<p>We can <strong>stop</strong> an instance to keep the storage state of the attached EBS volume but without incurring any more EC2 costs. The public IP address might change it stopping and starting. The private IP address stays the same.</p>
<p>Alternatively, we can <strong>terminate</strong> it completely.</p>
</section>
<section id="ec2-instance-types" class="level2">
<h2 class="anchored" data-anchor-id="ec2-instance-types">3.3. EC2 Instance Types</h2>
<p>There are several families of instances: general purpose, compute-optimised, memory-optimised, accelerated computing, storage-optimised.</p>
<p>See the <a href="https://aws.amazon.com/ec2/instance-types/">AWS website</a> for an overview of all instances. There is also a handy comparison website <a href="https://instances.vantage.sh/">here</a>.</p>
<p>The naming convention is: <span class="math display">\[
m5.large
\]</span></p>
<ul>
<li><code>m</code> is the instance class</li>
<li><code>5</code> is the generation (AWS releases new versions over time)</li>
<li><code>large</code> is the size within the class</li>
</ul>
<p>The use cases for each of the instance types:</p>
<ul>
<li><strong>General purpose</strong> is for generic workloads like web servers. Balance between compute, memory and networking.</li>
<li><strong>Compute-optimized</strong> instances for tasks that require good processors, such as batch processing, HPC, scientific modelling.</li>
<li><strong>Memory-optimized</strong> instances for large RAM, e.g.&nbsp;in-memory databases and big unstructured data processing.</li>
<li><strong>Storage-optimised</strong> instances for tasks that require reading and writing a lot of data from lcoal storage, e.g.&nbsp;high-frequency transaction processing, cache for in-memory databases, data warehouse.</li>
</ul>
</section>
<section id="security-groups" class="level2">
<h2 class="anchored" data-anchor-id="security-groups">3.4. Security Groups</h2>
<p>Security groups control how traffic is allowed into or out of EC2 instances. They act as a firewall on EC2 instances.</p>
<p>Security groups only contain <strong>allow</strong> rules. Security groups can reference IP addresses or other security groups.</p>
<p>They regulate:</p>
<ul>
<li>Access to ports</li>
<li>Authorised IP ranges (IPv4 and IPv6)</li>
<li>Inbound and outbound network</li>
</ul>
<p>By default, any inbound traffic is blocked and any outbound traffic is allowed.</p>
<p>A security group can be attached to multiple instances. It is locked down to a <code>(region, VPC)</code> combination.</p>
<p>The security group exists outside of the EC2 instance, so if traffic is blocked then the instance will never see it.</p>
<ul>
<li>Any time you get a timeout when trying to access your EC2 instance, its almost always a result of the security rule.</li>
<li>If the application gives connection refused then its an application error.</li>
<li>It can be helpful to keep a security group specifically for SSH access</li>
</ul>
<p>Access security groups under:</p>
<pre><code>EC2 -&gt; Network &amp; Security -&gt; Security Groups</code></pre>
<p>We can set the type of connection, the port and the IP address/range.</p>
<p>A security group can reference other security groups, i.e.&nbsp;allow traffic from any other EC2 instance which has Security Group A or Security Group B attached to it. This saves us from having to reference IP addresses all the time, which can be handy when these are not static.</p>
<p>Typical ports to know:</p>
<ul>
<li>21 - FTP, file transfer protocol</li>
<li>22 - SSH or SFTP (because SFTP uses SSH), secure shell and secure FTP</li>
<li>80 - HTTP, access unsecured websites</li>
<li>443 - HTTPS, access secured websites</li>
<li>3389 - RDP, Remote Desktop Protocol, SSH equivalent for Windows</li>
</ul>
</section>
<section id="connecting-to-instances" class="level2">
<h2 class="anchored" data-anchor-id="connecting-to-instances">3.5. Connecting to Instances</h2>
<p>SSH works for Linux, Mac or Windows &gt; 10. Putty works for all versions of Windows. <strong>EC2 Instance Connect</strong> works for all operating systems.</p>
<section id="linux-via-ssh" class="level3">
<h3 class="anchored" data-anchor-id="linux-via-ssh">3.5.1. Linux via SSH</h3>
<p>SSH allows you to control a remote machine using the command line.</p>
<p>You need you pem / ppm file for your secure keys. The EC2 instance needs to allow inbound connections for SSH access.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ssh</span> EC2-<span class="op">&lt;</span>username<span class="op">&gt;</span>@<span class="op">&lt;</span>public IP address<span class="op">&gt;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We can pass the file path for the key with the argument <code>-i path/to/file.pem</code></p>
</section>
<section id="ec2-instance-connect" class="level3">
<h3 class="anchored" data-anchor-id="ec2-instance-connect">3.5.2. EC2 Instance Connect</h3>
<p>This opens a terminal in browser. No security keys are required since it generates temporary keys.</p>
<p>This relies on SSH behind the scenes, so the correct security groups for SSH need to be allowed on the EC2 instance.</p>
<p>Use the <code>EC2 Instance Connect</code> tab in the EC2 section for your running instance.</p>
</section>
</section>
<section id="ec2-instance-roles" class="level2">
<h2 class="anchored" data-anchor-id="ec2-instance-roles">3.6. EC2 Instance Roles</h2>
<p>Never enter your IAM details on an EC2 instance as this would be available to anybody else who can access the instance. Poor security practices!</p>
<p>Instead, we use EC2 instance roles.</p>
<p>In the tab for the instance tab, we can do this with:</p>
<pre><code>Action -&gt; Security -&gt; Modify IAM Role</code></pre>
<p>Then select a role to attach to the instance.</p>
</section>
<section id="ec2-instance-purchase-options" class="level2">
<h2 class="anchored" data-anchor-id="ec2-instance-purchase-options">3.7. EC2 Instance Purchase Options</h2>
<section id="purchase-options" class="level3">
<h3 class="anchored" data-anchor-id="purchase-options">3.7.1. Purchase Options</h3>
<p>More common: - <strong>Spot</strong>: short workloads, cheap but can be terminated. Not suitable for critical jobs or databases. - <strong>On-demand</strong>: short uninterrupted workloads, pay per second - <strong>Reserved</strong>: long workloads like a database. 1 or 3 years. Convertible reserved instances allow you to change the instance type over the reserved period. - <strong>Savings plan</strong>: 1 to 3 year commitment to an amount of USAGE rather than committing to a specific instance size or OS.</p>
<p>Less common: - <strong>Dedicated hosts</strong>: book an entire physical server and control instance placement. Most expensive. Useful to meet compliance requirements, or where you have Bring Your Own Licence (BYOL) software. - <strong>Dedicated instances</strong>: no other customers share your hardware. No control over instance placement, so the physical hardware might move after stopping and starting. May share hardware with other instances in the same account. - <strong>Capacity reservations</strong>: reserve capacity in your AZ for any duration. No time commitment and no billing discounts. Youre charged on demand rates whether you run the instance or not. Suitable for short term interrupted workloads that need to be in a specific AZ.</p>
</section>
<section id="ipv4-charges" class="level3">
<h3 class="anchored" data-anchor-id="ipv4-charges">3.7.2. IPv4 Charges</h3>
<p>There is a $0.005 per hour charge for all public IPv4 in your account.</p>
<p>There is a free tier for the EC2 service. There is no free tier for any other service.</p>
<p>There is no charge for IPv6 addresses. But this does not work for all ISPs.</p>
<p>AWS Public IP Insights Service under Billing is helpful to see these costs.</p>
</section>
<section id="spot-instances" class="level3">
<h3 class="anchored" data-anchor-id="spot-instances">3.7.3. Spot Instances</h3>
<p>Discount of up to 90% compared to on demand instances.</p>
<p>You define the max spot price you are willing to pay, and you get the instance for as long as the current price is less than your max price. The hourly spot price varies by offer and capacity. If the current price rises above your max, you have a 2 minute grace period to stop or terminate your instance.</p>
<p>Spot Block is a strategy to block a spot instance for a specified time frame (1-6 hours). They are no longer available but could potentially still come up on the exam.</p>
<p>A <strong>spot request</strong> consists of:</p>
<ul>
<li>Max price</li>
<li>Desired number of instances</li>
<li>Launch specification - AMI</li>
<li>Request type: one-time or persistent. A persistent request will automatically request more spot instances whenever any are terminated, for as long as the spot request is valid.</li>
<li>Valid from and until</li>
</ul>
<p><strong>Spot Instance Requests</strong> can only be cancelled if they are open, active or disabled. Canceling a spot request does not terminate the instance. You need to cancel the request then terminate the instance, to ensure a persistent request does not launch another.</p>
</section>
</section>
<section id="spot-fleets" class="level2">
<h2 class="anchored" data-anchor-id="spot-fleets">3.7.4. Spot Fleets</h2>
<p>A spot fleet is a set of spot instances + optional on-demand instances.</p>
<p>It will try to meet the target capacity within the price constraints. You specify the launch pool: instance type, OS and availability zone. You can have multiple launch pools so the fleet can choose the best. It will stop launching instances either when it reaches target capacity or max cost.</p>
<p>There are several strategies for allocating spot instances:</p>
<ul>
<li><strong>lowestPrice</strong>: from the pool with lowest price</li>
<li><strong>diversified</strong>: distributed across pools for better availability</li>
<li><strong>capacityOptimized</strong>: from the pool with optimal capacity</li>
<li><strong>priceCapacityOptimized</strong> (recommended): pool with highest capacity first, then lowest price</li>
</ul>
</section>
</section>
<section id="ec2-networking" class="level1">
<h1>4. EC2 Networking</h1>
<section id="private-vs-public-ip" class="level2">
<h2 class="anchored" data-anchor-id="private-vs-public-ip">4.1. Private vs Public IP</h2>
<p>There are two types of IP in networking: IPv4 and IPv6. v4 is most commonly used, v6 is for IoT.</p>
<p><strong>Public IP</strong> means the machine can be identified on the internet. It must be unique across the whole web.</p>
<p><strong>Private IP</strong> means the machine can only be located on the private network. It must be unique across that private network. Only a specified range of IP addresses can be used as private addresses. Machines connect to the internet using an internet gateway (a proxy).</p>
</section>
<section id="elastic-ip" class="level2">
<h2 class="anchored" data-anchor-id="elastic-ip">4.2. Elastic IP</h2>
<p>When you start and stop an EC2 instance it can change its IP. If you need this to be fixed, you can use <strong>elastic IP</strong> which will get reused for future instances if that one gets terminated. You can only have 5 elastic IP addresses in your account.</p>
<p>It is <em>best practice to avoid elastic IP addresses as they often are a symptom of bad design choices</em>. Instead, <strong>use a random public IP and register a DNS name to it</strong>. Or <strong>alternatively, use a load balancer</strong> and dont use a public IP.</p>
</section>
<section id="placement-groups" class="level2">
<h2 class="anchored" data-anchor-id="placement-groups">4.3. Placement Groups</h2>
<p>Placement groups allow you to control the EC2 instance placement strategy. You dont get direct access to / knowledge of the hardware, but you can specify one of three strategies:</p>
<ul>
<li><strong>Cluster</strong> - cluster instances into a low latency group in a single AZ. High performance but high risk; low latency and high bandwidth. Useful for big data jobs that need to complete quickly.</li>
<li><strong>Spread</strong> - spread instances across different hardware (max 7 instances per AZ). Useful for critical applications as the risk of all instances simultaneously failing is minimised. But the max instance count limits the size of the job.</li>
<li><strong>Partition</strong> - Spread instances across many different sets of <em>partitions</em> within an AZ. Each partition represents a physical rack of hardware. Max 7 partitions per AZ, but each partition can have many instances. Useful for applications with hundreds of instances or more, like Hadoop.</li>
</ul>
<section id="creating-a-placement-group" class="level3">
<h3 class="anchored" data-anchor-id="creating-a-placement-group">Creating a Placement Group</h3>
<p>To create a placement group:</p>
<pre><code>EC2 -&gt; Network &amp; Security -&gt; Placement Groups -&gt; Create Placement Group</code></pre>
<p>Give it a name, e.g.&nbsp;my-critical-group, then select one of the three strategies.</p>
<p>To launch an instance in a group:</p>
<pre><code>Click Launch Instances -&gt; Advanced Settings -&gt; Placement Group Name</code></pre>
</section>
</section>
<section id="elastic-network-interfaces" class="level2">
<h2 class="anchored" data-anchor-id="elastic-network-interfaces">4.4. Elastic Network Interfaces</h2>
<section id="what-is-an-eni" class="level3">
<h3 class="anchored" data-anchor-id="what-is-an-eni">4.4.1. What is an ENI?</h3>
<p>Elastic Network Interfaces (ENIs) represent a <strong>virtual network card in a VPC</strong>. They are bound to a specific AZ.</p>
<p>Each ENI can have the following attributes:</p>
<ul>
<li>One private IPv4, plus one or more secondary IPv4 addresses</li>
<li>One Elastic IPv4 per private IPv4</li>
<li>One public IPv4</li>
<li>One or more security groups</li>
<li>One MAC address</li>
</ul>
<p>An ENI can be created and then attached to EC2 instances on the fly. This makes them <em>useful for failover</em>, as the ENI from the failed instance can be moved to its replacement to keep the IP addresses consistent.</p>
<p>Another use case is for deployments. We have the current version of the application running on instance A with an ENI. This is accessible by its IP address. Then we can run the new version of the application of instance B. When we are ready to deploy, move the ENI to instance B.</p>
</section>
<section id="creating-an-eni" class="level3">
<h3 class="anchored" data-anchor-id="creating-an-eni">4.4.2. Creating an ENI</h3>
<p>Click on the Instance in the UI and see the <code>Network Interfaces</code> section.</p>
<p>Under the <code>Network &amp; Security</code> tab we can see Network Interfaces. We can create ENIs here.</p>
<p>Specify: description, subnet, Private IPv4 address (auto assign), attach a Security Group.</p>
</section>
<section id="attaching-an-eni-to-an-instance" class="level3">
<h3 class="anchored" data-anchor-id="attaching-an-eni-to-an-instance">4.4.3 Attaching an ENI to an Instance</h3>
<p>On the Network Interfaces UI, Actions -&gt; Attach. Select the instance.</p>
<p>More on ENIs: https://aws.amazon.com/blogs/aws/new-elastic-network-interfaces-in-the-virtual-private-cloud/</p>
</section>
</section>
<section id="ec2-hibernate" class="level2">
<h2 class="anchored" data-anchor-id="ec2-hibernate">4.5. EC2 Hibernate</h2>
<section id="why-hibernate" class="level3">
<h3 class="anchored" data-anchor-id="why-hibernate">4.5.1. Why Hibernate?</h3>
<p>When we <strong>stop</strong> an instance, the data on disk (EBS) is kept intact until the next start. When we start it again, the OS boots up and runs the EC2 User Data script. This can take time.</p>
<p>EC2 Hibernate is a way of reducing boot time. When the instance is hibernated, the RAM state is saved to disk (EBS). When the instance is started again, it loads the RAM state from disk. This avoids having to boot up and initialise the instance from scratch.</p>
<p>Use cases:</p>
<ul>
<li>Long-running processing</li>
<li>Services that take time to initialise</li>
</ul>
<p>An instance can not be hibernated for more than 60 days. The instance RAM size must be less than 150GB and the EBS root volume large enough to store it.</p>
</section>
<section id="enable-hibernation-on-an-instance" class="level3">
<h3 class="anchored" data-anchor-id="enable-hibernation-on-an-instance">4.5.2. Enable Hibernation on an Instance</h3>
<p>We can enable hibernation when creating an instance under Advanced Details, there is a Stop - Hibernate Behaviour drop down that we can enable.</p>
<p>Under Storage, the EBS volume must be encrypted and larger than the RAM.</p>
<p>To then hibernate a specific instance, on the Instance Summary select <code>Instance State -&gt; Hibernate Instance</code>.</p>
</section>
</section>
</section>
<section id="ec2-instance-storage" class="level1">
<h1>5. EC2 Instance Storage</h1>
<section id="ebs" class="level2">
<h2 class="anchored" data-anchor-id="ebs">5.1. EBS</h2>
<section id="what-is-an-ebs-volume" class="level3">
<h3 class="anchored" data-anchor-id="what-is-an-ebs-volume">5.1.1. What is an EBS Volume?</h3>
<p>An Elastic Block Storage (EBS) volume is a <strong>network drive that you can attach to your instance</strong>. Think of it like a cloud USB stick. They allow us to persist data even after an instance is terminated. EBS volumes have a provisioned capacity: size in GB and IOPS.</p>
<p>Each EBS volume can only be mounted to one EC2 instance at a time, and are bound to a specific AZ. To move a volume across an AZ, you need to snapshot it. Each EC2 instance can have multiple EBS volumes.</p>
<p>There is a delete on terminate option. By default, this is on for the root volume but not any additional volumes. We can control this in the AWS console or CLI.</p>
</section>
<section id="creating-an-ebs-volume-on-an-instance" class="level3">
<h3 class="anchored" data-anchor-id="creating-an-ebs-volume-on-an-instance">5.1.2. Creating an EBS Volume on an Instance</h3>
<p>We can see existing volumes under</p>
<pre><code>EC2 -&gt; Elastic Block Store -&gt; Volumes</code></pre>
<p>We can select Create Volume. We then choose volume type, size, AZ (same as instance).</p>
<p>This makes the volume available. We can then attach the volume using <code>Actions -&gt; Attach Volume</code>. The Volume State will now be In-use instead of Available.</p>
</section>
<section id="ebs-snapshots" class="level3">
<h3 class="anchored" data-anchor-id="ebs-snapshots">5.1.3. EBS Snapshots</h3>
<p>A snapshot is a <strong>backup of your EBS volume at a point in time</strong>.</p>
<p>It is recommended, but not necessary, to detach the volume from an instance.</p>
<p>We can copy snapshots across AZ and regions.</p>
<p>Features:</p>
<ul>
<li>EBS Snapshot Archive. Moving the snapshot to an archive tier is much cheaper (75%) but then takes 24-72 hours to restore.</li>
<li>Recycle bin. There are setup rules to retain deleted snapshots so they can be restored after deletion. Retention period is 1 day to 1 year.</li>
<li>Fast snapshot restore (FSR). Force full initialisation of snapshot to have no latency. This costs more.</li>
</ul>
</section>
<section id="ebs-features-hands-on" class="level3">
<h3 class="anchored" data-anchor-id="ebs-features-hands-on">5.1.4. EBS Features Hands On</h3>
<p><strong>Create</strong> an EBS volume:</p>
<pre><code>Elastic Block Store UI, Actions -&gt; Create Snapshot -&gt;  Add a description</code></pre>
<p><strong>See</strong> snapshots:</p>
<pre><code>EBS -&gt; Snapshots tab</code></pre>
<p><strong>Copy</strong> it to another region:</p>
<pre><code>Right-click volume -&gt; Copy Snapshot -&gt; Select the description and destination region</code></pre>
<p><strong>Recreate</strong> a volume from a snapshot:</p>
<pre><code>Select the snapshot -&gt; Actions -&gt; Create Volume From Snapshot -&gt;  Select size and AZ</code></pre>
<p><strong>Archive</strong> the snapshot:</p>
<pre><code>Select the volume -&gt; Actions -&gt; Archive Snapshot</code></pre>
<p><strong>Recover</strong> a snapshot after deletion:</p>
<pre><code>Recycle Bin -&gt; Select the snapshot -&gt; Recover</code></pre>
</section>
<section id="ebs-volume-types" class="level3">
<h3 class="anchored" data-anchor-id="ebs-volume-types">5.1.5. EBS Volume Types</h3>
<p>EBS volumes are characterised by: size, throughput and IOPS.</p>
<p>Types of EBS volumes:</p>
<ul>
<li>gp2/gp3 - General purpose SSD. The newer gp3 options allow size and IOPS to be varied independently, for the older gp2 types they were linked.</li>
<li>io1/io2 Block Express - High throughput low latency SSD. Support EBS Multi Attach.</li>
<li>st1 - Low cost HDD for frequently accessed data.</li>
<li>sc1 - Lowest cost HDD for infrequently accessed data.</li>
</ul>
<p>Only the SSD options can be used as boot volumes.</p>
</section>
<section id="ebs-multi-attach" class="level3">
<h3 class="anchored" data-anchor-id="ebs-multi-attach">5.1.6. EBS Multi Attach</h3>
<p>Attach the same EBS volume to multiple EC2 instances (up to 16) in the same AZ.</p>
<p>Only available for io1 and io2 EBS volume types. You must use a file system that is cluster-aware.</p>
<p>For use cases with higher application availability in clustered applications, or where applications must manage concurrent write operations.</p>
</section>
<section id="ebs-encryption" class="level3">
<h3 class="anchored" data-anchor-id="ebs-encryption">5.1.7. EBS Encryption</h3>
<p>When you create an encrypted EBS volume you get:</p>
<ul>
<li>Data at rest is encrypted inside the volume</li>
<li>Data in flight is encrypted between the volume and the instance</li>
<li>Snapshots are encrypted</li>
<li>Volumes created from the snapshot are encrypted</li>
</ul>
<p>Encryption and decryption is all handled by AWS. The latency impact is minimal. It uses KMA (AES-256) keys.</p>
<p>Copying an unencrypted snapshot allows encryption:</p>
<ol type="1">
<li>Create an EBS snapshot of the volume.</li>
<li>Encrypt the snapshot using copy.</li>
<li>Create a new EBS volume from the snapshot. This will be encrypted.</li>
<li>Attach the encrypted volume to the original instance.</li>
</ol>
</section>
</section>
<section id="ami" class="level2">
<h2 class="anchored" data-anchor-id="ami">5.2. AMI</h2>
<p>Amazon Machine Image (AMI) is the <strong>customisation of an EC2 instance</strong>. It defines the OS, installed software, configuration, monitoring, etc. AMIs are built for a specific region.</p>
<p>Putting this in the AMI rather than the boot script results in a <em>faster boot time</em> since the software is prepackaged.</p>
<p>We can launch EC2 instances from:</p>
<ul>
<li>A public AMI (provided by AWS)</li>
<li>An AMI from the AWS Marketplace (provided by a third-party)</li>
<li>Your own AMI</li>
</ul>
<p><strong>Create an AMI from a running instance</strong> that we have customised to our liking:</p>
<pre><code>Right-click the instance -&gt; Images and Templates -&gt; Create Image</code></pre>
<p><strong>See</strong> the AMI:</p>
<pre><code>EC2 UI -&gt; Images -&gt; AMIs</code></pre>
<p>Launch an instance from an AMI</p>
<pre><code>Select the AMI -&gt; Launch Instance from AMI</code></pre>
</section>
<section id="ec2-instance-store" class="level2">
<h2 class="anchored" data-anchor-id="ec2-instance-store">5.3. EC2 Instance Store</h2>
<p>EBS volumes are <em>network drives</em>, which gives adequate but potentially slow read/write.</p>
<p>EC2 Instance Store is <strong>a physical disk attached to the server that is running the EC2 instance</strong>.</p>
<p>They give better I/O performance but are ephemeral, the data is lost if the instance is stopped or the hardware fails.</p>
<p>Good for cache or temporary data.</p>
</section>
<section id="elastic-file-system-efs" class="level2">
<h2 class="anchored" data-anchor-id="elastic-file-system-efs">5.4. Elastic File System (EFS)</h2>
<section id="what-is-efs" class="level3">
<h3 class="anchored" data-anchor-id="what-is-efs">5.4.1. What is EFS?</h3>
<p>EFS is a <strong>managed Network File System (NFS) that can be mounted on multiple EC2 instances</strong>. The EC2 instances can be in multiple AZs.</p>
<p>Highly available, scalable, but more expensive. It scales automatically and you pay per GB. You dont need to plan the capacity in advance.</p>
<p>A <em>security group is required</em> to control access to EFS. It is compatible with Linux AMIs only, not Windows. It is a POSIX (Linux-ish) file system with the standard API.</p>
<p>Uses cases: content management, web serving, data sharing, Wordpress.</p>
</section>
<section id="performance-modes" class="level3">
<h3 class="anchored" data-anchor-id="performance-modes">5.4.2. Performance Modes</h3>
<ul>
<li>EFS Scale - This gives thousands of concurrent NFS clients for &gt;10GB/s of throughput.</li>
<li>Performance modes - This can be set to <strong>general purpose</strong> for latency-sensitive use cases, or <strong>Max I/O</strong> for higher throughput at the expense of higher latency.</li>
<li>Throughput mode - This can be set to <strong>bursting</strong> which scales throughput with the total storage used, <strong>provisioned</strong> which sets a fixed throughput, or <strong>elastic</strong> which scales throughput depending on the demand (ie the requests received)</li>
</ul>
</section>
<section id="storage-classes" class="level3">
<h3 class="anchored" data-anchor-id="storage-classes">5.4.3. Storage classes</h3>
<p>Storage tiers are a lifecycle management feature to <strong>move files to cheaper storage after N days</strong>. You can implement lifecycle policies to automatically move files between tiers based on the number of days since it was last accessed.</p>
<ul>
<li><strong>Standard</strong>. For frequently accessed files.</li>
<li><strong>Infrequent access</strong> (EFS-IA). There is a cost to retrieve files, but lower cost to store.</li>
<li><strong>Archive</strong>. For rarely accessed data.</li>
</ul>
<p>There are two different availability options:</p>
<ul>
<li>Regional. Multi-AZ within a region, good for production.</li>
<li>One zone. Only one AZ with backup enabled by default. Good for dev.</li>
</ul>
</section>
</section>
<section id="ebs-vs-efs" class="level2">
<h2 class="anchored" data-anchor-id="ebs-vs-efs">5.5. EBS vs EFS</h2>
<p>EBS volumes are attached to one instance (mostly, apart from multi-attach) and are locked at the AZ level.</p>
<p>EFS can be mounted to hundreds of instances across AZs. It is more expensive, but storage tiers can help reduce this.</p>
<p>Instance Store is attached to a specific instance, and is lost when that instance goes down.</p>
</section>
</section>
<section id="elb-and-asg" class="level1">
<h1>6. ELB and ASG</h1>
<section id="scalability-and-availability" class="level2">
<h2 class="anchored" data-anchor-id="scalability-and-availability">6.1. Scalability and Availability</h2>
<p><strong>Scalability</strong> means an application can adapt to <strong>handle greater loads</strong>.</p>
<ul>
<li><strong>Vertical</strong> scalability. Increase the size of a single instance. The scaling limit is often a hardware limit. <em>Scale up and down</em>.</li>
<li><strong>Horizontal</strong> scalability. Also called elasticity. Distribute across more instances. <em>Scale out and in</em>.</li>
</ul>
<p>High <strong>availability</strong> is the ability to <strong>survive a data center loss</strong>. This often comes with horizontal scale. Run the application across multiple AZs.</p>
</section>
<section id="elb" class="level2">
<h2 class="anchored" data-anchor-id="elb">6.2. ELB</h2>
<section id="load-balancing" class="level3">
<h3 class="anchored" data-anchor-id="load-balancing">6.2.1. Load balancing</h3>
<p>Load balancers are <strong>servers that forward traffic to multiple servers downstream</strong>.</p>
<p>Benefits:</p>
<ul>
<li>Spread the load across downstream instances</li>
<li>Perform health checks on instances and handle downstream failures</li>
<li>Expose a single point of access (DNS) to your application</li>
<li>Provide SSL termination</li>
<li>Separate public traffic from private traffic</li>
<li>High availability across zones</li>
</ul>
<p><strong>Elastic Load Balancer</strong> (ELB) is a managed load balancer.</p>
<p>Health checks are done on a port and route, and return a 200 status if it can be reached.</p>
<p>There are four kinds of managed load balancer:</p>
<ul>
<li>Classic load balancer (Deprecated)</li>
<li>Application load balancer</li>
<li>Network load balancer</li>
<li>Gateway load balancer</li>
</ul>
<p>Some can be set up as internal (private) or external (public).</p>
</section>
<section id="security-groups-1" class="level3">
<h3 class="anchored" data-anchor-id="security-groups-1">6.2.2. Security Groups</h3>
<p>Users can connect via HTTP/HTTPS from anywhere. So the security groups typically allow inbound TCP connections on ports 80 and 443.</p>
<p>The security groups for the downstream <em>EC2 instances then only needs to allow inbound connections from the load balancer</em>, i.e.&nbsp;one specific source. This means we can forbid users from connecting directly to the instance and force them to go via the load balancer.</p>
</section>
<section id="application-load-balancer-alb" class="level3">
<h3 class="anchored" data-anchor-id="application-load-balancer-alb">6.2.3. Application Load Balancer (ALB)</h3>
<p>These are <strong>layer 7</strong> load balancers, meaning they take <strong>HTTP requests</strong>. They support HTTP/2 and WebSocket, and can also redirect from HTTP to HTTPS.</p>
<p>You get a fixed hostname, i.e.&nbsp;<code>XXX.region.elb.amazonaws.com</code>. This is helpful to get a fixed IP to connect to instances which are being created and destroyed, where IP addresses are normally changing constantly. The application servers dont see the IP of the client directly, but this is inserted as a header <code>X-forwarded-for</code>. We also headers for the port and protocol.</p>
<p>Use cases are microservices and container-based applications (e.g.&nbsp;ECS). One load balancer can route traffic between multiple applications. There is a port mapping feature to redirect to a dynamic port in ECS.</p>
<p>They can route requests to multiple HTTP applications across machines (called target groups) or multiple applications on the same machine (e.g.&nbsp;containers).</p>
<p>Routing options:</p>
<ul>
<li>By <strong>path in URL</strong> - e.g.&nbsp;<code>/users</code> endpoint, <code>/blog</code> endpoint</li>
<li>By <strong>hostname in URL</strong> - e.g.&nbsp;<code>one.example.com</code> and <code>two.example.com</code></li>
<li>By <strong>query string headers</strong> - e.g.&nbsp;<code>/id=123&amp;orders=True</code></li>
</ul>
<p>ALB can route to multiple target groups. Health checks are at the target group level. Target groups can be:</p>
<ul>
<li>EC2 instances</li>
<li>ECS tasks</li>
<li>Lambda functions</li>
<li>Private IP addresses</li>
</ul>
</section>
<section id="network-load-balancer-nlb" class="level3">
<h3 class="anchored" data-anchor-id="network-load-balancer-nlb">6.2.4. Network Load Balancer (NLB)</h3>
<p>These are <strong>layer 4</strong> load balancers, meaning they route <strong>TCP and UDP traffic</strong>. Ultra-low latency and can handle millions of requests per second. NLB has one static IP per AZ.</p>
<p>Target groups can be:</p>
<ul>
<li>EC2 instances</li>
<li>Private IP addresses</li>
<li>Application load balancers. You may want the NLB for a static IP, routing to an ALB for the http routing rules.</li>
</ul>
<p>Health checks support TCP, HTTP and HTTPS protocols.</p>
</section>
<section id="gateway-load-balancer-gwlb" class="level3">
<h3 class="anchored" data-anchor-id="gateway-load-balancer-gwlb">6.2.5. Gateway Load Balancer (GWLB)</h3>
<p>This is a <strong>layer 3</strong> load balancer, meaning it routes <strong>IP packet</strong>s.</p>
<p>This is useful when we want to route traffic via a target group of a 3rd party network virtual appliance (e.g.&nbsp;a firewall) before it reaches our application.</p>
<pre><code>User traffic &gt; GWLB &gt; Firewall &gt; GWLB &gt; Our application </code></pre>
<p>It uses the GENEVE protocol on port 6081.</p>
<p>Target groups can be:</p>
<ul>
<li>EC2 instances</li>
<li>Private IP addresses</li>
</ul>
</section>
<section id="sticky-sessions" class="level3">
<h3 class="anchored" data-anchor-id="sticky-sessions">6.2.6. Sticky Sessions</h3>
<p>Stickiness means <strong>a particular client is always routed to the same instance behind the load balancer</strong>. This means the user doesnt lose their session data. It does this via a cookie which has an expiration date.</p>
<p>Overusing sticky sessions can result in <em>imbalanced loads</em>, since theyre constraining the load balancer to direct traffic to instances that may not be optimal.</p>
<p><strong>Application-based cookies</strong>. Two options for this: - A <strong>custom cookie</strong> is generated by the target. The cookie name must be specified for each target group and cannot be one of the reserved keywords: AWSALB, AWSALBAPP, AWSALBTG. - An <strong>application cookie</strong> is generated by the load balancer. The cookie name is always AWSALBAPP.</p>
<p><strong>Duration-based cookies</strong>. This is generated by the load balancer. The cookie name is always AWSALB for ALB (or AWSELB for CLB).</p>
<pre><code>ELB UI -&gt; Target Groups -&gt; Select a target group -&gt; Edit Target Group 
-&gt; Turn On Stickiness -&gt; Select cookie type and duration</code></pre>
</section>
<section id="cross-zone-load-balancing" class="level3">
<h3 class="anchored" data-anchor-id="cross-zone-load-balancing">6.2.7. Cross-Zone Load Balancing</h3>
<p>With cross-zone load balancing, each load balancer will distribute requests evenly across all registered instances <strong>in all AZs</strong>, regardless of which zone the request came from.</p>
<p>Without cross-zone load balancing, there can be big disparities between load in different AZs.</p>
<p>Cross-zone load balancing is enabled by default for ALB and CLB, and wont charge for data transfer between AZs. It is disabled by default for NLB and GWLB. These will charge for inter-AZ data transfer if you enable it.</p>
</section>
<section id="connection-draining" class="level3">
<h3 class="anchored" data-anchor-id="connection-draining">6.2.8. Connection Draining</h3>
<p>The load balancer allows time to complete in-flight requests while the instance is registering or unhealthy. The load balancer stops sending new requests to the EC2 instance which is de-registering.</p>
<p>The is called <strong>connection draining</strong> for CLB, and <strong>deregistration delay</strong> for ALB and NLB.</p>
<p>It can be 0-3600 seconds. By default it is 300 seconds. Disable connection draining by setting it to 0.</p>
</section>
</section>
<section id="ssl-certificates" class="level2">
<h2 class="anchored" data-anchor-id="ssl-certificates">6.3. SSL Certificates</h2>
<section id="ssl-and-tls" class="level3">
<h3 class="anchored" data-anchor-id="ssl-and-tls">6.3.1. SSL and TLS</h3>
<p>An SSL certificate allows <strong>in-flight encryption</strong> - traffic between clients and load balancer is encrypted. They have an expiration date (that you set) and must be renewed. Public SSL certificates are issued by Certificate Authorities (CA) like GoDaddy, GlobalSign etc.</p>
<p>TLS certificates are actually used in practice, but the name SSL has stuck.</p>
<ul>
<li>SSL = Secure Sockets Layer</li>
<li>TLS = Transport Layer Security (a newer version of SSL)</li>
</ul>
<p>The load balancer uses a default X.509 certificate, but you can upload your own. AWS Certificate Manager (ACM) allows you to manage these certificates.</p>
</section>
<section id="sni" class="level3">
<h3 class="anchored" data-anchor-id="sni">6.3.2. SNI</h3>
<p>Clients can use Server Name Indication (SNI) to <strong>specify the hostname they reach</strong>.</p>
<p>SNI solves the problem of loading multiple SSL certificates on one web server. We may have a single load balancer serving two websites: <code>www.example.com</code> and <code>www.company.com</code></p>
<p>Each of these websites has an SSL certificate uploaded to the load balancer. When a client request comes in, it indicates which website it wants to reach and the load balancer will use the corresponding SSL certificate.</p>
<p>This works for ALB, NLB or CloudFront.</p>
<pre><code>ELB UI -&gt; Select a load balancer -&gt; Add a listener -&gt; Select the default SSL/TLS certificate</code></pre>
</section>
</section>
<section id="auto-scaling-groups-asg" class="level2">
<h2 class="anchored" data-anchor-id="auto-scaling-groups-asg">6.4. Auto Scaling Groups (ASG)</h2>
<section id="what-is-an-asg" class="level3">
<h3 class="anchored" data-anchor-id="what-is-an-asg">6.4.1. What is an ASG?</h3>
<p>The goal of an ASG is to <strong>scale out/in</strong> (add/remove EC2 instances) to match load. It ensures we have a minimum and maximum number of instances running.</p>
<p>If running an ASG connected to a load balancer, any EC2 instances created will be part of that load balancer.</p>
<p>ASG is free, you only pay for the underlying EC2 instances.</p>
<p>You need to create a <strong>ASG Launch Template</strong>.</p>
<ul>
<li>AMI and instance type</li>
<li>EC2 user data</li>
<li>EBS volumes</li>
<li>Security groups</li>
<li>SSH key pair</li>
<li>IAM roles for EC2 instances</li>
<li>Network and subnet information</li>
<li>Load balancer information</li>
</ul>
<p>The ASG has a minimum, maximum and initial size as well as a scaling policy.</p>
<p>It is possible to scale the ASG based on CloudWatch alarms.</p>
</section>
<section id="scaling-policies" class="level3">
<h3 class="anchored" data-anchor-id="scaling-policies">6.4.2. Scaling Policies</h3>
<p><strong>Dynamic scaling</strong>:</p>
<ul>
<li>Target tracking scaling. Keep a certain metric, e.g.&nbsp;ASG CPU, to stay at 40%</li>
<li>Simple / step scaling. When a CloudWatch alarm is triggered, e.g.&nbsp;CPU &gt; 70%, add 2 units.</li>
</ul>
<p><strong>Scheduled scaling</strong>:</p>
<ul>
<li>Anticipate scaling based on known usage patterns. E.g. market open.</li>
</ul>
<p><strong>Predictive scaling</strong>:</p>
<ul>
<li>Continuously forecast load and schedule scaling accordingly.</li>
</ul>
<p>Good metrics to scale on:</p>
<ul>
<li>CPUUtilization</li>
<li>RequestCountPerTarget</li>
<li>Average Network In/Out</li>
<li>Application-specific metrics</li>
</ul>
</section>
<section id="scaling-cooldown" class="level3">
<h3 class="anchored" data-anchor-id="scaling-cooldown">6.4.3. Scaling Cooldown</h3>
<p>After a scaling activity happens, there is a cooldown period (default 300 seconds) where the ASG will not launch or remove any more instances while it waits for metrics to stabilise.</p>
<p>Using a ready-to-use AMI means the EC2 instances start quicker, allowing you to use a shorter cooldown and be more reactive.</p>
</section>
</section>
</section>
<section id="relational-databases" class="level1">
<h1>7. Relational Databases</h1>
<section id="rds" class="level2">
<h2 class="anchored" data-anchor-id="rds">7.1. RDS</h2>
<section id="what-is-relational-database-service" class="level3">
<h3 class="anchored" data-anchor-id="what-is-relational-database-service">7.1.1 What is Relational Database Service?</h3>
<p>Relational Database Service (RDS) is a <strong>managed DB using SQL</strong> as a query language.</p>
<p>Supported database engines: Postgres, MySQL, MariaDB, Oracle, Microsoft SQL Server, IBM DB2, Aurora (AWS proprietary database).</p>
<p>Instead of RDS, we <em>could</em> run our own EC2 instance with a database inside. The benefit of RDS is that it is a managed service, so you get:</p>
<ul>
<li>Automated provisioning and OS patching</li>
<li>Continuous backups and point-in-time restore</li>
<li>Monitoring dashboards</li>
<li>Read replicas</li>
<li>Multi-AZ setup for disaster recovery</li>
<li>Maintenance windows for upgrades</li>
<li>Horizontal and vertical scaling capabilities</li>
<li>Storage backed by EBS</li>
</ul>
<p>But the downside is you cant SSH into the underlying instances.</p>
</section>
<section id="storage-auto-scaling" class="level3">
<h3 class="anchored" data-anchor-id="storage-auto-scaling">7.1.2. Storage Auto-Scaling</h3>
<p>RDS will increase your DB instance automatically as you run out of free space. You set a <strong>Maximum Storage Threshold</strong>.</p>
<p>This will automatically modify storage if:</p>
<ul>
<li>Free storage is less than 10%</li>
<li>Low-storage lasts at least 5 mins</li>
<li>6 hours have passed since the last notification</li>
</ul>
</section>
<section id="read-replicas" class="level3">
<h3 class="anchored" data-anchor-id="read-replicas">7.1.3. Read Replicas</h3>
<p>Read replicas allow <strong>better read scalability</strong>. Read replicas are obviously read-only, so only support SELECT statements.</p>
<p>We can create up to 15 read replicas. They can be within AZ, cross-AZ or cross-region. The replication is <strong>asynchronous</strong> so they are <em>eventually consistent</em>. Replicas can be promoted to their own DB.</p>
<p>Applications must update their connection string to use the read replicas.</p>
<p>Use cases may be if you have an existing production application, and now you want to add a reporting application without affecting performance of the existing process.</p>
<p><strong>Network costs</strong>:</p>
<ul>
<li>If the read replicas are in the same region, there is no network costs for the data transfer.</li>
<li>There is a network cost for cross-region read replicas.</li>
</ul>
</section>
<section id="multi-az" class="level3">
<h3 class="anchored" data-anchor-id="multi-az">7.1.4. Multi-AZ</h3>
<p>This is typically for disaster recovery.</p>
<p>This is a <strong>synchronous</strong> replication.</p>
<p>There is one DNS name, and the application will automatically failover to the standby database if the master database goes down. No manual intervention is required. This increases availability.</p>
<p>Aside from the disaster case, no traffic is normally routed to the standby database. It is only for failovers, not scaling.</p>
<p>You can set up read replicas as multi-AZ for disaster recovery.</p>
<p>Single-AZ to multi-AZ is a zero downtime operation, the DB does not stop. We just click modify on the database.</p>
<p>Internally, what happens is: a snapshot it taken, a new DB is restored from this snapshot in a new AZ, synchronisation is established between the two databases.</p>
</section>
<section id="rds-custom" class="level3">
<h3 class="anchored" data-anchor-id="rds-custom">7.1.5. RDS Custom</h3>
<p>This is a <strong>managed Oracle and Microsoft SQL Server database with full admin access</strong> for OS and database customisation. Usually these are managed by RDS.</p>
<p>It allows us to configure the OS and settings, and access the underlying EC2 instance using SSH or SSM Session Manager.</p>
</section>
<section id="rds-proxy" class="level3">
<h3 class="anchored" data-anchor-id="rds-proxy">7.1.6. RDS Proxy</h3>
<p>An RDS Proxy <strong>pools and shares incoming connections together</strong> resulting in fewer connections to the database. Think of it <em>like a load balancer for the database</em>.</p>
<p>This is useful when you have multiples instances scaling in and out that might connect to your database then disappear and leave lingering connections open. For example, when using Lambda functions.</p>
<p>It is serverless and supports autoscaling. It reduces failover time by up to 66%. It supports both RDS and Aurora, including most flavours of SQL.</p>
<p>No code changes are required for most apps, just point the connection details to the proxy rather than the database directly. Authentication is via IAM using credentials stored in AWS Secrets Manager. The <em>RDS Proxy can only be accessed from inside the VPC</em>, it is never publicly accessible.</p>
</section>
</section>
<section id="amazon-aurora" class="level2">
<h2 class="anchored" data-anchor-id="amazon-aurora">7.2. Amazon Aurora</h2>
<section id="what-is-aurora" class="level3">
<h3 class="anchored" data-anchor-id="what-is-aurora">7.2.1. What is Aurora?</h3>
<p>Aurora is a <strong>proprietary database from AWS</strong> with compatibility with Postgres and MySQL.</p>
<p>Aurora is cloud-optimised with faster read/write performance and less lag when creating read replicas. Storage grows automatically. Failover is instantaneous.</p>
<p>It stores 6 copies of your data across 3 AZ: 4 out of 6 copies are needed for writes, and 3 out of 6 for reads.</p>
<p>Storage is striped across hundreds of volumes. There is self-healing with peer-to-peer replication.</p>
<ul>
<li>One master Aurora instance takes <em>writes</em>. There is automated failover within 30 seconds if the master instance goes down.<br>
</li>
<li>Master + up to 15 read replicas serve <em>reads</em>. You can set up auto-scaling for read replicas. There is support for cross-region replication.</li>
</ul>
<p><strong>The aurora DB cluster</strong>. You dont interact with any instance directly; they can scale and be removed so the connection URL would be constantly changing. Instead there is a <strong>writer endpoint</strong> that always points to the master instance. There is a <strong>read endpoint</strong> which points to a load balancer that directs your query to a read replica.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="AuroraCluster.png" class="img-fluid figure-img"></p>
<figcaption>Aurora Cluster Readers and Writers</figcaption>
</figure>
</div>
</section>
<section id="advanced-concepts" class="level3">
<h3 class="anchored" data-anchor-id="advanced-concepts">7.2.2. Advanced Concepts</h3>
<p><strong>Auto scaling</strong>. Read replicas scale based on CPU usage or number of connections breaching a user-defined threshold.</p>
<p><strong>Custom endpoint</strong>. Define a subset of the read replicas as a custom endpoint. This means we can route traffic for jobs that we know are database-intensive, like analytical queries, to a subset of the instances without affecting the performance on the other read replicas.</p>
<p><strong>Aurora serverless</strong>. Automated database instantiation and auto-scaling based on actual usage.</p>
<p>Good for infrequent, intermittent or unpredictable workloads. No capacity planning needed, you pay per second of usage.</p>
<p>The client connects to a proxy fleet, which is like a load balancer that directs requests to Aurora instances that are scaled in the background.</p>
<p><strong>Global Aurora</strong>. Cross-region replicas are useful for disaster recovery. <strong>Aurora Global Database</strong> is the recommended approach.</p>
<p>You create 1 primary regions for read/write. You can then have up to 5 secondary read-only regions. Replication lag is &lt;1 second. Up to 16 read replicas per secondary region.</p>
<p>Promoting another region in the event of disaster recovery has a Recovery Time Objective (RTO) &lt; 1 minute.</p>
<p><strong>Aurora Machine Learning.</strong> Add ML-based predictions to your application via SQL. Supported on SageMaker or Amazon Comprehend.</p>
<p><strong>Babelfish for Aurora PostgreSQL</strong>. Babelfish allows Aurora PostgreSQL to understand commands targeted for Microsoft SQL Server (written in T-SQL). It automatically translates between these flavours of SQL to make migration easier.</p>
</section>
</section>
<section id="backups-and-monitoring" class="level2">
<h2 class="anchored" data-anchor-id="backups-and-monitoring">7.3. Backups and Monitoring</h2>
<section id="rds-1" class="level3">
<h3 class="anchored" data-anchor-id="rds-1">7.3.1. RDS</h3>
<p>There are automated backups:</p>
<ul>
<li>Full backup daily during the backup window.</li>
<li>Transaction logs backed up every 5 mins. This gives the ability to do a point-in-time restore.</li>
<li>1-35 days of retention. Can be disabled by setting to 0.</li>
</ul>
<p>Manual DB snapshots are triggered by the user and can be retained as long as you want.</p>
<p>A use case for this is for an infrequently used database. A stopped RDS database will still incur storage costs. If you intend to stop it for a long time, you can snapshot it then restore it later.</p>
</section>
<section id="aurora" class="level3">
<h3 class="anchored" data-anchor-id="aurora">7.3.2. Aurora</h3>
<p>Automate backups are retained for 1-35 days. Cannot be disabled. Point-in-time recovery for any point in that timeframe.</p>
<p>Manual DB snapshots. Triggered by user and retained for as long as you want.</p>
</section>
<section id="restore-options" class="level3">
<h3 class="anchored" data-anchor-id="restore-options">7.3.3. Restore Options</h3>
<ul>
<li>Restore an <strong>RDS / Aurora backup</strong> or snapshot to create a new database.</li>
<li>Restore a <strong>MySQL RDS database from S3</strong>. Create a backup of your on-premises database, store it in S3, the restore the backup file on to a new instance running MySQL.</li>
<li>Restore a <strong>MySQL Aurora cluster from S3</strong>. Same as for RDS, except the on-premises backup must be created using Percona XtraBackup.</li>
</ul>
</section>
<section id="aurora-database-cloning" class="level3">
<h3 class="anchored" data-anchor-id="aurora-database-cloning">7.3.4 Aurora Database Cloning</h3>
<p>Create a new Aurora DB cluster from an existing one. An example use case is cloning a production database into dev and staging.</p>
<p>It is faster than doing a snapshot+restore. It uses the copy-on-write protocol. Initially the clone uses the same data volume as the original cluster, then when updates are made to the cloned DB cluster additional storage is allocated and data is copied to be separated.</p>
</section>
</section>
<section id="encryption" class="level2">
<h2 class="anchored" data-anchor-id="encryption">7.4. Encryption</h2>
<p>Applies to both RDS and Aurora.</p>
<p><strong>At rest encryption</strong>. Database master and read replicas are encrypted using AWS KMS. This must be defined at launch time. If master is not encrypted then the read replicas cannot be encrypted. If you want to encrypt and unencrypted database, you need to take a snapshot of it and restore a new database with encryption set up at launch time.</p>
<p><strong>In flight encryption</strong>. RDS and Aurora are TLS-ready by default. Applications must use the provided AWS TLS root certificates on the client side.</p>
<p>Authentication can be via IAM or by the standard username/password used to connect to databases. Security groups can also be used to control access. Audit logs can be enabled and sent to CloudWatch Logs for longer retention.</p>
</section>
<section id="elasticache" class="level2">
<h2 class="anchored" data-anchor-id="elasticache">7.5. ElastiCache</h2>
<section id="what-is-elasticache" class="level3">
<h3 class="anchored" data-anchor-id="what-is-elasticache">7.5.1. What is ElastiCache?</h3>
<p>ElastiCache is a <strong>managed Redis or Memcached</strong>. Analogous to how RDS is a managed SQL database. It is managed, meaning AWS takes care of OS maintenance, configuration, monitoring, failure recovery, backups, etc.</p>
<p>Caches are <strong>in-memory databases</strong> with low latency. They reduce the load on your database for read-intensive workloads.</p>
<p>This can help make your application stateless. For example, when the user logs in, their session is written to the cache. If their workload is moved to another instance, their session can be retrieved from the cache.</p>
<p>It does, however, require significant changes to your applications code. Instead of querying the database directly, we need to:</p>
<ol type="1">
<li>Query the cache. If we get a cache hit, use that result.</li>
<li>If we get a cache miss, read from the database directly.</li>
<li>Then write that result to the cache ready for the next query.</li>
</ol>
<p>We also need to define a <strong>cache invalidation strategy</strong> to ensure the data in the cache is not stale.</p>
</section>
<section id="redis-vs-memcached" class="level3">
<h3 class="anchored" data-anchor-id="redis-vs-memcached">7.5.2. Redis vs Memcached</h3>
<p>Redis <strong>replicates</strong> whereas Memcached <strong>shards</strong>.</p>
<p>Redis:</p>
<ul>
<li>Multi-AZ with auto-failover</li>
<li>Read replicas to scale for high availability</li>
<li>AOF persistence</li>
<li>Backup and restore features</li>
<li>Supports sets and sorted sets. Sorted sets allow for things like real-time leaderboards</li>
</ul>
<p>Memcached:</p>
<ul>
<li>Multi-node for partitioning (sharding) data</li>
<li>No replication (therefore not high availability)</li>
<li>Not persistent</li>
<li>Backup and restore available for the serverless option only</li>
<li>Multi-threaded architecture</li>
</ul>
</section>
<section id="elasticache-security" class="level3">
<h3 class="anchored" data-anchor-id="elasticache-security">7.5.3. ElastiCache Security</h3>
<p>ElastiCache supports IAM authentication for Redis. IAM policies on ElastiCache are only used for AWS API-level security.</p>
<p>For Memcached, it needs to be username/password. Memcached supports SASL-based authentication.</p>
<p>With <strong>Redis AUTH</strong> you can set a password/token when you create a cluster, which provides an extra level of security on top of security groups. It supports SSL in-flight encryption.</p>
<p>Common patterns for ElastiCache.</p>
<ul>
<li><strong>Lazy loading</strong> - All the read data is cached, but data in the cache may become stale.</li>
<li><strong>Write through</strong> - Data is inserted/updated in the cache any time it is written to the DB. Ensures no stale data.</li>
<li><strong>Session store</strong> - Using the cache to store temporary session data, and using TTL to determine cache validation.</li>
</ul>
</section>
<section id="common-port-numbers" class="level3">
<h3 class="anchored" data-anchor-id="common-port-numbers">7.5.4. Common Port Numbers</h3>
<p>Useful port numbers to know:</p>
<ul>
<li>21 - FTP</li>
<li>22 - SFTP, SSH</li>
<li>80 - HTTP</li>
<li>443 - HTTPS</li>
</ul>
<p>Common database ports:</p>
<ul>
<li>5432 - PostgreSQL, Aurora</li>
<li>3306 - MySQL, MariaDB, Aurora</li>
<li>1433 - MySQL Server</li>
<li>1521 - Oracle RDS</li>
</ul>
</section>
</section>
</section>
<section id="route-53" class="level1">
<h1>8. Route 53</h1>
<section id="dns" class="level2">
<h2 class="anchored" data-anchor-id="dns">8.1. DNS</h2>
<section id="what-is-dns" class="level3">
<h3 class="anchored" data-anchor-id="what-is-dns">8.1.1. What is DNS?</h3>
<p>Domain Name System (DNS) translates human-friendly hostnames into the machine-friendly IP address. E.g. <code>www.google.com</code> -&gt; <code>172.217.18.36</code></p>
<p>There is a hierarchical naming structure separated by <code>.</code>, e.g.&nbsp;</p>
<pre><code>www.example.com
api.example.com</code></pre>
<p>Terminology:</p>
<ul>
<li><strong>Domain registrar</strong>: Amazon Route 53, GoDaddy</li>
<li><strong>DNS Records</strong>: A, AAAA, CNAME</li>
<li><strong>Zone file</strong>: contains DNS records</li>
<li><strong>Name server</strong>: Server that resolves DNS queries</li>
<li><strong>Top-Level Domain</strong> (TLD): .com, .gov, .org</li>
<li><strong>Second-Level Domain</strong> (SLD): google.com, amazon.com</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="url_components_example.png" class="img-fluid figure-img"></p>
<figcaption>Components of a URL</figcaption>
</figure>
</div>
</section>
<section id="how-dns-works" class="level3">
<h3 class="anchored" data-anchor-id="how-dns-works">8.1.2. How DNS Works</h3>
<p>Your web browser sends a request for <code>www.example.com</code> to a Local DNS Server managed by your company or ISP. This routes to a <strong>Root DNS Server</strong> managed by ICANN, which resolves the top-level domain (.com) and gives the corresponding IP address for that part. The browser then sends a request to the <strong>TLD DNS Server</strong> managed by ICANN which resolves the second-level domain. The browser then sends a request to the <strong>SLD DNS Server</strong> managed by Amazon Registrar etc, and that gives the IP address of the requested website.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="dns_routing.png" class="img-fluid figure-img"></p>
<figcaption>DNS Routing</figcaption>
</figure>
</div>
</section>
</section>
<section id="route-53-1" class="level2">
<h2 class="anchored" data-anchor-id="route-53-1">8.2. Route 53</h2>
<p>Route 53 is a fully managed authoritative DNS and Domain Regstrar. You can also check the health of your resources. Authoritative means the customer (you) can update the DNS records.</p>
<p>53 is a reference to the traditional DNS port.</p>
<section id="records" class="level3">
<h3 class="anchored" data-anchor-id="records">8.2.1. Records</h3>
<p>You define <strong>records</strong> which define how you want to route traffic for a domain. Each record contains:</p>
<ul>
<li>Domain/subdomain name - example.com</li>
<li>Record type - A/AAAA/CNAME/NS</li>
<li>Value - 12.34.56.78</li>
<li>Routing policy - how Route53 responds to queries</li>
<li>TTL - how long this record is cached at DNS resolvers</li>
</ul>
<p>Record types:</p>
<ul>
<li>A - maps a hostname to IPv4</li>
<li>AAAA - maps a hostname to IPv6</li>
<li>CNAME - maps a hostname to another hostname. The target is a domain which must have an A or AAAA record.</li>
<li>NS - Name servers for the hosted zone. These are the DNS names/IP addresses for the servers that can respond to queries for your hosted zone.</li>
</ul>
</section>
<section id="hosted-zones" class="level3">
<h3 class="anchored" data-anchor-id="hosted-zones">8.2.2. Hosted Zones</h3>
<p>A hosted zone is a container for records that define how traffic is routed to a domain and its subdomains.</p>
<ul>
<li>Public hosted zones - contain records specifying how to route traffic on the <strong>internet</strong> (i.e.&nbsp;public domain names)</li>
<li>Private hosted zones - contain records specifying how to route traffic in <strong>your VPC</strong> (i.e.&nbsp;private domain names)</li>
</ul>
<p>It costs $0.50 per month per hosted zone.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="hosted_zones.png" class="img-fluid figure-img"></p>
<figcaption>Public vs Private Hosted Zones</figcaption>
</figure>
</div>
<pre><code>Route 53 UI -&gt; Domains -&gt; Registered Domains 
-&gt; Choose a domain name -&gt; Choose duration, auto renew 
-&gt; Checkout -&gt; Contact info</code></pre>
<p>Now in Hosted Zones you will see the DNS records created for your domain.</p>
</section>
<section id="creating-a-record" class="level3">
<h3 class="anchored" data-anchor-id="creating-a-record">8.2.3. Creating a Record</h3>
<pre><code>Route 53 -&gt; Hosted Zones -&gt; Create Record</code></pre>
<p>Specify the record details discussed previously.</p>
<p>We can take the IP addresses from our EC2 instances, load balancers, etc and route to these as we wish.</p>
</section>
<section id="ttl" class="level3">
<h3 class="anchored" data-anchor-id="ttl">8.2.4. TTL</h3>
<p>Time To Live (TTL) on a record <strong>tells the client how long it should cache the record</strong> (i.e.&nbsp;the IP address) before requesting it again. TTL is mandatory for all records except Alias records.</p>
<p>A high TTL (e.g.&nbsp;24 hours) results in less traffic to Route 53, but clients might possibly have outdated records. A low TTL results in more traffic to Route 53 (and therefore higher costs) but records are more up to date and so easier to change.</p>
<p>A common strategy when you know you are changing your DNS record soon is to temporarily lower the TTL close to the switchover.</p>
</section>
<section id="cname-vs-alias-records" class="level3">
<h3 class="anchored" data-anchor-id="cname-vs-alias-records">8.2.5. CNAME vs Alias Records</h3>
<p>Many AWS resources, like ELB and CloudFront, expose an AWS hostname, e.g.&nbsp;<code>blabla.us-east-1.elb.amazonaws.com</code> and we want to map it to <code>myapp.domain.com</code>.</p>
<p><strong>CNAME</strong> records allow a hostname to point to any other hostname, but only for a non-root domain.</p>
<p><strong>Alias records</strong> point a host name to an AWS resource, and this works for root domains and non-root domains. It is free and has a native health check. It automatically recognises changes in the resources IP address. It is always of type A or AAAA, i.e.&nbsp;IPv4 or IPv6. AWS sets the TTL so you cant set this manually.</p>
<p>Valid Alias record targets: ELB, CloudFront Distributions, API Gateway, Elastic Beanstalk environments, S3 Websites (not buckets), VPC Interface Endpoints, Global Accelerator, Route 53 record in the same hosted zone.</p>
<p>You cannot set an Alias record for an EC2 DNS name.</p>
</section>
</section>
<section id="routing-policies" class="level2">
<h2 class="anchored" data-anchor-id="routing-policies">8.3. Routing Policies</h2>
<p>Routing policies define <strong>how Route 53 responds to DNS queries</strong>.</p>
<p>It isnt routing in the sense of a load balancer; DNS does not route any traffic, it just responds to DNS queries.</p>
<p>Route 53 supports several routing policies:</p>
<ul>
<li><p><strong>Simple</strong>. Route traffic to a single resource. We can specify multiple values for the same record. The client will pick one of the IP addresses <em>at random</em>. Cannot use with health checks.</p></li>
<li><p><strong>Weighted</strong>. Control the percentage of requests that go to each resource. We <em>assign each record a relative weight</em>; the DNS records must have the same name and type. Can be used with health checks.</p></li>
<li><p><strong>Latency-based</strong>. Redirect to the <em>resource with the lowest latency</em>, based on traffic between users and AWS. Can be associated with health checks.</p></li>
<li><p><strong>Failover</strong>. There is a health checker associated with the primary instance. If this passes, Route 53 returns its IP address to route traffic to it. If unhealthy, it fails over to another instance and returns that IP address.</p></li>
<li><p><strong>Geolocation</strong>. Routing is based on the <em>users location</em>. This is subtly different from the latency-based policy. We can specify location by continent, country or US state. There should be a default record in case of no match. Can be used with health checks.</p></li>
<li><p><strong>Geo-proximity</strong>. Route traffic to your resources based on the geographic location of users and resources. It is like a continuous equivalent of the discrete binning of the geolocation policy. We shift more traffic to resources based on the defined <strong>bias</strong> - a value between -99 to 99. Resources can be AWS resources (specify AWS region) or non-AWS resources (specify latitude and longitude).</p></li>
<li><p><strong>IP-based routing</strong>. Routing is based of the <em>clients IP addresses</em>. You provide a list of CIDRs for your clients and the corresponding endpoints/locations. These are user-IP-to-endpoint mappings. An example is you route users from a particular ISP to a specify endpoint.</p></li>
<li><p><strong>Multi-value</strong>. Used when routing traffic to multiple resources; Route 53 returns multiple values. Can be associated with health checks and will only return IP addresses of healthy instances.</p></li>
</ul>
<p>It is not a replacement for an ELB. It <em>doesnt necessarily distribute load evenly</em>, it just gives clients more options and lets them choose.</p>
</section>
<section id="health-checks" class="level2">
<h2 class="anchored" data-anchor-id="health-checks">8.4 Health Checks</h2>
<p>HTTP Health Checks are for public resources. We can use them to get automatic DNS failover.</p>
<p>We can use health checks to:</p>
<ol type="1">
<li>Monitor resources</li>
<li>Monitor other health checks. This is called a <strong>Calculated Health Check</strong>. We can use OR, AND or NOT logic to combine the results of multiple health checks, or specify at least N checks must pass.</li>
<li>Monitor CloudWatch Alarms. This gives us a workaround to use them for private resources. The health checkers are outside the VPC so cannot access the endpoint directly. Create a CloudWatch Metric with and associated CloudWatch Alarm, and the health checker monitors the alarm.</li>
</ol>
<pre><code>Route 53 UI -&gt; Health Checks -&gt; Create health check</code></pre>
<p>There are 15 global health checkers in different regions. They will periodically send HTTP requests to <code>/health</code> and if &gt;18% of them receive a 2xx or 3xx status code the endpoint is healthy. The health checker can use the text in the first 5120 bytes of the response.</p>
<p>You can customise the range of regions to use. You must configure your resource to allow incoming requests from the Route 53 health checker IP range.</p>
</section>
<section id="domain-registrar-vs-dns-service" class="level2">
<h2 class="anchored" data-anchor-id="domain-registrar-vs-dns-service">8.5. Domain Registrar vs DNS Service</h2>
<p>You buy/register your domain name with a Domain Registrar by paying an annual fee. The Domain Registrar usually provides you with a DNS service to manage your DNS records. Examples of domain registars are GoDaddy, Amazon Registrar.</p>
<p>But you dont have to stick with the same service provider. You could buy a domain from GoDaddy and use Route53 to manage your DNS records. You can create a hosted zone in Route 53 and specify the custom <strong>Nameservers</strong> to do this.</p>
</section>
</section>
<section id="solutions-architect" class="level1">
<h1>9. Solutions Architect</h1>
<section id="instantiating-applications-quickly" class="level2">
<h2 class="anchored" data-anchor-id="instantiating-applications-quickly">9.1. Instantiating Applications Quickly</h2>
<p>EC2 instances, RDS databases and other resources take time to boot up. Some common patterns to speed up boot time:</p>
<ul>
<li><p><strong>EC2 instances</strong>. Use a <strong>golden AMI</strong> which already has your applications and dependencies installed. Launch your instance from this AMI. You may have some user data or other dynamic data. Use a <strong>bootstrap script</strong> for these. A hybrid approach is to put as much static logic as possible into the golden AMI and keep the bootstrap script lean.</p></li>
<li><p><strong>RDS databases</strong>. Restore from a <strong>snapshot</strong> to quickly recover/resume without having to do lots of slow inserts.</p></li>
<li><p><strong>EBS volumes</strong>. Restore from a <strong>snapshot</strong>. The disk will already be formatted and have the correct data.</p></li>
</ul>
</section>
<section id="elastic-beanstalk" class="level2">
<h2 class="anchored" data-anchor-id="elastic-beanstalk">9.2. Elastic Beanstalk</h2>
<p>Many applications will have the same architecture: an ALB with an ASG scaling out the EC2 instances with an RDS database.</p>
<p>The pain points are around managing infrastructure and configuring all of the services each time. Ideally, we would have a single way of doing this rather than repeating the same steps every time.</p>
<p><strong>Elastic Beanstalk</strong> is a managed service to handle all of this. It automatically handles scaling, load balancing, health monitoring, configuration. You still have control to configure the resources.</p>
<p>Beanstalk is free, but you pay for the underlying resources (EC2, RDS, ALB, etc).</p>
<p>Components:</p>
<ul>
<li><strong>Application</strong> - a collection of Elastic Beanstalk components (environments, versions, configurations)</li>
<li><strong>Application Version</strong> - an iteration of your application code</li>
<li><strong>Environment</strong> - a collection of AWS resources running an application version. You can create multiple environments for dev, staging, prod, etc. There are web server and worker environment tiers</li>
</ul>
<pre><code>Create application -&gt; Upload version -&gt; Launch environment -&gt; Manage environment (upload another version to update it)</code></pre>
<p>Beanstalk supports a lot of languages.</p>
</section>
<section id="web-server-environment-vs-worker-environment" class="level2">
<h2 class="anchored" data-anchor-id="web-server-environment-vs-worker-environment">9.3. Web Server Environment vs Worker Environment</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="web_env_worker_env.png" class="img-fluid figure-img"></p>
<figcaption>Web server env vs worker env</figcaption>
</figure>
</div>
</section>
<section id="deployment-modes" class="level2">
<h2 class="anchored" data-anchor-id="deployment-modes">9.4. Deployment Modes</h2>
<p>Single instance vs high availability</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="single_instance_vs_highly_available.png" class="img-fluid figure-img"></p>
<figcaption>Single instance vs high availability</figcaption>
</figure>
</div>
</section>
</section>
<section id="s3" class="level1">
<h1>10. S3</h1>
<p>##&nbsp;10.1 S3 Objects and Buckets Simple Storage Service (S3) is used for backup and storage, disaster recovery, archive, hybrid cloud storage, application hosting, media hosting, data lakes and analytics, software delivery, static website.</p>
<p>S3 allows people to store <strong>objects</strong> (files) in <strong>buckets</strong> (directories). Bucket names must be unique <strong>globally</strong> (across all regions and all accounts) even though S3 is a region-specific service.</p>
<ul>
<li><p><strong>Buckets</strong>. Naming convention: 3-63 characters long, no uppercase or underscore, not an IP address, must start with lowercase letter or number and cannot start with xn, must not end with -s3alias.</p></li>
<li><p><strong>Objects</strong>. Objects (files) have a key which is the <strong>full</strong> path. The key is composed of prefix+object name. S3 does <strong>not</strong> have a concept of directories, objects are just files with really long keys containing slashes. The UI is misleading as it splits the buckets to look like directories for convenience/familiarity. The max object size is 5TB. Uploads of &gt;5GB must use multi-part upload.</p></li>
<li><p><strong>Metadata</strong>. Objects can contain <strong>metadata</strong>, a list of key/value pairs for system or user metadata. They can contain <strong>tags</strong>, up to 10 key/value pairs for security/lifecycle.</p></li>
</ul>
<section id="security" class="level2">
<h2 class="anchored" data-anchor-id="security">10.2. Security</h2>
<p>Can be:</p>
<ul>
<li>User-based. IAM policies</li>
<li>Resource-based. Bucket policies (allows cross-account access), Object Access Control List (ACL) for finer grained control, Bucket ACL.</li>
</ul>
<p>Use bucket policies to grant public access, grant cross-account access, or force encryption for objects at upload. We can use bucket settings or account settings to block public access, if we know that nothing should ever be public so we want to make sure nobody accidentally sets a policy that is too open.</p>
<p>The policies are <code>OR</code> based - a user can access a resource if either the IAM policy or the resource policy allows it, as long as there is not a specific deny.</p>
<p>Objects can be encrypted within S3 as an extra layer of security.</p>
<p>Policies are defined with a JSON. Important keys are:</p>
<ul>
<li>Resources: buckets and objects that this policy applies to</li>
<li>Effect: allow or deny</li>
<li>Actions: the API actions to allow or deny, like GetObject, ListObjects etc</li>
<li>Principal: the account/user to apply the policy to</li>
</ul>
</section>
<section id="s3-website" class="level2">
<h2 class="anchored" data-anchor-id="s3-website">10.3. S3 Website</h2>
<p>S3 can host static websites.</p>
<p>We must enable public read access on the bucket, otherwise users will get 403 errors.</p>
</section>
<section id="s3-versioning" class="level2">
<h2 class="anchored" data-anchor-id="s3-versioning">10.4. S3 Versioning</h2>
<p>You can version files in S3. If we upload a file with the same key, it will increment the version number.</p>
<p>This needs to be enabled at the bucket-level. It is best practice to use versioning for backup and roll back.</p>
<ul>
<li><em>Enabling</em> versioning on an existing bucket will result in <code>version=null</code> for existing objects.</li>
<li><em>Removing</em> versioning on a bucket will not delete the previous versions on existing objects.</li>
</ul>
<p>We can delete the newest version if we want to roll back to the previous version.</p>
<p>When we delete an object, we are actually updating it with a <strong>delete marker</strong> version. We can then rollback the delete marker to recover our file.</p>
</section>
<section id="replication" class="level2">
<h2 class="anchored" data-anchor-id="replication">10.5. Replication</h2>
<p><strong>Cross-Region Replication (CRR) and Same-Region Replication (SRR)</strong> are used to asynchronously copy data from one bucket to another. They can be in different accounts.</p>
<p>Versioning must be enabled in source and destination buckets, and S3 must have the required IAM permissions.</p>
<p>Use cases:</p>
<ul>
<li>CRR. Compliance, lower latency access</li>
<li>SRR. Log aggregation, sync dev vs prod environments</li>
</ul>
<p>After you enable replication, <em>only new objects are replicated</em>. To also replicate the history, use <strong>S3 Batch Replication</strong>. Deletes with delete markers are replicated, but unversioned permanent deletes are not replicated to avoid replicating malicious deletes.</p>
<p>You <strong>cannot chain</strong> replication from Bucket <code>A -&gt; B -&gt; C</code>.</p>
</section>
<section id="s3-storage-classes" class="level2">
<h2 class="anchored" data-anchor-id="s3-storage-classes">10.6. S3 Storage Classes</h2>
<p><strong>Durability</strong> represents how often you will lose an object in storage. S3 has 11 9s durability, so if you store 10 million objects you will lose a single object on average once every 10000 years.</p>
<p>This is the same for all storage classes.</p>
<p><strong>Availability</strong> is how the uptime of a service. This varies depending on the storage class.</p>
<p>Storage classes:</p>
<ul>
<li>S3 Standard: general purpose, infrequent access, one zone infrequent access</li>
<li>S3 Glacier: instance retrieval, flexible retrieval, deep archive</li>
<li>S3 Intelligent Tiering: automatically move objects between tiers based on lifecycle policies.</li>
</ul>
</section>
<section id="lifecycle-rules" class="level2">
<h2 class="anchored" data-anchor-id="lifecycle-rules">10.7. Lifecycle Rules</h2>
<p>You can transition objects between storage classes. This can be done manually, or automated through <strong>lifecycle rules</strong>.</p>
<ul>
<li><strong>Transition</strong> actions. Configure objects to transition to another storage class. E.g. standard-IA 60 days after creation or glacier for archiving after 6 months.</li>
<li><strong>Expiration</strong> actions. Configure objects to expire (delete) after a specified period. Can be used to delete old versions of files, called non-current versions, if versioning is enabled. Can also be used to delete incomplete multi-part uploads after a certain time has elapsed.</li>
</ul>
<p>Rules can be created for a certain prefix, or for certain tags.</p>
<p><strong>Amazon S3 Analytics</strong> provides storage classes analysis. It gives daily reports with recommendations for transition actions for standard and standard-IA storage classes.</p>
</section>
<section id="s3-requester-pays" class="level2">
<h2 class="anchored" data-anchor-id="s3-requester-pays">10.8. S3 Requester Pays</h2>
<p>Generally, the owner of the bucket pays for storage and data transfer costs.</p>
<p>With <strong>Requester Pays</strong> buckets, the requester pays the data transfer costs associated with their request. The requester must be authenticated in AWS (they cannot be anonymous).</p>
<p>This is useful when sharing large amounts of data with other accounts.</p>
</section>
<section id="s3-event-notifications" class="level2">
<h2 class="anchored" data-anchor-id="s3-event-notifications">10.9. S3 Event Notifications</h2>
<p>An <strong>event</strong> can be an object being created, removed, restored, replicated.</p>
<p>You can filter on the object names, e.g.&nbsp;<code>*.jpg</code></p>
<p>S3 Event Notifications can then be sent to other AWS resources, e.g.&nbsp;EC2, to trigger a downstream workflow. The notifications typically deliver in seconds but can take a minute or more.</p>
<p>The S3 service needs to have the appropriate access policy. To send event notifications to SNS, it needs an SNS Resource Access Policy. For SQS, it needs an SQS resource policy. And for Lambda functions, it needs a Lambda resource policy. Do this in the AWS console for the appropriate service (SNS, SQS, Lambda).</p>
<p>All events, regardless of whether they are going to SNS, SQS, Lambda etc, go <strong>via Amazon EventBridge</strong>. From here, you can set rules to go to over 18 AWS services as destinations.</p>
<p>EventBridge has filtering options, multiple destinations, and archive and replay capabilities.</p>
</section>
<section id="s3-performance" class="level2">
<h2 class="anchored" data-anchor-id="s3-performance">10.10 S3 Performance</h2>
<p>You can get at least 3500 PUT, COPY, POST, DELETE requests and 5500 GET/HEAD requests per second per prefix in a bucket.</p>
<p>The <strong>prefix is everything between the bucket and the file name</strong>. Remember S3 isnt really a file system, its an object store, so the prefix is just a long string that happens to have some slashes in, it isnt actually a hierarchy.</p>
<p>There are no limits to the number of prefixes you can have in a bucket.</p>
<p><strong>Multi-part upload</strong> is recommended for files &gt; 100 MB and required for files &gt; 5GB The file is divided into parts and uploaded in parallel.</p>
<p><strong>S3 transfer acceleration</strong> increases transfer speed by transferring the file to an AWS edge location and then forwarding it to the target region. So rather than uploading directly to an AZ that is far away, you can upload to your nearest location which is quicker and then transfer between regions using AWSs private network which is fast. Minimise the time spent on public networks and maximise the time on private networks.</p>
<p><strong>S3 Byte-range</strong> fetches parallelises GET requests by requesting specific byte ranges. This also gives better resilience in the case of failures. It can also be used to retrieve partial data, e.g.&nbsp;just the head of a file.</p>
</section>
<section id="s3-batch-operations" class="level2">
<h2 class="anchored" data-anchor-id="s3-batch-operations">10.11 S3 Batch Operations</h2>
<p><strong>Perform bulk operations</strong> on existing S3 objects with a single request. A job consists of a list of objects, the action to perform, optional parameters. You can use S3 Inventory to get the object list and use Athena to filter the list.</p>
<p>S3 Batch Operations will manage retries, progress tracking, completion notifications and generate reports.</p>
<p>Common use cases: modify object metadata, copy objects between buckets, encrypt objects, modify tags, restore objects from S3 Glacier, invoke a Lambda function to perform custom actions on each object.</p>
</section>
<section id="s3-storage-lens" class="level2">
<h2 class="anchored" data-anchor-id="s3-storage-lens">10.12 S3 Storage Lens</h2>
<p>Analyse storage across the entire organisation. It can identify anomalies and cost efficiencies.</p>
<p>It aggregates data for an organisation, or specific accounts, regions, buckets or prefixes.</p>
<p>You can use this to create a dashboard or export metrics as a CSV file to an S3 bucket. There is a default dashboard and you can create your own custom dashboards.</p>
<p>Available metrics:</p>
<ul>
<li>Summary metrics. Storage bytes, object count</li>
<li>Cost-optimisation metrics. Non-current version storage bytes, incomplete multi part upload storage bytes.</li>
<li>Data protection metrics. Version-enabled bucket count, MFA enabled bucket count, KMS-enabled bucket count, cross-region replication rule count.</li>
<li>Access management metrics. Object ownership bucket owner enforce bucket count.</li>
<li>Event metrics. Insights for S3 Event notifications, number of buckets with S3 events enabled.</li>
<li>Performance metrics. Transfer acceleration enabled bucket count.</li>
<li>Activity metrics. Number of requests, split get get vs put vs list etc, bytes downloaded.</li>
<li>Status code metrics. Count of 200 status codes, 403, 404 etc.</li>
</ul>
<p>Some metrics are free and some are paid. Under the free tier, metrics are available for 14 days. For paid, it is available for 15 months and automatically published to CloudWatch.</p>
</section>
</section>
<section id="s3-security" class="level1">
<h1>11. S3 Security</h1>
<section id="object-encryption" class="level2">
<h2 class="anchored" data-anchor-id="object-encryption">11.1. Object Encryption</h2>
<p>Object encryption can either be server-side or client-side.</p>
<ul>
<li>Server-Side Encryption (SSE). Can manage keys using S3-managed keys (SSE-S3), KMS (SSE-KMS) or customer-provided keys (SSE-C).</li>
<li>Client-Side Encryption.</li>
</ul>
<p>SSE-S3 is enabled by default for new buckets and objects. SSE-KMS allows usage statistics of keys to be tracked using CloudTrail. Each write and read using these keys will could towards your KMS APi usage. This can result in throttling if uploading lots of data. SSE-C requires the key to be provided in the header directly when uploading or downloading data. You can only use this from the CLI, not from the AWS console UI.</p>
<p>The option used is specified in the <em>header when uploading the object</em>.</p>
<p>For client-side encryption, the customer manages the keys and encryption themselves. Client must encrypt data before sending it to S3 and decrypt data when retrieving it. You handle this yourself and dont need to specify this in the S3 encryption settings.</p>
<p>Encryption in transit is also called SSL/TLS. Amazon S3 exposes two endpoints: HTTPS which is encrypted in transit and HTTP which is not. HTTPS is recommended.</p>
<p>Encryption in transit and/or server-side encryption can be enforced using a bucket policy. Bucket policies are evaluated before Default Encryption settings for the bucket.</p>
</section>
<section id="cors" class="level2">
<h2 class="anchored" data-anchor-id="cors">11.2. CORS</h2>
<p>Cross-Origin Resource Sharing (CORS).</p>
<pre><code>Origin = scheme (protocol) + host (domain) + port</code></pre>
<p>Using https://www.example.com The port is implied by HTTPS (443) or HTTP (80). The scheme is www and the host is example.com</p>
<p>So these have the same origin:</p>
<ul>
<li>http://www.example.com/app1</li>
<li>http://www.example.com/app2</li>
</ul>
<p>These have different origins:</p>
<ul>
<li>http://www.example.com</li>
<li>http://api.example.com</li>
</ul>
<p>CORS is a web-browser based mechanism to allow requests to other origins while visiting the main origin. The other origin must allow for requests using CORS Headers.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="cors.png" class="img-fluid figure-img"></p>
<figcaption>CORS example</figcaption>
</figure>
</div>
<p>We make a request to a web server, and it routes us to another server in a different region, for example to retrieve some images on the page.</p>
<p>On S3, if a client makes a cross-origin request on our S3 bucket, we need to enable the correct CORS headers. For example, if we are hosting a static website on S3 which contains images stored on a different S3 bucket; the image bucket must have the correct CORS headers enabled to fulfil the request. You can allow a specific region or <code>*</code> for any region.</p>
</section>
<section id="mfa-delete" class="level2">
<h2 class="anchored" data-anchor-id="mfa-delete">11.3. MFA Delete</h2>
<p>We can force users to authenticate with MFA when doing potentially destructive actions on the bucket, e.g.&nbsp;permanently deleting an object version or <code>SuspendVersioning</code> on the bucket. Only the bucket owner (root account) can enable/disable MFA Delete.</p>
<p>MFA wont be required to enable versioning or list deleted versions.</p>
</section>
<section id="s3-access-logs" class="level2">
<h2 class="anchored" data-anchor-id="s3-access-logs">11.4 S3 Access Logs</h2>
<p>For audit purposes, you can log access requests to a particular S3 bucket, whether authorised or denied.</p>
<p>The logs are written to another S3 bucket; the target logging bucket must be in the same region. <strong>Never set the logging bucket to be the monitoring bucket!</strong> Otherwise you will create an infinite loop and rack up AWS costs.</p>
</section>
<section id="pre-signed-url" class="level2">
<h2 class="anchored" data-anchor-id="pre-signed-url">11.5. Pre-signed URL</h2>
<p>Users given a pre-signed URL <strong>inherit the permissions of the user that generated it</strong> for GET/PUT requests.</p>
<p>They can be generated in the AWS console, CLU or SDK. The expiration time can be 1 minute to 168 hours.</p>
<pre><code>Within S3 console -&gt; Find the object -&gt; Object actions -&gt; Share with pre-signed URL</code></pre>
</section>
<section id="s3-glacier-vault-lock" class="level2">
<h2 class="anchored" data-anchor-id="s3-glacier-vault-lock">11.6. S3 Glacier Vault Lock</h2>
<p>This allows us to adopt a <strong>Write Once Read Many (WORM) model</strong>, which is helpful for compliant and data retention.</p>
<p>We create a Vault Lock Policy, which means the object cannot be deleted by anyone, and the policy itself cannot be edited.</p>
</section>
<section id="s3-object-lock" class="level2">
<h2 class="anchored" data-anchor-id="s3-object-lock">11.7. S3 Object Lock</h2>
<p>S3 Object Lock is a similar idea but less restrictive. Again you can adopt a WORM model, but it is <strong>for specific objects for a specified amount of time</strong>. So you can block object deletion. The retention period must be set when creating the lock.</p>
<p>There are two retention modes:</p>
<ul>
<li><strong>Compliance</strong>. Object versions cannot be overwritten or deleted by anyone user, even the root user. The retention modes cannot be edited once set. This is similar to vault lock and is the strictest setting.</li>
<li><strong>Governance</strong>. Most users cannot overwrite or delete objects or change the lock settings, but <em>some users</em> have special permissions to override this.</li>
</ul>
<p>A third option is <strong>legal hold</strong> which protects an object indefinitely, independent of the retention period. Only users with the <code>s3:PutObjectLegalHold</code> IAM permission can add or remove legal holds on objects.</p>
</section>
<section id="s3-access-points" class="level2">
<h2 class="anchored" data-anchor-id="s3-access-points">11.8. S3 Access Points</h2>
<p>This is a more granular control over permissions at the <strong>prefix level</strong> rather than the bucket policy.</p>
<p>Say we have a bucket which has folders for multiple departments: finance, sales, analytics. We want to make sure each department can only access their folder. We <em>could</em> define a complicated bucket policy to enforce this.</p>
<p>A convenient alternative is to define a Finance Access Point for that folder, a Sales Access Point for that folder, etc.</p>
<p>Each access policy looks similar to a bucket policy  it is a JSON document with the same keys  but it applies to a prefix. <strong>Each access point has its own DNS name and access point policy</strong>.</p>
<p>We can restrict the access point to only be accessible from within the VPC. You must create a VPC Endpoint to connect to the Access Point, and define a VPC Endpoint Policy that allows access to the Access Point and target bucket.</p>
</section>
<section id="s3-object-lambda" class="level2">
<h2 class="anchored" data-anchor-id="s3-object-lambda">11.9. S3 Object Lambda</h2>
<p>This allows us to <strong>transform an object as it is loaded</strong>.</p>
<p>Say you want multiple versions of a file: the original, a redacted version for customers, an enriched version for the sales department.</p>
<p>We <em>could</em> store 3 different variations of each file. But this is an inefficient use of storage.</p>
<p>We can create a lambda function for each transformation and apply it at read time before it reaches the user. Only one S3 bucket is needed, on which we create an S3 Access Point and multiple S3 Object Lambda Access Points.</p>
</section>
</section>
<section id="cloudfront" class="level1">
<h1>12. CloudFront</h1>
<section id="cloudfront-overview" class="level2">
<h2 class="anchored" data-anchor-id="cloudfront-overview">12.1 CloudFront Overview</h2>
<p>CloudFront is a <strong>Content Delivery Network (CDN)</strong>. It improves read performance by <strong>caching content at the edges</strong>, at 216 points of presence globally. I this protects against DDoS attacks.</p>
</section>
<section id="origin" class="level2">
<h2 class="anchored" data-anchor-id="origin">12.2. Origin</h2>
<p>CloudFront can have different origins:</p>
<ul>
<li><strong>S3 bucket</strong>. For distributing files and caching them at the edge. Secured using Origin Access Control (OAC).</li>
<li><strong>VPC Origin</strong>. For applications hosted in VPC private subnets - ALB, EC2 instances. CloudFront creates a VPC Origin inside the VPC and communicates with that. The old deprecated method was to create a public EC2 instance or ALB and attach a security group that only allowed access from the public IP addresses of the edge location; this is more error prone and less secure.</li>
<li><strong>Custom origin</strong>. Any public HTTP backend.</li>
</ul>
<p>The client requests data from the edge location. If the data is cached, return it. Otherwise, fetch it from the origin and cache it at that edge location ready for any future requests.</p>
<p>CloudFront differs from <strong>S3 Cross-Region Replication</strong>, but naively seems similar in principle. CloudFront caches across the global edge network (there is no region selection) and only caches files for the TTL (short lived). Good for static content that must be highly available.</p>
<p>S3 Cross-Region Replication must be set up for each region you want replication to happen in, and files are updated in near real-time. Good for dynamic content that needs to be available in a small number of regions at low latency.</p>
</section>
<section id="cloudfront-geo-restriction" class="level2">
<h2 class="anchored" data-anchor-id="cloudfront-geo-restriction">12.3. CloudFront Geo Restriction</h2>
<p>You can restrict who can access your distribution based on location. You define an Allowlist or Blocklist to allow/block access to content is the user is in a particular country. The country is determined using a 3rd party Geo-IP database.</p>
<p>A use case is to enforce copyright laws based on country.</p>
</section>
<section id="price-classes" class="level2">
<h2 class="anchored" data-anchor-id="price-classes">12.4. Price Classes</h2>
<p>The cost of data out per edge location varies.</p>
<p>You can reduce the number of edge locations for cost reduction. There are three price classes:</p>
<ul>
<li>Price Class All. All regions, best performance but most expensive.</li>
<li>Price Class 200. Most regions but excluding the most expensive.</li>
<li>Price Class 100. Only the cheapest regions.</li>
</ul>
</section>
<section id="cache-invalidation" class="level2">
<h2 class="anchored" data-anchor-id="cache-invalidation">12.5. Cache Invalidation</h2>
<p>If you update the content on the backend origin, the CloudFront edge location will only get the refreshed content after the TTL expires.</p>
<p>You can force an entire or partial cache refresh by performing a <strong>CloudFront Invalidation</strong>. You pass in a file path. This can be all files <code>*</code> or a specific folder <code>/images/*</code>.</p>
<p>It essentially <strong>tells the edge location that the content isnt there, so the next user that requests the data will get a cache miss</strong> and go to the origin. Note that it <strong>doesnt</strong> <em>refresh</em> the data per se, it invalidates the data and its only when the next user makes a request that the edge location retrieves the updated content.</p>
</section>
<section id="aws-global-accelerator" class="level2">
<h2 class="anchored" data-anchor-id="aws-global-accelerator">12.6 AWS Global Accelerator</h2>
<p>The problem AWS Global Accelerator is solving is you have an application deployed in one region, say an ALB, but your traffic is global. So some users in faraway locations have many hops before reaching our content. We want to go through the AWS network as soon as possible to minimise latency.</p>
<section id="unicast-ip-vs-anycast-ip" class="level3">
<h3 class="anchored" data-anchor-id="unicast-ip-vs-anycast-ip">12.6.1. Unicast IP vs Anycast IP</h3>
<p><strong>Unicast</strong> is what were typically familiar with. Each server holds one IP address.</p>
<p>With <strong>Anycast IP</strong>, all servers hold the <strong>same</strong> IP address, and the client is routed to the nearest one. This is how AWS Global Accelerator works.</p>
</section>
<section id="how-global-accelerator-works" class="level3">
<h3 class="anchored" data-anchor-id="how-global-accelerator-works">12.6.2. How Global Accelerator Works</h3>
<p>There is a server at each edge location. Anycast IP sends traffic directly to the nearest edge location. The traffic is then routed along AWSs private network which is faster than over public internet.</p>
<p>Two Anycast IP addresses are created for you application. It works with Elastic IP, EC2 instances, ALB, NLB, and can be public or private. It is helpful for security too because there are only two IP addresses that clients need to whitelist, but with the benefit of being globally available.</p>
</section>
<section id="global-accelerator-vs-cloudfront" class="level3">
<h3 class="anchored" data-anchor-id="global-accelerator-vs-cloudfront">12.6.3. Global Accelerator vs CloudFront</h3>
<p>CloudFront is <strong>caching</strong> data. A server at the edge location stores a cached version of your data and serves this to clients.</p>
<p>Global Accelerator is simply <strong>routing traffic through AWSs private network</strong>, there is no caching. The clients request is routed to the nearest edge location then directly to the origin through the AWS network.</p>
</section>
</section>
</section>
<section id="aws-storage-extras" class="level1">
<h1>13. AWS Storage Extras</h1>
<section id="aws-snowball" class="level2">
<h2 class="anchored" data-anchor-id="aws-snowball">13.1. AWS Snowball</h2>
<p>Snowball is a device that allows you to collect and process data at the edge, and migrate data in and out of AWS. You receive physical Snowball device that you upload data on to locally and then ship it to AWS.</p>
<p>When performing data migrations of large amounts of data or over a slow connection (over a week of transfer time), AWS Snowball is recommended.</p>
<p>Another use case is edge computing, where we want to process data at an edge location (e.g.&nbsp;a truck or a ship) that has limited internet or compute power.</p>
<p>In the UI, you specify the your shipping address and the S3 bucket you want the data uploaded to once AWS receive it, and they will post you a Snowball device.</p>
<p>A common user story is you want to upload data from the Snowball device directly in to Glacier. This is not possible, so the workaround is to upload into S3 and have a lifecycle policy on the bucket which transitions the data into Glacier.</p>
</section>
<section id="amazon-fsx" class="level2">
<h2 class="anchored" data-anchor-id="amazon-fsx">13.2 Amazon FSx</h2>
<p>FSx allows you to launch <strong>third-party file systems</strong> on AWS as a fully managed service.</p>
<p>Analogous to how RDS allows you to run third party <strong>databases</strong> like MySQL, PostgreSQL etc as a managed service. FSx is the equivalent for <strong>file systems</strong>.</p>
<ul>
<li><p><em>FSx for Windows File Server</em> is a fully managed shared drive. It supports Active Directory integration. Despite it being windows, it can also be mounted on Linux EC2 instances. There are SSD or HDD storage options. Data is backed up to S3 daily.</p></li>
<li><p><em>FSx for Lustre</em> is a parallel distributed file system. The name is derived from Linux cluster. It is used for high performance computing (HPC), ML, video processing. Storage options can be SSD or HDD. There is integration with S3 so you can read S3 as if it were a file system and write data back to S3.</p></li>
<li><p><em>FSx for NetApp ONTAP</em>. Scaled automatically and there is point in time instantaneous cloning which is helpful for testing new workloads.</p></li>
<li><p><em>FSx for OpenZFS</em>. Managed OpenZFS file system. Good for snapshots, compression and low cost, but no data duplication.</p></li>
</ul>
<p>There are two <strong>file system deployment options</strong> for FSx:</p>
<ul>
<li>Scratch file system. Temporary storage. Data is not replicated but throughput is high.</li>
<li>Persistent file system. Long term storage replicated within the same AZ. Failed files are replace within minutes.</li>
</ul>
</section>
<section id="storage-gateway" class="level2">
<h2 class="anchored" data-anchor-id="storage-gateway">13.3. Storage Gateway</h2>
<p>Hybrid cloud for storage. Some infrastructure on-premises and some on cloud. This can be due to: long cloud migrations, security requirements, compliance requirements, IT strategy</p>
<p>AWS Storage Gateway is <strong>a way to expose S3 on premises</strong>.</p>
<p>The cloud native options are:</p>
<ul>
<li>Block store. EBS, EC2 instance store</li>
<li>File storage. EFS, FSx</li>
<li>Object storage. S3, Glacier</li>
</ul>
<p>Types of Storage Gateway:</p>
<ul>
<li><p><strong>S3 file gateway</strong>. Allows our on premises to access our S3 bucket. The application server communicates with S3 file gateway via NFS or SMB. S3 file gateway communicates with S3 via HTTPS. The most recently used data is cached in the file gateway. Data can then be transferred to Glacier using a lifecycle policy. IAM roles must be created for each gateway.</p></li>
<li><p><strong>FSx file gateway</strong>. Local cache for frequently accessed data.</p></li>
<li><p><strong>Volume gateway</strong>. Block storage backed by EBS snapshots. Cached volumes allow low latency access to most recent data. Entire data set is stored on premise and there are scheduled backups to S3.</p></li>
<li><p><strong>Tape gateway</strong>. For companies with backup processes using physical tapes. With tape gateway, companies can use the same process but in the cloud.</p></li>
<li><p>Storage gateway - <strong>hardware appliance</strong>. A physical appliance that Amazon post to you which works with file gateway, volume gateway, tape gateway.</p></li>
</ul>
</section>
<section id="aws-transfer-family" class="level2">
<h2 class="anchored" data-anchor-id="aws-transfer-family">13.4. AWS Transfer Family</h2>
<p>A <strong>managed service for FTP file transfers</strong> in and out of S3. Supports FTP, FTPS, SFTP.</p>
<p>Pay per provisioned endpoint per hour + data transfer in GB.</p>
</section>
<section id="aws-datasync" class="level2">
<h2 class="anchored" data-anchor-id="aws-datasync">13.5. AWS DataSync</h2>
<p>Move large amounts of data to and from:</p>
<ul>
<li>On-premises -&gt; AWS</li>
<li>AWS -&gt; AWS</li>
</ul>
<p>Can sync to: S3, EFS, FSx. It can work in either direction.</p>
<p>Replication tasks can be scheduled hourly, daily, weekly; it is <strong>not</strong> continuous/ instantaneous. <strong>File permissions and metadata are preserved - DataSync is the only option that does this.</strong></p>
<p>AWS Snowcone comes with a DataSync agent pre-installed. It can be used on premises to sync to the cloud.</p>
</section>
<section id="comparison-of-storage-options" class="level2">
<h2 class="anchored" data-anchor-id="comparison-of-storage-options">13.6. Comparison of Storage Options</h2>
<ul>
<li>S3: Object Storage</li>
<li>S3 Glacier: Object Archival</li>
<li>EBS volumes: Network storage for one EC2 instance at a time</li>
<li>Instance Storage: Physical storage for your EC2 instance (high IOPS)</li>
<li>EFS: Network File System for Linux instances, POSIX filesystem</li>
<li>FSx for Windows: Network File System for Windows servers</li>
<li>FSx for Lustre: High Performance Computing Linux file system</li>
<li>FSx for NetApp ONTAP: High OS Compatibility</li>
<li>FSx for OpenZFS: Managed ZFS file system</li>
<li>Storage Gateway: S3 &amp; FSx File Gateway, Volume Gateway (cache &amp; stored), Tape Gateway</li>
<li>Transfer Family: FTP, FTPS, SFTP interface on top of Amazon S3 or Amazon EFS</li>
<li>DataSync: Schedule data sync from on-premises to AWS, or AWS to AWS</li>
<li>Snowcone / Snowball / Snowmobile: to move large amount of data to the cloud, physically</li>
<li>Database: for specific workloads, usually with indexing and querying</li>
</ul>
</section>
</section>
<section id="messaging-and-integration" class="level1">
<h1>14. Messaging and Integration</h1>
<p>Our applications may need to communicate with one another.</p>
<p>There are two main patterns:</p>
<ol type="1">
<li><strong>Synchronous</strong> communication. Application to application. This can be problematic if there are sudden spikes of traffic; the solution is to <em>decouple</em> applications.</li>
<li><strong>Asynchronous</strong> communication (event-based). Application to <em>queue</em> to application.</li>
</ol>
<p>Options for decoupling synchronous applications:</p>
<ul>
<li>Using SQS. <strong>Queue</strong> model.</li>
<li>Using SNS. <strong>Pub/sub</strong> model.</li>
<li>Using Kinesis. Real-time <strong>streaming</strong> model.</li>
</ul>
<section id="simple-queuing-service-sqs" class="level2">
<h2 class="anchored" data-anchor-id="simple-queuing-service-sqs">14.1. Simple Queuing Service (SQS)</h2>
<section id="overview-1" class="level3">
<h3 class="anchored" data-anchor-id="overview-1">14.1.1. Overview</h3>
<p>A <strong>producer</strong> sends messages to a <strong>queue</strong>. A <strong>consumer</strong> polls the queue for messages. The queue essentially acts as a buffer between producer and consumer.</p>
<ul>
<li><p>Standard queue. Unlimited throughput and number of messages in queue. Messages are short-lived; they can stay in the queue for 14 days maximum, and this is set to 4 days by default. The latency is low, &lt;10ms on publish and receive. Messages can be 256 KB maximum. It uses at least once delivery so it is possible to have multiple messages in the queue, and messages may be out of order (best effort ordering), so the application should be able to handle this.</p></li>
<li><p>Producing messages. The application code sends a message to the queue using the <code>SendMessage</code> API in the AWS SDK. The message is persisted in SQS until a consumer deletes it, or the retention period is reached.</p></li>
<li><p>Consuming messages. The application code may be running on premises or in AWS. The consumer polls SQS for messages (up to 10 at a time). Once the consumer processes the message, it deletes the message from the queue using the DeleteMessage API.</p></li>
<li><p>Encryption. Inflight encryption using HTTPS API. At rest encryption using KMS keys. You can use client-side encryption if the client wants to handle encryption/decryption itself.</p></li>
<li><p>IAM policies regulate access to the SQS API (SendMessage and DeleteMessage). SQS Access Policies can be used for cross-account access to SQS queues or allowing access from other services like SNS or S3; analogous to S3 bucket policies.</p></li>
</ul>
</section>
<section id="message-visibility-timeout" class="level3">
<h3 class="anchored" data-anchor-id="message-visibility-timeout">14.1.2. Message Visibility Timeout</h3>
<p>After a message is polled by a consumer, it <em>becomes invisible to other consumers</em>. This ensures that multiple consumers do not try to process the same message.</p>
<p>By default, the visibility timeout is 30 seconds, so consumers have 30 seconds to process the message before it rejoins the queue.</p>
<p>If a consumer is processing a message but knows that it needs more time, it can call the <code>ChangeMessageVisibility</code> API to get more time. This is helpful to ensure a message isnt processed twice.</p>
<p>The value of the timeout should be high enough to avoid duplicate processing from multiple consumers, but low enough that if a consumer crashes then the message is made available on the queue again in reasonable time.</p>
</section>
<section id="long-polling" class="level3">
<h3 class="anchored" data-anchor-id="long-polling">14.1.3. Long Polling</h3>
<p>When a consumer requests messages from the queue, it can optionally <em>wait for messages</em> to arrive if there are none in the queue. This is long polling.</p>
<p>This reduces the number of API calls made to SQS and improves the latency of the application.</p>
<p>The long polling wait time can be 1-20 seconds.</p>
<p>Long polling can be enabled either at the queue level or the API level using WaitTimeSeconds.</p>
</section>
<section id="fifo-queues" class="level3">
<h3 class="anchored" data-anchor-id="fifo-queues">14.1.4. FIFO Queues</h3>
<p>First In First Out ordering of messages. FIFO queues <em>guarantee the order</em> of messages at the expense of <em>limiting throughput</em>.</p>
<p>Messages are processed in order by the consumer. Ordering is done by Message Group ID which is a mandatory parameter.</p>
<p>FIFO queues also support exactly-once send capability. You add a unique <em>Deduplication ID</em> to each message.</p>
<p>The queue name when you create it must end in <code>.fifo</code></p>
</section>
<section id="sqs-with-asg" class="level3">
<h3 class="anchored" data-anchor-id="sqs-with-asg">14.1.5. SQS with ASG</h3>
<p>To increase throughput, we can <strong>scale the number of consumers</strong> horizontally.</p>
<p>A common pattern is to have EC2 instances as the consumers which are inside an Auto Scaling Group. There is a CloudWatch metric monitoring the queue length, and the ASG scales the number of instances based on that CloudWatch alarm.</p>
<p>Another common pattern is to use SQS as a buffer between EC2 instances and the database to ensure no data is dropped. If the EC2 instances are writing directly to the database, they may hit the write limit and lose data. SQS is added as an intermediate step. EC2 publishes to the SQS queue which is infinitely scalable to ensure no data is dropped. Then a different EC2 instance in a different ASG acts as the consumer to pick up messages and write them to the database in a durable way. This pattern only works if the client does not need write confirmation.</p>
</section>
</section>
<section id="simple-notification-service-sns" class="level2">
<h2 class="anchored" data-anchor-id="simple-notification-service-sns">14.2. Simple Notification Service (SNS)</h2>
<section id="overview-2" class="level3">
<h3 class="anchored" data-anchor-id="overview-2">14.2.1. Overview</h3>
<p>SNS allows you to send <strong>one message to many receivers</strong> using the <strong>pub/sub pattern</strong>. A publisher publishes a message on an SNS topic and various subscribers can read the message and act accordingly.</p>
<p>An event producer sends a message to one SNS topic. Many event receivers can listen for topic notifications. By default, subscribers see all messages but you can filter this.</p>
<p>You can have up to 12.5 million subscriptions per topic. An account can have up to 100k topics.</p>
<p>Subscribers can be: SQS, Lambda, Kinesis Data Firehose, emails, SMS and push notifications, and HTTP(S) endpoints.</p>
<p>SNS can receive data from many AWS services.</p>
<p>To publish from SNS, there are two options:</p>
<ul>
<li>Topic publish using the SDK</li>
<li>Direct publish using the mobile apps SDK</li>
</ul>
<p>Security for SNS is similar to SQS:</p>
<ul>
<li>in flight encryption using HTTPS</li>
<li>At rest encryption using KMS keys</li>
<li>Client side encryption if the client wants to handle encryption/decryption themselves</li>
</ul>
<p>IAM policies regulate access to the SNS. SNS Access Policies can be used for cross-account access to SNS topics or allowing access from other services like S3; analogous to S3 bucket policies and SQS Access Policies.</p>
</section>
<section id="fan-out-pattern" class="level3">
<h3 class="anchored" data-anchor-id="fan-out-pattern">14.2.2. Fan Out Pattern</h3>
<p>This is a common <code>SQS + SNS pattern</code>. We may want to publish a message to multiple SQS queues. We can decouple this using the fan out pattern, so the application code doesnt need to be changed for every added/removed queue.</p>
<p>We push once to SNS and let all of the SQS queues subscribe to that SNS topic.</p>
<p>Make sure the SQS queue access policy allows for SNS to write. There is cross-region delivery, meaning an SNS topic can be read by multiple SQS queues in different regions.</p>
<p>Another application is <code>S3 + SNS + SQS</code>. S3 has a limitation that you can only have one S3 Event rule per event type, prefix combination. If you want to send the same S3 event to multiple queues, publish it to SNS and let that fan out to the different SQS queues.</p>
<p>SNS can write to S3 (or another destination supported by KDF) by going via Kinesis Data Firehose.</p>
<p>Like SQS, we can have an SNS FIFO topic to ensure ordering. Again, we order by message group ID and pass a Deduplication ID. This is helpful if fanning out to SQS FIFO queues.</p>
</section>
<section id="message-filtering" class="level3">
<h3 class="anchored" data-anchor-id="message-filtering">14.2.3. Message Filtering</h3>
<p>This is an optional JSON policy applied to a subscriber to only filter on some messages. Useful if we want one queue to handle orders, one for cancellations etc.</p>
</section>
</section>
<section id="kinesis-data-streams" class="level2">
<h2 class="anchored" data-anchor-id="kinesis-data-streams">14.3. Kinesis Data Streams</h2>
<p>KDS used to Collect and store <strong>real-time</strong> streaming data.</p>
<p>A <strong>producer</strong> is application code that you write, or a Kinesis Agent if connecting to an AWS service, which writes to a Kinesis Data Stream.</p>
<p>A <strong>consumer</strong> is an application that can read from the data stream. Example consumers may be: your application, Lambda functions, Amazon Data Firehose, managed service for Apache Flink.</p>
<p>Data is retained on the data stream for up to 365 days which allows consumers to replay data. Data cannot be deleted from Kinesis, you have to wait for it to expire.</p>
<p>Data cannot be up to 1 MB; a typical use case is lots of small realtime data. Ordering is guaranteed for data with the same partition ID.</p>
<p>Encryption - KMS at-rest and HTTPS in-flight.</p>
<p>We can write optimised producers and consumers using <em>Kinesis Producer Library and Kinesis Client Library</em> respectively.</p>
<p>There are two <strong>capacity modes</strong>:</p>
<ul>
<li>Provisioned mode. You define the number of shards. Each shard allows for 1 MB/s in and 2 MB/s out. You can manually increase or decrease the number of shards and you pay per shard per hour.</li>
<li>On-demand mode. No manual intervention required. You start with the default capacity (4 shards) which scales automatically based on observed throughput peak during the last 30 days. You are billed per stream per hour and for each GB in and out.</li>
</ul>
</section>
<section id="amazon-data-firehose" class="level2">
<h2 class="anchored" data-anchor-id="amazon-data-firehose">14.4. Amazon Data Firehose</h2>
<section id="overview-3" class="level3">
<h3 class="anchored" data-anchor-id="overview-3">14.4.1. Overview</h3>
<p>Producers send records (up to 1 MB of data) to Firehose. They can optionally be transformed by a lambda function. <strong>Data is accumulated in a buffer and written as batches</strong> to a destination; therefore it is <em>near real time</em> since there is a lag between flushes of the buffer. You can optionally write all data or just failed data to an S3 backup bucket.</p>
<p>The buffer can be set to flush based on a storage limit (GB accumulated) or a time limit; it will be flushed when the first of these limits is hit.</p>
<p>It is a fully managed service, serverless with auto scaling. Supported file types: CSV, JSON, Parquet, Avro, raw text, binary data. It used to be called Kinesis Data Firehose but was renamed because it is more generally applicable beyond just Kinesis.</p>
<p>Producers can be applications, clients, SDK, Kinesis Agents, Kinesis Data Streams, CloudWatch logs and events, AWS IoT.</p>
<p>Destinations can be AWS destinations: S3, Redshift, OpenSearch. Or third party destinations: Datadog, Splunk, New Relic, MongoDB. Or you can write to custom destinations via an HTTP endpoint.</p>
</section>
</section>
<section id="comparison-of-messaging-and-integration-services" class="level2">
<h2 class="anchored" data-anchor-id="comparison-of-messaging-and-integration-services">14.5. Comparison of Messaging and Integration Services</h2>
<section id="kinesis-data-streams-vs-amazon-data-firehose" class="level3">
<h3 class="anchored" data-anchor-id="kinesis-data-streams-vs-amazon-data-firehose">14.5.1. Kinesis Data Streams vs Amazon Data Firehose</h3>
<p>Firehose does not store any data or allow for replay. There is a lag so it is not fully real time, unlike Kinesis data streams.</p>
<p>Firehose automatically scales, whereas Kinesis data streams allow a self-managed (provisioned mode) or fully managed (on demand mode) option.</p>
</section>
<section id="sqs-vs-sns-vs-kinesis" class="level3">
<h3 class="anchored" data-anchor-id="sqs-vs-sns-vs-kinesis">14.5.2. SQS vs SNS vs Kinesis</h3>
<ul>
<li>SQS - consumers <strong>pull</strong> data and delete it from the queue. You can have as many consumers as you want. No need to provision throughput.</li>
</ul>
<p>0 SNS - producers <strong>push</strong> data. Data is not persisted, so data can be lost if not delivered. No need to provision throughput.</p>
<ul>
<li>Kinesis - the standard approach is to pull data, but this can be adapted to push data using the fan-out pattern. Data is persisted so can be replayed. There are two modes to self-manage or auto-scale.</li>
</ul>
</section>
</section>
<section id="amazon-mq" class="level2">
<h2 class="anchored" data-anchor-id="amazon-mq">14.6. Amazon MQ</h2>
<p>Amazon MQ is a <strong>managed message broker service</strong> for RabbitMQ and ActiveMQ. It has both queue feature and topic feature, so <em>can be made to be roughly equivalent to SQS and SNS respectively</em>.</p>
<p>If you are already using RabbitMQ or ActiveMQ on premises, it may be easier to migrate to Amazons managed service.</p>
<p>SQS and SNS are cloud-native services, proprietary from AWS. Amazon MQ doesnt scale as well as the cloud-native services.</p>
<p><strong>It is essentially a halfway house for cases where you cant / dont want to migrate your whole application to use SQS/SNS but want some cloud features.</strong></p>
<p>For high availability, you can have MQ Brokers in two different AZs, one as active and one as failover. Both write to the same Amazon EFS storage volume so that no data is lost in the event of a failover.</p>
</section>
</section>
<section id="containers-on-aws" class="level1">
<h1>15. Containers on AWS</h1>
<section id="docker" class="level2">
<h2 class="anchored" data-anchor-id="docker">15.1. Docker</h2>
<p>Use Docker to containerise applications. Common use cases are for microservices or to lift and shift and app from on-premises to cloud.</p>
<p>Docker images are stored in a container repository. Docker Hub is a common public repository, AWS ECR is private (although there is public gallery if you want to make images in ECR public).</p>
<p>Docker vs virtual machines: <img src="docker_vs_vm.png" class="img-fluid" alt="Docker vs Virtual Machines Comparison"></p>
<p>AWS container services: ECR, ECS, EKS, Fargate.</p>
</section>
<section id="ecs" class="level2">
<h2 class="anchored" data-anchor-id="ecs">15.2. ECS</h2>
<p>Elastic Container Service. This is Amazons <strong>managed container service</strong>. You launch an ECS Task on an ECS Cluster.</p>
<p>There are two launch types: EC2 and Fargate.</p>
<section id="ec2-launch-type" class="level3">
<h3 class="anchored" data-anchor-id="ec2-launch-type">15.2.1. EC2 Launch Type</h3>
<p>An ECS cluster is essentially an cluster of EC2 instances each running an ECS Agent, which is essentially Docker and logic to register them as elements of the ECS cluster so AWS knows to start/stop/update containers within them.</p>
<p>With an EC2 launch type, you need to manage the infrastructure yourself, ie define the instance size, number, etc.</p>
</section>
<section id="fargate-launch-type" class="level3">
<h3 class="anchored" data-anchor-id="fargate-launch-type">15.2.2. Fargate Launch Type</h3>
<p>Serverless service. You dont provision the infrastructure so no need to manage EC2 instances.</p>
<p>You just create task definitions and AWS runs ECS Tasks for you based on the CPU/RAM needed. To scale, just increase the number of tasks.</p>
<p>There are two <strong>categories of IAM roles</strong> needed:</p>
<ul>
<li>EC2 Instance Profile (only for EC2 launch type). Used by the ECS Agent to make API called to the ECS service, pull images from ECR, send container logs to CloudWatch, get credentials from Secrets Manager of SSM Parameter Store. The IAM profile needs access to all of these services.</li>
<li>ECS Task Roles. Allows each task to have a specific role. Eg task A might only need access to S3, task B might only need access to RDS.</li>
</ul>
<p>We can run an ALB in front of the ECS Cluster.</p>
<p>For data persistence, we need a volume. EFS file systems can be mounted onto ECS tasks, and this works with both EC2 and Fargate launch types. EFS is serverless. EFS is a network drive, so tasks running in any AZ will share the same data. S3 cannot be mounted as a file system for ECS tasks.</p>
</section>
<section id="ecs-service-auto-scaling" class="level3">
<h3 class="anchored" data-anchor-id="ecs-service-auto-scaling">15.2.3. ECS Service Auto Scaling</h3>
<p>Automatically increase/decrease the number of ECS tasks. ECS Auto Scaling uses AWS Application Auto Scaling to scale based on: CPU utilisation, RAM utilisation or ALB request count per target.</p>
<p>There are three <strong>types of scaling</strong>:</p>
<ul>
<li>Target tracking - based on a target value for a specific CloudWatch metric</li>
<li>Step scaling - based on a CloudWatch alarm</li>
<li>Scheduled scaling - based on a date/time</li>
</ul>
<p>EC2 <strong>Service</strong> Auto Scaling is scaling the service (at the task level). It is not the same as EC2 Auto Scaling which is at the instance level. Fargate auto scaling is easier to set up because it is serverless.</p>
<p>ECS Cluster Capacity Provider is the preferred approach to scaling. It is a capacity provider paired with an auto scaling group.</p>
<p>You can use Auto Scaling Group Scaling, but this is the older discouraged method.</p>
</section>
</section>
<section id="common-ecs-architectures" class="level2">
<h2 class="anchored" data-anchor-id="common-ecs-architectures">15.2.4. Common ECS Architectures</h2>
<p>Amazon EventBridge can have a rule set up to <strong>run an ECS task in response to a trigger</strong>. For example, when a user uploads a file to a specific S3 bucket, EventBridge will start an ECS task inside a Fargate container to process the data and write it to RDS.</p>
<p>A similar approach is to use EventBridge to do the same but on a <em>schedule</em>, e.g.&nbsp;every hour do some batch processing.</p>
<p>Another scenario is processing messages in an SQS queue. ECS tasks poll the queue and auto scale depending on the number of items in the queue.</p>
<p>Another scenario is having EventBridge monitor the ECS task and trigger an event if the task fails or is stopped. It sends the event to SNS which emails the Ops team.</p>
</section>
<section id="ecr" class="level2">
<h2 class="anchored" data-anchor-id="ecr">15.3. ECR</h2>
<p>Elastic Container Registry. <strong>Store and manage docker images on AWS</strong>. It is integrated with ECS and backed by S3 under the hood. Access is controlled by IAM.</p>
<p>Images can be public or private. Public images are stored in Amazon ECR Public Gallery.</p>
</section>
<section id="eks" class="level2">
<h2 class="anchored" data-anchor-id="eks">15.4. EKS</h2>
<p>Elastic Kubernetes Service. <strong>Managed Kubernetes clusters on AWS</strong>. Kubernetes is cloud-agnostic, so can be helpful when migrating between cloud providers.</p>
<p>Like ECS, it supports EC2 and Fargate launch types.</p>
<p>Node types:</p>
<ul>
<li>Managed node groups. AWS creates and manages nodes (EC2 instances) for you. These can be spot or on demand instances.</li>
<li>Self-managed nodes. You create the nodes and register them to an EKS cluster.</li>
<li>AWS Fargate. Serverless, no maintenance required.</li>
</ul>
<p>You can attach data volumes by specifying a <code>StorageClass</code> manifest on your EKS cluster and using a Container Storage Interface (CSI) driver. EKS supports EBS, EFS and FSx; Fargate can only use EFS.</p>
</section>
<section id="aws-app-runner" class="level2">
<h2 class="anchored" data-anchor-id="aws-app-runner">15.5. AWS App Runner</h2>
<p>Managed service to make it easy to deploy web apps and APIs. You pass it your source code or container images and configure some settings like number of vCPUs, RAM, auto scaling, health checks etc. AWS creates all of the services under the hood, you dont need any infrastructure experience. It is the easiest option to get something running without much cloud knowledge.</p>
</section>
<section id="aws-app2container-a2c" class="level2">
<h2 class="anchored" data-anchor-id="aws-app2container-a2c">15.6. AWS App2Container (A2C)</h2>
<p>A2C is a CLI tool for migrating Java and .NET containers into Docker containers. Lift and shift from on-premises to cloud.</p>
<p>It generates CloudFormation templates and registers the Docker containers to ECR. You can then deploy to ECS, EKS or AppRunner.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="app2container.png" class="img-fluid figure-img"></p>
<figcaption>AWS App2Container Example</figcaption>
</figure>
</div>
</section>
</section>
<section id="serverless" class="level1">
<h1>16. Serverless</h1>
<p>Serverless is a bit misleading: there are still servers behind the scenes, <strong>you just dont manage the servers yourself</strong>.</p>
<p>It was originally branded as Function as a Service (FaaS) but now includes any managed service: database, messaging, storage, etc.</p>
<p>Serverless services in AWS: Lambda, DynamoDB, Cognito, API Gateway, S3, SNS and SQS, Kinesis Data Firehose, Aurora Serverless, Step Functions, Fargate.</p>
<section id="aws-lambda" class="level2">
<h2 class="anchored" data-anchor-id="aws-lambda">16.1. AWS Lambda</h2>
<section id="overview-4" class="level4">
<h4 class="anchored" data-anchor-id="overview-4">16.1.1. Overview</h4>
<p>Lambdas are <strong>virtual functions</strong>; there are no servers to manage. Execution time must be &lt;15 mins. They run on-demand; you are only billed when your function is running. Scaling is automated.</p>
<p><strong>Lambdas are the serverless counterparts to EC2 instances</strong>. With EC2 instances you need to intervene to scale up and down.</p>
<p>There is integration with CloudWatch for monitoring. You can have up to 10GB of RAM per function; increasing the RAM also improves the CPU and networking.</p>
<p>Lambda pricing is pay per request and compute time.</p>
<p>Supported languages: JavaScript, Python, Java, C#, Ruby. Other languages are supported via a custom runtime API.</p>
<p>You can have <strong>Lambda Container Images</strong> which must implement the Lambda Runtime API. Generally, ECS or Fargate are preferred for running arbitrary Docker images.</p>
<p>A common pattern is to use Lambda to create a <em>serverless CRON job</em>. CloudWatch Events triggers an event on a schedule, say every hour. This triggers a Lambda function to run a certain task.</p>
</section>
<section id="lambda-limits" class="level3">
<h3 class="anchored" data-anchor-id="lambda-limits">16.1.2. Lambda Limits</h3>
<p>These limits are <strong>per region</strong>.</p>
<p>Execution:</p>
<ul>
<li>Memory allocation - 128MB-10 GB in 1MB increments</li>
<li>Max execution time is 15 minutes</li>
<li>Environment variables can take up to 4 KB</li>
<li>Disk capacity in /tmp - 512 MB to 10GB</li>
<li>Concurrency executions: 1000</li>
</ul>
<p>Deployment:</p>
<ul>
<li>Deployment size (compressed zip) 50 MB, uncompressed 250 MB</li>
<li>Can use <code>/tmp</code> directory to load other files at startup</li>
<li>Environment variables 4KB</li>
</ul>
</section>
<section id="lambda-concurrency-and-throttling" class="level3">
<h3 class="anchored" data-anchor-id="lambda-concurrency-and-throttling">16.1.3. Lambda Concurrency and Throttling</h3>
<p>Concurrency limit: up to 1000 concurrent executions across all Lambda functions in our <strong>account</strong>.</p>
<p>We can set a <strong>reserved concurrency</strong> at the function-level to limit calls to individual Lambda functions. It is good practice to do this so that one application in your account scaling does not cause it to use all of the available Lambda functions in your account and cause unrelated Lambda functions for other applications to be throttled.</p>
<p>Each invocation over the concurrency limit triggers a throttle. For synchronous invocations, this returns a 429 ThrottleError. For asynchronous invocations, it will retry automatically for up to 6 hours with exponential backoff and then go to a dead letter queue.</p>
</section>
<section id="cold-starts" class="level3">
<h3 class="anchored" data-anchor-id="cold-starts">16.1.4. Cold Starts</h3>
<p>When a new instance is starting, it needs to initialise by running all of the code and dependencies. This can take a long time, causing the first request to a new instance to have higher latency than the rest.</p>
<p><strong>Provisioned concurrency</strong> is allocated before the function is invoked to avoid cold starts.</p>
</section>
<section id="lambda-snapstart" class="level3">
<h3 class="anchored" data-anchor-id="lambda-snapstart">16.1.5. Lambda SnapStart</h3>
<p>When a regular Lambda function is invoked the lifecycle it goes through is: initialise, invoke, shutdown.</p>
<p>When SnapStart is enabled, <strong>the function is pre-initialised</strong> so it can skip straight to the invoke stage.</p>
<p>When you publish a new version: lambda initialises your function, takes a snapshot of memory and disk state, then that snapshot is cached for low-latency access.</p>
</section>
<section id="customisation-at-the-edge" class="level3">
<h3 class="anchored" data-anchor-id="customisation-at-the-edge">16.1.6. Customisation at the Edge</h3>
<p>Some applications may require some form of logic at the edge location, e.g.&nbsp;to customise the CDN content.</p>
<p>An <strong>edge function</strong> is code that you write and attach to CloudFront distributions. It runs close to the user to minimise latency.</p>
<p>CloudFront provides two types:</p>
<ul>
<li>CloudFront Functions</li>
<li>Lambda@Edge</li>
</ul>
<p>Both are serverless and deployed globally. You only pay for what you use.</p>
<section id="cloudfront-functions" class="level4">
<h4 class="anchored" data-anchor-id="cloudfront-functions">CloudFront Functions</h4>
<p>These are JavaScript functions that modify the response sent from CloudFront to the user. They can change the viewer request (what the user sends to CloudFront before it reaches the origin server) or the viewer response (what the origin server sends back before it reaches the user).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="cloudfront_function.png" class="img-fluid figure-img"></p>
<figcaption>CloudFront Function</figcaption>
</figure>
</div>
</section>
<section id="lambdaedge" class="level4">
<h4 class="anchored" data-anchor-id="lambdaedge">Lambda@Edge</h4>
<p>This can modify viewer request/ response or origin request/response. You write the function in one region (us-east-1) then CloudFront replicates it across all regions. The function can be written in node.js or Python.</p>
<p>It is more expensive with a higher max execution time, so you can run more logic.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="lamba_at_edge.png" class="img-fluid figure-img"></p>
<figcaption>Lambda@Edge Function</figcaption>
</figure>
</div>
</section>
<section id="comparison" class="level4">
<h4 class="anchored" data-anchor-id="comparison">Comparison</h4>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="comparison_cloudfront_function_vs_lambda_at_edge.png" class="img-fluid figure-img"></p>
<figcaption>Comparison of CloudFront Functions vs Lambda@Edge</figcaption>
</figure>
</div>
<p>Use cases of CloudFront Functions:</p>
<ul>
<li>Cache key normalization</li>
<li>Header manipulation</li>
<li>URL rewrites or redirects</li>
<li>Request authentication &amp; authorization</li>
</ul>
<p>Use cases of Lambda@Edge Functions:</p>
<ul>
<li>Longer execution time (several ms)</li>
<li>Adjustable CPU or memory</li>
<li>Your code depends on a 3rd-party libraries (e.g., AWS SDK to access other AWS services)</li>
<li>Network access to use external services for processing</li>
<li>File system access or access to the body of HTTP requests</li>
</ul>
</section>
</section>
<section id="vpc" class="level3">
<h3 class="anchored" data-anchor-id="vpc">16.1.7. VPC</h3>
<p>By default, Lambda launches in its own AWS-owned VPC, so can only access public resources and not the resources in your VPC.</p>
<p>We can <strong>launch Lambda in a VPC</strong> if we specify the <em>VPC ID, subnets and security groups</em>. Lambda will create an ENI in your subnets.</p>
<section id="lambda-with-rds-proxy" class="level4">
<h4 class="anchored" data-anchor-id="lambda-with-rds-proxy">Lambda with RDS Proxy</h4>
<p>A common use case for launching lambda in your VPC is to connect to your RDS database. But we dont want to connect Lambdas directly to RDS, as this can result in lots of open connections and high load.</p>
<p>Instead the Lambda functions connect to an <strong>RDS proxy</strong> which <em>pools and shares database connections</em>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="lambda_with_rds_proxy.png" class="img-fluid figure-img"></p>
<figcaption>Lambda with RDS Proxy</figcaption>
</figure>
</div>
<p>This requires running Lambda in a VPC because the RDS Proxy is never publicly accessible.</p>
</section>
<section id="invoking-a-lambda-function-from-rds" class="level4">
<h4 class="anchored" data-anchor-id="invoking-a-lambda-function-from-rds">Invoking a Lambda Function from RDS</h4>
<p>You can invoke a Lambda function from within your database instance to <strong>process data events from within the database</strong>.</p>
<p>You need to allow outbound traffic to the Lambda function from within the DB instance. This is done in the database, not the AWS console.</p>
<p>This should not be confused with <strong>RDS Event Notifications</strong>. These tell you information about the database instance, not the data itself. So you can see when the database was created, stopped, started etc. But you cannot see anything about the data itself is actually processing.</p>
</section>
</section>
</section>
<section id="dynamodb" class="level2">
<h2 class="anchored" data-anchor-id="dynamodb">16.2. DynamoDB</h2>
<section id="overview-5" class="level3">
<h3 class="anchored" data-anchor-id="overview-5">16.2.1. Overview</h3>
<p>Fully managed NoSQL database with replication across multiple AZs. It is a good choice if the <strong>schema needs to change frequently</strong>.</p>
<p>Security is all handled via IAM.</p>
<p>DynamoDB auto-scales and has fast (single digit milliseconds) performance.</p>
<p>There are two classes: standard and infrequent access.</p>
<p>DynamoDB is made of <strong>tables</strong>. Each table must have a <strong>primary key</strong>, and can have an infinite number of <strong>items (rows)</strong>. Each <strong>item</strong> has <strong>attributes (columns)</strong>. These can be added to over time without having to alter a table schema.</p>
<p>Maximum item size is 400KB. Supported data types are ScalarTypes, DocumentTypes (list, map), SetTypes.</p>
<p>Capacity modes:</p>
<ul>
<li>Provisioned mode. You specify the number of reads/writes per second required and pay per Read Capacity Unit (RCU) and Write Capacity Unit (WCU). You can optionally add autoscaling.</li>
<li>On-demand mode. Reads/writes scale automatically, no capacity planning required. You pay for what you use but it is more expensive. Good for unpredictable, spiky workloads.</li>
</ul>
</section>
<section id="dynamodb-accelerator-dax" class="level3">
<h3 class="anchored" data-anchor-id="dynamodb-accelerator-dax">16.2.2. DynamoDB Accelerator (DAX)</h3>
<p>Fully managed <strong>in-memory cache for DynamoDB</strong>. Microsecond latency for cached content. No change to application logic required. Default TTL of 5 minutes.</p>
<p><strong>DAX is for caching individual objects</strong> or table scan results. <strong>Amazon Elasticache is for caching aggregation results</strong>.</p>
</section>
<section id="stream-processing" class="level3">
<h3 class="anchored" data-anchor-id="stream-processing">16.2.3. Stream Processing</h3>
<p>Ordered stream of item-level updates (create/update/delete). This is useful for realtime analytics or reacting to changes like sending welcome emails to new users.</p>
<p>DynamoDB Streams have 24 hour retention with limited number of consumers. Kinesis Data Streams have 1 year retentions, more consumers and more integration with other AWS services.</p>
</section>
<section id="global-tables" class="level3">
<h3 class="anchored" data-anchor-id="global-tables">16.2.4. Global Tables</h3>
<p>A table that is replicated in multiple regions. It is a <strong>two-way replication</strong>; changes made in either table are reflected in the other. It is an <strong>active-active replication</strong>, means applications can read and write to tables in any region.</p>
<p>DynamoDB Streams must be enabled as this is used under the hood.</p>
</section>
<section id="ttl-1" class="level3">
<h3 class="anchored" data-anchor-id="ttl-1">16.2.5. TTL</h3>
<p>Automatically delete items in the table after a certain expiry timestamp.</p>
<p>Use cases are enforcing a retention policy and reducing storage after that, or web session handling.</p>
</section>
<section id="backups-for-disaster-recovery" class="level3">
<h3 class="anchored" data-anchor-id="backups-for-disaster-recovery">16.2.6. Backups for Disaster Recovery</h3>
<p>Continuous backups for point-in-time recovery. This can be optionally enabled for the last 35 days. The recovery process creates a new table.</p>
<p>On demand backups are retained until explicitly deleted.</p>
</section>
<section id="integration-with-s3" class="level3">
<h3 class="anchored" data-anchor-id="integration-with-s3">16.2.7. Integration with S3</h3>
<p>You can export to S3 and import from it.</p>
<p>Point-in-time recovery must be enabled for export to S3.</p>
</section>
</section>
<section id="api-gateway" class="level2">
<h2 class="anchored" data-anchor-id="api-gateway">16.3. API Gateway</h2>
<section id="overview-6" class="level3">
<h3 class="anchored" data-anchor-id="overview-6">16.3.1. Overview</h3>
<p>We could connect our client directly to our Lambda function / EC2 instances, but it would need appropriate IAM permissions. Alternatively, we can have an ALB.</p>
<p>API Gateway is another alternative that <strong>acts as a proxy</strong> like ALB, but we also get some convenient <strong>features for managing our API</strong>. It is a serverless service.</p>
<p>Handles API versioning and multiple environments (dev, staging, prod), authentication, creates API keys. Support for websocket protocol, swagger and open API interfaces, caching. We can transform and validate requests and responses.</p>
<p>API gateway can integrate with:</p>
<ul>
<li>Invoke Lambda functions. This is a common way to expose a REST API.</li>
<li>HTTP. Expose any HTTP endpoints in the backend.</li>
<li>AWS service. Expose any AWS API through the API Gateway.</li>
</ul>
<p>Endpoint types:</p>
<ul>
<li>Edge-optimised. For global clients. This is the default. Requests are routed through CloudFront, although API Gateway still lives in one region.</li>
<li>Regional. For clients in the same region.</li>
<li>Private. Can only be accessed from your VPC using an interface VPC endpoint (ENI). Use a resource policy to define access.</li>
</ul>
</section>
<section id="security-1" class="level3">
<h3 class="anchored" data-anchor-id="security-1">16.3.2. Security</h3>
<p>User auth can be via:</p>
<ul>
<li>IAM roles. For internal applications.</li>
<li>Cognito. For exposing to external users.</li>
<li>Custom auth that you define.</li>
</ul>
<p>You can use ACM (AWS Certificate Manager) to define a custom HTTPS domain name.</p>
</section>
</section>
<section id="step-functions" class="level2">
<h2 class="anchored" data-anchor-id="step-functions">16.4. Step Functions</h2>
<p>Build a serverless <strong>visual workflow to orchestrate Lambda functions</strong> using step functions.</p>
<p>Can integrate with AWS services by defining a flowchart. You can optionally include a human approval step.</p>
</section>
<section id="cognito" class="level2">
<h2 class="anchored" data-anchor-id="cognito">16.5. Cognito</h2>
<p>Cognito is a service to <strong>give users an identity to interact with our web or mobile application</strong>. Typical use cases are when dealing with external users (where we dont want to set up IAM permissions), where there are hundreds of users or more, or mobile users.</p>
<p>There are two types:</p>
<ul>
<li>Cognito User Pools. Sign in functionality for app users that integrates with API Gateway and ALB. Serverless database of users.</li>
<li>Cognito Identity Pools. Also called Federated Identities. Provide AWS credentials so they can access AWS resources directly.</li>
</ul>
</section>
</section>
<section id="serverless-architecture-examples" class="level1">
<h1>17. Serverless Architecture Examples</h1>
<p>The examples in this section build an increasingly complex serverless infrastructure with improving throughput.</p>
<section id="rest-api" class="level2">
<h2 class="anchored" data-anchor-id="rest-api">17.1. REST API</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="serverless_example_rest_api.png" class="img-fluid figure-img"></p>
<figcaption>REST API Serverless Example</figcaption>
</figure>
</div>
</section>
<section id="giving-mobile-users-access-to-an-s3-bucket" class="level2">
<h2 class="anchored" data-anchor-id="giving-mobile-users-access-to-an-s3-bucket">17.2. Giving Mobile Users Access to an S3 Bucket</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="serverless_example_s3_access.png" class="img-fluid figure-img"></p>
<figcaption>S3 Serverless Example</figcaption>
</figure>
</div>
</section>
<section id="high-throughput-example" class="level2">
<h2 class="anchored" data-anchor-id="high-throughput-example">17.3. High Throughput Example</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="serverless_example_high_read_throughput.png" class="img-fluid figure-img"></p>
<figcaption>High Throughput Serverless Example</figcaption>
</figure>
</div>
<p>We can add a caching layer to improve read times.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="serverless_example_high_read_throughput_with_caching.png" class="img-fluid figure-img"></p>
<figcaption>Serverless Example with Cache</figcaption>
</figure>
</div>
</section>
</section>
<section id="databases" class="level1">
<h1>18. Databases</h1>
<section id="database-overview" class="level2">
<h2 class="anchored" data-anchor-id="database-overview">18.1. Database Overview</h2>
<p>Database types:</p>
<ul>
<li>RDBMS (SQL OLTP)</li>
<li>NoSQL</li>
<li>Object store</li>
<li>Data warehouse (SQL OLAP)</li>
<li>Search database</li>
<li>Graph database</li>
<li>Ledger</li>
<li>Time series</li>
</ul>
</section>
<section id="rds-2" class="level2">
<h2 class="anchored" data-anchor-id="rds-2">18.2. RDS</h2>
<p><strong>Managed RDBMS</strong>. Discussed in previous section.</p>
</section>
<section id="aurora-1" class="level2">
<h2 class="anchored" data-anchor-id="aurora-1">18.3. Aurora</h2>
<p><strong>Separation of storage vs compute</strong>. Aurora has a PostgreSQL and MySQL compatible API.</p>
<p>Data is stored in 6 replicas across 3 AZ.</p>
<p>There is a serverless option.</p>
</section>
<section id="elasticache-1" class="level2">
<h2 class="anchored" data-anchor-id="elasticache-1">18.4. ElastiCache</h2>
<p>Managed Redis or Memcached <strong>cache</strong>; <strong>in-memory data store</strong>.</p>
<p>Requires changes to your application code to use the cache.</p>
</section>
<section id="dynamodb-1" class="level2">
<h2 class="anchored" data-anchor-id="dynamodb-1">18.5. DynamoDB</h2>
<p>Managed serverless <strong>NoSQL database</strong>.</p>
<p>There are two capacity modes: provisioned or on-demand.</p>
<p>You can optionally add a <strong>DAX cluster</strong> for read caching.</p>
</section>
<section id="s3-1" class="level2">
<h2 class="anchored" data-anchor-id="s3-1">18.6. S3</h2>
<p><strong>Key/value store for objects</strong>.</p>
<p>Best for large objects, not many small objects. Max object size is 5 TB.</p>
</section>
<section id="documentdb" class="level2">
<h2 class="anchored" data-anchor-id="documentdb">18.7. DocumentDB</h2>
<p>DocumentDB is like a <strong>managed MongoDB</strong> (NoSQL). Analogous to how Aurora is managed SQL.</p>
</section>
<section id="neptune" class="level2">
<h2 class="anchored" data-anchor-id="neptune">18.8. Neptune</h2>
<p>Managed <strong>graph database</strong>.</p>
<p>Highly available with up to 15 read replicas across 3 AZs.</p>
<p><strong>Neptune Streams</strong> is a real-time ordered sequence of <em>every change to your graph DB</em>. The streams data is available via a REST API.</p>
</section>
<section id="amazon-keyspaces" class="level2">
<h2 class="anchored" data-anchor-id="amazon-keyspaces">18.9. Amazon Keyspaces</h2>
<p>This is a <strong>managed Cassandra</strong> (NoSQL) database service.</p>
<p>Queries are done with Cassandra Query Language (CQL).</p>
<p>There are two capacity modes: on-demand and provisioned.</p>
</section>
<section id="amazon-timestream" class="level2">
<h2 class="anchored" data-anchor-id="amazon-timestream">18.10. Amazon Timestream</h2>
<p><strong>Managed time series database</strong>.</p>
<p>Recent data is stored in memory and older data is stored in cost optimised storage.</p>
<p>Compatible with SQL and has additional time series analytics functions.</p>
</section>
</section>
<section id="data-analytics" class="level1">
<h1>19. Data Analytics</h1>
<section id="athena" class="level2">
<h2 class="anchored" data-anchor-id="athena">19.1. Athena</h2>
<section id="overview-7" class="level3">
<h3 class="anchored" data-anchor-id="overview-7">19.1.1. Overview</h3>
<p>Athena is a <strong>serverless query service</strong> to <strong>analyse data stored in S3 using SQL</strong>.</p>
<p>It supports CSV, JSON, ORC, Avro and Parquet file formats.</p>
<p>Think of it <em>like Snowflake external tables</em>. The data is in files in S3 but you can query it with SQL.</p>
<p>You need to specify an S3 bucket where query results are saved to.</p>
</section>
<section id="athena-performance-improvements" class="level3">
<h3 class="anchored" data-anchor-id="athena-performance-improvements">19.1.2. Athena Performance Improvements</h3>
<ul>
<li>Use <strong>columnar data</strong>. This means Athena has fewer columns to scan. Parquet and ORC are recommended. AWS Glue can be used for ETL jobs to convert files to parquet from other formats.</li>
<li><strong>Compress</strong> data. Smaller retrieval.</li>
<li><strong>Partition</strong> datasets in S3 to allow querying on <strong>virtual columns</strong>. Name the directories <code>column_name=value</code>, e.g.&nbsp;<code>s3://example_bucket/year=2025/month=1/date=2/data.parquet</code></li>
</ul>
</section>
<section id="federated-query" class="level3">
<h3 class="anchored" data-anchor-id="federated-query">19.1.3. Federated Query</h3>
<p>This allows you to run SQL <strong>queries across data stored in different places</strong> - Elasticache, DynamoDB, Aurora, on-premises, etc.</p>
<p>It does this using <strong>Data Source Connectors</strong> that run as a Lambda function.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="athena_federated_query.png" class="img-fluid figure-img"></p>
<figcaption>Athena Federated Query Example</figcaption>
</figure>
</div>
</section>
</section>
<section id="redshift" class="level2">
<h2 class="anchored" data-anchor-id="redshift">19.2. Redshift</h2>
<section id="overview-8" class="level3">
<h3 class="anchored" data-anchor-id="overview-8">19.2.1. Overview</h3>
<p>Redshift is based on PostgreSQL but used for OLAP not OLTP (<strong>analytics not transactions</strong>). It uses columnar storage.</p>
<p>There are two modes: provisioned cluster or serverless cluster. Provisioned mode allows you to select instance types in advance and reserve instances for cost savings.</p>
<p>Compared to Athena, Redshift is faster to join, query, aggregate. The downside is <em>you need a cluster</em> whereas <em>Athena is completely serverless</em>.</p>
<p>A Redshift cluster has a <strong>leader node</strong> for query planning and results aggregation, and <strong>compute nodes</strong> which perform queries and send results to the leader node.</p>
</section>
<section id="disaster-recovery" class="level3">
<h3 class="anchored" data-anchor-id="disaster-recovery">19.2.2. Disaster Recovery</h3>
<p>Redshift has multi0AZ for some clusters. Otherwise <strong>snapshots are required for DR</strong>.</p>
<p>Snapshots are point-in-time backups stored in S3. They are <em>incremental</em>, so only diffs are saved. They can be automated, either every 8 hours or every 5 GB, with a set retention periods. Manual snapshots are retained indefinitely.</p>
<p>Snapshots can be configured to save to another region for DR.</p>
</section>
<section id="loading-data-into-redshift" class="level3">
<h3 class="anchored" data-anchor-id="loading-data-into-redshift">19.2.2. Loading Data into Redshift</h3>
<p>Large inserts are much better.</p>
</section>
<section id="redshift-spectrum" class="level3">
<h3 class="anchored" data-anchor-id="redshift-spectrum">19.2.3. Redshift Spectrum</h3>
<p>This can be used to <strong>query data into S3 without loading it</strong>, using an existing Redshift cluster that is already running.</p>
<p>The query is sent to Redshift referencing an S3 external table, then the leader node routes the query to compute nodes, which route to Redshift Spectrum nodes, which query S3.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="redshift_spectrum.png" class="img-fluid figure-img"></p>
<figcaption>Redshift Spectrum</figcaption>
</figure>
</div>
</section>
</section>
<section id="amazon-opensearch" class="level2">
<h2 class="anchored" data-anchor-id="amazon-opensearch">19.3. Amazon OpenSearch</h2>
<p>OpenSearch is a successor to ElasticSearch. You can <strong>search any field, even partial matches</strong>. Contrast this to DynamoDB, where queries must be by primary key or indexes.</p>
<p><strong>OpenSearch is commonly used to complement other databases</strong>; for example, DynamoDB provides the retrieval capability, then writes to OpenSearch via a Lambda function so that OpenSearch can be used for the search capability.</p>
<p>OpenSearch uses its own query language, but can be made compatible with SQL using a plugin.</p>
<p>Two modes: managed cluster or serverless cluster.</p>
</section>
<section id="emr" class="level2">
<h2 class="anchored" data-anchor-id="emr">19.4. EMR</h2>
<p>Elastic MapReduce (EMR) creates <strong>Hadoop clusters to analyse and process big data</strong>. The cluster can be made of hundreds of EC2 instances. The cluster can autoscale and use spot or ondemand instances.</p>
<p>EMR comes bundled with Spark, HBase, Presto, Flink, etc so requires less provisioning and configuration.</p>
<p>Node types:</p>
<ul>
<li>Master node: manage the cluster, coordinate, health checks. Long running.</li>
<li>Core node: run tasks and store data. Long running.<br>
</li>
<li>Task node: optional nodes that just run tasks. Typically spot instances.</li>
</ul>
<p>Purchasing options:</p>
<ul>
<li>On demand</li>
<li>Reserved</li>
<li>Spot</li>
</ul>
<p>Clusters can be long running or transient (temporary).</p>
</section>
<section id="quicksight" class="level2">
<h2 class="anchored" data-anchor-id="quicksight">19.5. QuickSight</h2>
<section id="overview-9" class="level3">
<h3 class="anchored" data-anchor-id="overview-9">19.5.1. Overview</h3>
<p>Serverless BI service to <strong>create interactive dashboards</strong>. Integrated with RDS, Aurora, Athena, Redshift, S3, etc.</p>
<p>QuickSight integrates with:</p>
<ul>
<li>Most (all?) AWS data services</li>
<li>3rd party applications like Salesforce or Jira</li>
<li>Imports for files, eg xlsx, csv, json</li>
<li>On-premises databases using JDBC</li>
</ul>
<p>If data is imported into QuickSight, in-memory computation can be done using the <em>SPICE engine</em>.</p>
<p>It is possible to set up <em>column-level security</em> so users can only see columns that they are permissioned for.</p>
</section>
<section id="dashboard-and-analysis" class="level3">
<h3 class="anchored" data-anchor-id="dashboard-and-analysis">19.5.2. Dashboard and Analysis</h3>
<p>You define <strong>Users</strong> and <strong>Groups</strong> in QuickSight; note that these are <em>not the same as IAM users</em>.</p>
<p>A dashboard is a read-only snapshot of an analysis that can be shared and preserves the configuration (filtering, parameters, sort, etc).</p>
<p>Users who can see a dashboard can also access its underlying data.</p>
</section>
</section>
<section id="aws-glue" class="level2">
<h2 class="anchored" data-anchor-id="aws-glue">19.6. AWS Glue</h2>
<section id="overview-10" class="level3">
<h3 class="anchored" data-anchor-id="overview-10">19.6.1. Overview</h3>
<p>Glue is a <strong>managed ETL service</strong> (serverless).</p>
<p>It is commonly used to convert file formats, e.g.&nbsp;CSV -&gt; Parquet.</p>
<ul>
<li>Glue Job Bookmarks prevent reprocessing old data.</li>
<li>Glue DataBrew cleans and normalises data using prebuilt transformations</li>
<li>Glue Studio is a GUI to create and manage ETL jobs in Glue.</li>
<li>Glue Streaming ETL is built on Apache Spark Structured Streaming.</li>
</ul>
</section>
<section id="glue-data-catalog" class="level3">
<h3 class="anchored" data-anchor-id="glue-data-catalog">19.6.2. Glue Data Catalog</h3>
<p>An <strong>AWS Glue Data Crawler</strong> crawls the different AWS data services (S3, RDS, DynamoDB, connected on-premises databases) and <strong>writes metadata to the AWS Glue Data Catalog</strong>.</p>
<p><strong>Glue jobs can then use this to know what tables and schemas exist</strong>.</p>
<p>Athena, Redshift and EMR use this under the hood for data discovery.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="glue_data_catalog.png" class="img-fluid figure-img"></p>
<figcaption>Glue Data Catalog Example</figcaption>
</figure>
</div>
</section>
</section>
<section id="aws-lake-formation" class="level2">
<h2 class="anchored" data-anchor-id="aws-lake-formation">19.7. AWS Lake Formation</h2>
<p>A data lake is a central place for data. AWS Lake Formation is a <strong>managed service to set up data lakes</strong>. It allows you to discover, clean, catalog, transform and ingest data into your data lake, providing automated tools for this. Behind the scenes, it is <em>a layer on top of AWS Glue</em>.</p>
<p>There are blueprints for S3, RDS, relational databases, NoSQL databases, etc to make set up easy.</p>
<p><strong>Access control</strong> is fine-grained at both <strong>row-level and column-level</strong>. <strong>Centralised permissions is a common use case for using Lake Formation.</strong> The underlying S3, RDS, Aurora sources might all use different IAM rules and access policies, so you can define the user access in Lake Formation.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="lake_formation.png" class="img-fluid figure-img"></p>
<figcaption>AWS Lake Formation</figcaption>
</figure>
</div>
</section>
<section id="amazon-managed-service-for-apache-flink" class="level2">
<h2 class="anchored" data-anchor-id="amazon-managed-service-for-apache-flink">19.8. Amazon Managed Service for Apache Flink</h2>
<p>Flink is a framework for <strong>processing data streams</strong>. AWS provides a managed service to handle provisioning and backups.</p>
<p>Flink can read from Kinesis Data Streams or Amazon MSK (managed Kafka). Note that Flink does not read from Amazon Data Firehose.</p>
</section>
<section id="amazon-managed-streaming-for-apache-kafka" class="level2">
<h2 class="anchored" data-anchor-id="amazon-managed-streaming-for-apache-kafka">19.9. Amazon Managed Streaming for Apache Kafka</h2>
<p>This is called MSK. It is a fully managed Apache Kafka service, and is an <em>alternative to Amazon Kinesis</em>. It is a <strong>message broker that sits between your data sources and downstream services</strong>.</p>
<p>It allows you to create, update and delete clusters, manage the Kafka broker nodes and zookeeper nodes, deploy in multi-AZ setup, automatic recovery and persist data to EBS volumes.</p>
<p>There is a serverless option to autoscale.</p>
<p>Example of how Kafka works: <img src="managed_kafka.png" class="img-fluid" alt="Managed Kafka"></p>
<p>Difference between Kinesis Data Streams and Amazon MSK:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="kinesis_vs_msk.png" class="img-fluid figure-img"></p>
<figcaption>Kinesis Data Streams vs MSK</figcaption>
</figure>
</div>
</section>
<section id="big-data-ingestion-pipeline" class="level2">
<h2 class="anchored" data-anchor-id="big-data-ingestion-pipeline">19.10. Big Data Ingestion Pipeline</h2>
<p>Example of a big data ingestion pipelines</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="big_data_ingestion_pipeline.png" class="img-fluid figure-img"></p>
<figcaption>Big Data Ingestion Pipeline</figcaption>
</figure>
</div>
</section>
</section>
<section id="machine-learning" class="level1">
<h1>20. Machine Learning</h1>
<section id="amazon-rekognition" class="level2">
<h2 class="anchored" data-anchor-id="amazon-rekognition">20.1. Amazon Rekognition</h2>
<p><strong>Computer vision</strong>. Find objects, people, text, scenes in images and videos.</p>
<p>You can create a database of familiar faces or compare against celebrities.</p>
<p>One use case is content moderation, to detect inappropriate or offensive content. You can set a minimum confidence threshold for flagging content. Flagged content can be manually reviewed in Amazon Augmented AI (A2I).</p>
</section>
<section id="amazon-transcribe" class="level2">
<h2 class="anchored" data-anchor-id="amazon-transcribe">20.2. Amazon Transcribe</h2>
<p>Convert <strong>speech to text</strong> using automatic speech recognition.</p>
<p>You can automatically remove Personally Identifiable Information (PII) using <em>Redaction</em>, and automatically detect languages for multi-lingual audio.</p>
</section>
<section id="polly" class="level2">
<h2 class="anchored" data-anchor-id="polly">20.3. Polly</h2>
<p><strong>Text to speech</strong>.</p>
<p>Lexicon can be used to customise the pronunciation of words, or expand acronyms to the full name.</p>
<p><strong>Speech Synthesis Markup Language</strong> allows more precise customisation, such as emphasis, breathing sounds, whispering.</p>
</section>
<section id="translate" class="level2">
<h2 class="anchored" data-anchor-id="translate">20.4. Translate</h2>
<p><strong>Language translation</strong>. It can be used to localise content.</p>
</section>
<section id="lex-and-connect" class="level2">
<h2 class="anchored" data-anchor-id="lex-and-connect">20.5. Lex and Connect</h2>
<p>Amazon Lex is the technology that powers Alexa. <strong>Automatic Speech Recognition</strong> and natural language understanding. It can be used to build chatbots.</p>
<p>Amazon Connect allows you to <strong>receive calls</strong> and create contact flows like a virtual call centre. It can integrate with CRM or AWS services.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="lex_and_connect.png" class="img-fluid figure-img"></p>
<figcaption>Lex and Connect Example</figcaption>
</figure>
</div>
</section>
<section id="amazon-comprehend" class="level2">
<h2 class="anchored" data-anchor-id="amazon-comprehend">20.6. Amazon Comprehend</h2>
<p>Fully <strong>managed NLP service</strong>. Use cases include: detecting language, sentiment analysis, extract entities, organise text files by topic.</p>
<p><strong>Comprehend Medical</strong> is specifically for a clinical setting. It automatically detects Protected Health Information (PHI).</p>
</section>
<section id="sagemaker-ai" class="level2">
<h2 class="anchored" data-anchor-id="sagemaker-ai">20.7. SageMaker AI</h2>
<p>Fully <strong>managed service for data scientists</strong> to build ML models.</p>
</section>
<section id="amazon-kendra" class="level2">
<h2 class="anchored" data-anchor-id="amazon-kendra">20.8. Amazon Kendra</h2>
<p>Fully <strong>managed document search service</strong>. Extract answers from within a document. Natural language search capability. Incremental learning from user interactions to promote preferred results.</p>
</section>
<section id="amazon-personalize" class="level2">
<h2 class="anchored" data-anchor-id="amazon-personalize">20.9. Amazon Personalize</h2>
<p>Fully managed ML service to build apps with <strong>real-time personalised recommendations</strong>. Same tech used for the Amazon website.</p>
</section>
<section id="amazon-textract" class="level2">
<h2 class="anchored" data-anchor-id="amazon-textract">20.10 Amazon Textract</h2>
<p>Automatically <strong>extract text</strong>, handwriting and data <strong>from scanned documents</strong>.</p>
</section>
</section>
<section id="monitoring" class="level1">
<h1>21. Monitoring</h1>
<section id="cloudwatch" class="level2">
<h2 class="anchored" data-anchor-id="cloudwatch">21.1. CloudWatch</h2>
<section id="cloudwatch-metrics" class="level3">
<h3 class="anchored" data-anchor-id="cloudwatch-metrics">21.1.1. CloudWatch Metrics</h3>
<p>CloudWatch provides metrics for AWS services. A <strong>metric is a variable to monitor</strong> like CPU utilisation, network in throughput, etc. Metrics belong to a <strong>namespace</strong>. Metrics have <strong>timestamps</strong>. You can create CloudWatch Custom Metrics.</p>
<p><strong>A dimension is an attribute of a metric</strong> (instance ID, environment, etc). You can have 30 dimensions per metric.</p>
<p>You can create dashboards of metrics in CloudWatch.</p>
<p>CloudWatch Metric Streams are a near realtime delivery of CloudWatch metrics into another service, eg Kinesis Data Firehose or a 3rd party service like Datadog. You can filter metrics to see just a subset.</p>
</section>
<section id="cloudwatch-logs" class="level3">
<h3 class="anchored" data-anchor-id="cloudwatch-logs">21.1.3. CloudWatch Logs</h3>
<p>You can create named log groups, which usually represent an application. Within the log groups, you have log stream which are individual log files.</p>
<p>You can define a log expiration policy between 1 day and 10 years, or retain indefinitely.</p>
<p>Logs are encrypted by default and you can customise this with KMS.</p>
<p>CloudWatch Logs can send logs to:</p>
<ul>
<li>S3 - batch export with <code>CreateExportTask</code> API call, can take up to 12 hours</li>
<li>Kinesis Data Stream</li>
<li>Kinesis Data Firehose</li>
<li>AWS Lambda</li>
<li>OpenSearch</li>
</ul>
<p><strong>CloudWatch Logs Subscriptions</strong> can be used to get <em>real-time log events</em> (all services above except S3). A subscription filter can filter on relevant data. You can use these to aggregate logs across regions and accounts. A cross-account subscription is required from multi-account aggregation; the sender account must have cross-account write access in the IAM role and the recipient account must have an access policy to allow the subscription from the sender account.</p>
<p>Sources of logs can be:</p>
<ul>
<li>SDK</li>
<li>Elastic beanstalk - from application</li>
<li>ECS - from container</li>
<li>Lambda - from function</li>
<li>VPC Flow Logs</li>
<li>API Gateway</li>
<li>CloudTrail</li>
<li>Route53 - log DNS queries</li>
</ul>
<p>CloudWatch Logs Insights can be used to search and analyse data stored in CloudWatch Logs. It can query across different AWS accounts.</p>
</section>
<section id="cloudwatch-agent" class="level3">
<h3 class="anchored" data-anchor-id="cloudwatch-agent">21.1.4. CloudWatch Agent</h3>
<p>By default, logs from EC2 do not go to CloudWatch. You need to run a <strong>CloudWatch Agent on EC2</strong> to push the log files, and the EC2 instance must have the corresponding IAM permissions. A CloudWatch log agent can be set up on-premises too.</p>
<p><strong>CloudWatch Unified Agent</strong> can collect both <em>system-level metrics</em> (RAM, CPU usage etc) and <em>logs</em>. You can configure it with SSM Parameter Store. The older CloudWatch Logs Agent only does logs.</p>
</section>
<section id="cloudwatch-alarms" class="level3">
<h3 class="anchored" data-anchor-id="cloudwatch-alarms">21.1.5. CloudWatch Alarms</h3>
<p><strong>Alarms are used to trigger notifications for any metric</strong>. They can be based on different aggregations, e.g.&nbsp;min, max, % threshold, sampling. The <strong>period</strong> is the time window (seconds) to evaluate the metric.</p>
<p>Alarm states: OK, INSUFFICIENT_DATA, ALARM</p>
<p>Alarms have three main targets:</p>
<ul>
<li>EC2 instance - stop, terminate, reboot or recover and instance</li>
<li>Trigger EC2 autoscaling</li>
<li>Send a notification to SNS</li>
</ul>
<p><strong>Composite alarms</strong> monitor the state of multiple alarms, so you can combine metrics with AND or OR conditions. Composite alarms can be useful to reduce alarm noise.</p>
<p>Alarms can be created based on CloudWatch Logs Metrics Filters. To test alarms, there is a <code>set-alarm-state</code> command in the CLI.</p>
<section id="ec2-instance-recovery" class="level4">
<h4 class="anchored" data-anchor-id="ec2-instance-recovery">EC2 Instance Recovery</h4>
<p>We can perform status checks on:</p>
<ul>
<li>Instance status - check the EC2 VM</li>
<li>System status - check the underlying hardware</li>
<li>Attached EBS status - check attached EBS volumes</li>
</ul>
<p>If one or more fail, we can recover by creating a new EC2 instance with the same IP (public, private or elastic), metadata, placement group, etc.</p>
</section>
</section>
<section id="amazon-eventbridge" class="level3">
<h3 class="anchored" data-anchor-id="amazon-eventbridge">21.1.6. Amazon EventBridge</h3>
<p>EventBridge was formerly called CloudWatch Events. It can be used to <strong>schedule cron jobs, react to events, or trigger lambdas</strong>.</p>
<p>Different sources can send events to EventBridge, which then <strong>sends a JSON to a target destination</strong>.</p>
<p>EventBridge is the default event bus in AWS. Partner event bus means third-parties like Datadog can write to EventBridge. You can also create a Custom Event Bus for your own applications.</p>
<p>You can archive events sent to an event bus. Archived events can be replayed for debugging and testing.</p>
<p>EventBridge can analyse events in your bus and infer the schema. A schema registry allows you to specify a known schema in advance. Schemas can be versioned.</p>
<p>We can manage permissions for a specific event bus using a resource-based policy.</p>
</section>
<section id="cloudwatch-insights" class="level3">
<h3 class="anchored" data-anchor-id="cloudwatch-insights">21.1.7. CloudWatch Insights</h3>
<ul>
<li><p><strong>CloudWatch Container Insights</strong>. This collects, aggregates and summarises metrics and logs from <em>containers</em> on ECS, EKS and Fargate.</p></li>
<li><p><strong>CloudWatch Lambda Insights</strong>. Monitoring and troubleshooting for serverless applications running on <em>Lambda</em>. Collects, aggregates and summarises system-level metrics like CPU, memory, network. Also diagnostic info like number of cold starts, Lambda worker shutdowns.</p></li>
<li><p><strong>CloudWatch Contributor Insights</strong>. Analyse log data and create time series of contributor data, e.g.&nbsp;heaviest network users, URLs that generate the most errors.</p></li>
<li><p><strong>CloudWatch Application Insights</strong>. Automated dashboards showing issues with monitored applications. Uses SageMaker under the hood.</p></li>
</ul>
</section>
</section>
<section id="cloudtrail" class="level2">
<h2 class="anchored" data-anchor-id="cloudtrail">21.2. CloudTrail</h2>
<p>Provides <strong>governance, compliance and audit</strong> for your AWS account. It is enabled by default. It can be applied to all regions (by default) or a single region.</p>
<p>CloudTrail logs can be written to CloudWatch Logs or S3. This can be used to retain logs beyond the 90 day retention period of CloudTrail.</p>
<p>Actions from SDK, CLI, console, IAM users and roles are written to CloudTrail.</p>
<p>There are three types of CloudTrail Events:</p>
<ul>
<li><strong>Management Events</strong>. Operations performed on resources in your AWS account. You can separate read events and write events. Management events are logged by default.</li>
<li><strong>Data events</strong>. Read and write operations on data, e.g.&nbsp;S3 object-level activity. These are not logged by default as these are high volume.</li>
<li><strong>CloudTrail Insights Events</strong>. Analyses your events and tries to detect unusual activity. This needs to be enabled and costs extra. Anomalies appear in the CloudTrail console, and event is sent to S3 and and EventBridge event is generated.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="cloudtrail_insights_events.png" class="img-fluid figure-img"></p>
<figcaption>CloudTrail Insights Events</figcaption>
</figure>
</div>
<p>CloudTrail events are retained for 90 days. To persist events longer than this, log them to S3 and use Athena. <img src="cloudtrail_retention_example.png" class="img-fluid" alt="CloudTrail Long-Term Retention using S3"></p>
<section id="eventbridge-integration" class="level4">
<h4 class="anchored" data-anchor-id="eventbridge-integration">EventBridge Integration</h4>
<p>We get a CloudTrail log for any API call. If we wanted to notify on certain events, like a table being deleted, we send the event to EventBridge and then trigger an alert in SNS.</p>
</section>
</section>
<section id="aws-config" class="level2">
<h2 class="anchored" data-anchor-id="aws-config">21.3. AWS Config</h2>
<p><strong>Records configurations and changes over time</strong>. This helps with auditing and recording compliance of your AWS resources. Config rules alert when certain actions happen but they do not <strong>deny</strong> them.</p>
<p>AWS Config is a per-region service, and data can be aggregated across regions and accounts.</p>
<p>You can configure SNS alerts for changes to config and store config data in S3 for analysis with Athena.</p>
<section id="config-rules" class="level3">
<h3 class="anchored" data-anchor-id="config-rules">21.3.1. Config Rules</h3>
<p>Can use one of 75 AWS-managed config rules or create custom rules.</p>
<p>Rules can be evaluated for each <em>config change</em> or at <em>regular time intervals</em>.</p>
<p>You pay per config item per region and per config rule per region.</p>
<p>You can view the compliance of a resource over time and link it to CloudTrail API calls for that resource.</p>
</section>
<section id="remediations" class="level3">
<h3 class="anchored" data-anchor-id="remediations">21.3.2. Remediations</h3>
<p>You cannot prevent non-compliant resources but you can use SSM Automation Documents to trigger actions to remediate any compliance issues. You can create custom automation documents that trigger lambda functions.</p>
<p>You can set retries if the remediation is not successful the first time.</p>
<p>A common pattern is to use EventBridge to trigger notifications on non-compliance and set up an SNS alert to an email address or Slack channel.</p>
</section>
</section>
<section id="cloudwatch-vs-cloudtrail-vs-config" class="level2">
<h2 class="anchored" data-anchor-id="cloudwatch-vs-cloudtrail-vs-config">21.4. CloudWatch vs CloudTrail vs Config</h2>
<p>Compare and contrast.</p>
<ul>
<li><strong>CloudWatch</strong> is for <strong>performance monitoring</strong> and dashboards, alerts, and log aggregation/analysis.</li>
<li><strong>CloudTrail records API calls</strong> made within your account for audit.</li>
<li><strong>AWS Config records configuration changes</strong> and evaluates compliance of resources.</li>
</ul>
</section>
</section>
<section id="advanced-iam" class="level1">
<h1>22. Advanced IAM</h1>
<section id="aws-organisations" class="level2">
<h2 class="anchored" data-anchor-id="aws-organisations">22.1. AWS Organisations</h2>
<p>AWS Organisations allow you to <strong>manage multiple AWS accounts</strong>. The main account is the management account and others are member accounts. Member accounts can only belong to one organisation.</p>
<p>Billings are consolidated across all accounts, so the management account only needs to pay a single bill. This gives pricing benefits due to <strong>volume discounts on aggregated usage</strong>. You can share reserved instances and savings plans across member account.</p>
<p>The accounts are organised as Organizational Units (OU). An example of this below:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="aws_organsiation_ou.png" class="img-fluid figure-img"></p>
<figcaption>AWS Organisation: Organizational Units Example</figcaption>
</figure>
</div>
<p>As well as the convenience of managing a single management account and the cost savings, another benefit of AWS Organisations is <em>increased security</em>. <strong>Service Control Policies (SCP)</strong> can be applied to any and all member accounts.</p>
<section id="tag-policies" class="level3">
<h3 class="anchored" data-anchor-id="tag-policies">22.1.1. Tag Policies</h3>
<p><strong>Tag policies standardise tags across all resources</strong> in an AWS Organisation. You can define tag keys and their allowed values.</p>
<p>You can generate a report to list all tagged and non-compliant resources.</p>
</section>
<section id="iam-conditions" class="level3">
<h3 class="anchored" data-anchor-id="iam-conditions">22.1.2. IAM Conditions</h3>
<p>You can specify <strong>conditional statements in the IAM policy</strong> to only apply that rule in certain cases, e.g.&nbsp;deny certain IP addresses or allow certain regions.</p>
</section>
<section id="iam-roles-vs-resource-based-policies" class="level3">
<h3 class="anchored" data-anchor-id="iam-roles-vs-resource-based-policies">22.1.3. IAM roles vs Resource-Based Policies</h3>
<p>If we want to allow cross-account access to a resource, say an S3 bucket, we can either:</p>
<ul>
<li>Attach a resource-based policy to the S3 bucket</li>
<li>Use an IAM role as a proxy</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="iam_role_vs_resource_based_policy_access.png" class="img-fluid figure-img"></p>
<figcaption>IAM Role-based Access vs Resource-based Access</figcaption>
</figure>
</div>
<p><strong>When you assume a role you give up all other permissions</strong>, you only have access to the resources permissioned by that role.</p>
<p>There are cases where we may need to read from an S3 bucket in another account and write it to a bucket in our own account. This would require a resource-based policy, since the task needs both read and write permissions. The IAM approach would give up one or the other.</p>
<p>Amazon EventBridge uses resource-based permissions or IAM roles depending on the target resource. You need to look at the EventBridge policy to determine which it will use. Eg S3 uses resource based, ECS take use IAM.</p>
</section>
<section id="iam-permission-boundaries" class="level3">
<h3 class="anchored" data-anchor-id="iam-permission-boundaries">22.1.4. IAM Permission Boundaries</h3>
<p>Permission boundaries are supported for both users and roles, but not for groups. They act as a guardrail to <strong>limit the maximum permissions a user or role can have</strong>, regardless of the permissions granted by their IAM policies.</p>
<p>A permission boundary is an additional IAM policy definition that specifies the maximum permissions the role could be granted. The user/role still needs to have an IAM policy which defines the permissions it is actually granted.</p>
<p>If a permission is set in the IAM policy but this is outside the permission boundary, then this will NOT be granted.</p>
<p>The actual permissions a user has is the intersection of Organisations SCP, permissions boundary and IAM policy. See <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_boundaries.html">here</a>. <img src="permissions_boundary_venn_diagram.png" class="img-fluid" alt="Permissions for a User"></p>
<p>A use case of permission boundaries is to <strong>let users self-assign their policies</strong> without escalating their privileges to admin level.</p>
<p>Another use case is to <strong>restrict one specific user</strong> (e.g.&nbsp;an intern or a loose cannon) rather than applying and organisation-level SCP.</p>
<p>Explicit deny rules overall any allow rules.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="policy_evaluation_flowchart.png" class="img-fluid figure-img"></p>
<figcaption>Policy Evaluation Flowchart</figcaption>
</figure>
</div>
</section>
</section>
<section id="aws-iam-identity-centre" class="level2">
<h2 class="anchored" data-anchor-id="aws-iam-identity-centre">22.2. AWS IAM Identity Centre</h2>
<p>This used to be called <strong>AWS Single Sign On</strong>.</p>
<p>This allows you to have one login for: AWS accounts in AWS Organisations, business cloud applications (e.g.&nbsp;Microsoft 365), EC2 Windows Instances.</p>
<p>You define permission sets in the identity centre to determine who has access to what.</p>
<p>Identity providers can be the built-in identity store in IAM Identity Centre or a 3rd-party provider like Active Directory.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="iam_identity_centre_login_flow.png" class="img-fluid figure-img"></p>
<figcaption>IAM Identity Centre Login Flow</figcaption>
</figure>
</div>
</section>
<section id="aws-directory-services" class="level2">
<h2 class="anchored" data-anchor-id="aws-directory-services">22.3. AWS Directory Services</h2>
<section id="active-directory" class="level3">
<h3 class="anchored" data-anchor-id="active-directory">22.3.1. Active Directory</h3>
<p>Active Directory is a <strong>database of objects</strong> - user accounts, computers, printers, file shares, security groups - found on a <strong>Windows server</strong>. Objects are grouped into <strong>trees</strong>, trees are grouped into <strong>forests</strong>.</p>
<p>AD allows centralised security management to create account and assign permissions.</p>
</section>
<section id="aws-directory-services-1" class="level3">
<h3 class="anchored" data-anchor-id="aws-directory-services-1">22.3.2. AWS Directory Services</h3>
<p>There are three flavours of Active Directory on AWS:</p>
<ul>
<li><strong>AWS-Managed Microsoft AD</strong>. Create your own AD in AWS and establish trust connections with your on-premise AD</li>
<li><strong>AD Connector</strong>. This is a Directory Gateway, i.e.&nbsp;proxy, to redirect to your on premise AD. Users are managed on the on-premise AD.</li>
<li><strong>Simple AD</strong>. An AD-compatible managed directory solely on AWS. It cannot be joined with an on-premises AD. This could be useful if running EC2 instances which run Windows.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="active_directory_options.png" class="img-fluid figure-img"></p>
<figcaption>Comparison of Active Directory Options</figcaption>
</figure>
</div>
</section>
<section id="integrating-ad-with-iam-identity-centre" class="level3">
<h3 class="anchored" data-anchor-id="integrating-ad-with-iam-identity-centre">22.3.3. Integrating AD with IAM Identity Centre</h3>
<p>If using AWS-Managed Microsoft AD, the integration is out of the box.</p>
<p>If connecting to a self-managed directory, you either need to create a <strong>two-way trust</strong> relationship using AWS Managed Microsoft AD or use AD Connector.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="active_directory_integration.png" class="img-fluid figure-img"></p>
<figcaption>Active Directory Integration</figcaption>
</figure>
</div>
</section>
</section>
<section id="aws-control-tower" class="level2">
<h2 class="anchored" data-anchor-id="aws-control-tower">22.4. AWS Control Tower</h2>
<p>Control Tower provides an easy way to <strong>set up and govern a multi-account AWS environment</strong>. It used AWS Organisations to create organisations.</p>
<p>The benefits of Control Tower are automated environment set up, automated ongoing policy management using guardrails, detect and remediate policy violations, dashboards to monitor compliance.</p>
<p>Guardrails provide ongoing governance for your control tower environment. There are two types of guardrail:</p>
<ul>
<li><strong>Preventive guardrail</strong>. Using SCPs to <em>prevent</em> non-compliant resources.</li>
<li><strong>Detective guardrail</strong>. Using AWS Config to <em>detect</em> non-compliant resources.</li>
</ul>
</section>
</section>
<section id="security-and-encryption" class="level1">
<h1>23. Security and Encryption</h1>
<p>These topics have been covered alongside other topics so much of it is a refresher and filling in any gaps.</p>
<section id="encryption-1" class="level2">
<h2 class="anchored" data-anchor-id="encryption-1">23.1. Encryption</h2>
<section id="encryption-101" class="level3">
<h3 class="anchored" data-anchor-id="encryption-101">23.1.1 Encryption 101</h3>
<p>There are three encryption mechanisms to know about.</p>
<section id="in-flight-encryption" class="level4">
<h4 class="anchored" data-anchor-id="in-flight-encryption">In-flight Encryption</h4>
<p>Data is encrypted before sending and decrypted after receiving. TLS certificates (and SSL which is the more modern version) help with encryption.</p>
<p>In-flight encryption protects against Man in the Middle (MITM) attacks.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="inflight_encryption.png" class="img-fluid figure-img"></p>
<figcaption>In-flight Encryption</figcaption>
</figure>
</div>
</section>
<section id="server-side-encryption-at-rest" class="level4">
<h4 class="anchored" data-anchor-id="server-side-encryption-at-rest">Server-side Encryption at Rest</h4>
<p>Data is encrypted after being received. The server must have access to a key to encrypt/decrypt the data.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="server_side_encryption.png" class="img-fluid figure-img"></p>
<figcaption>Server-side Encryption</figcaption>
</figure>
</div>
</section>
<section id="client-side-encryption" class="level4">
<h4 class="anchored" data-anchor-id="client-side-encryption">Client-side Encryption</h4>
<p>Data is encrypted by the client only, never decrypted by the server. This is useful in cases where we dont trust the server.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="client_side_encryption.png" class="img-fluid figure-img"></p>
<figcaption>Client-side Encryption</figcaption>
</figure>
</div>
</section>
</section>
</section>
<section id="kms" class="level2">
<h2 class="anchored" data-anchor-id="kms">23.2. KMS</h2>
<section id="kms-overview" class="level3">
<h3 class="anchored" data-anchor-id="kms-overview">23.2.1. KMS Overview</h3>
<p><strong>Key Management Service</strong>. This handles pretty much all of the encryption in AWS and is fully integrated with IAM and other services. KMS key usage can be audited through CloudTrail.</p>
<p>There are two types of KMS Key:</p>
<ul>
<li><strong>Symmetric</strong>. A single key is used to both <em>encrypt and decrypt</em>. You never get access to the KMS Key directly, you call the KMS API to use it.</li>
<li><strong>Asymmetric</strong>. Public key to encrypt and private key to decrypt. RSA or ECC <em>key pairs</em>. You can download the public key from KMS but not the private key.</li>
</ul>
<p>Keys can be:</p>
<ul>
<li>AWS-owned keys</li>
<li>AWS-managed keys</li>
<li>Customer-managed keys created in KMS</li>
<li>Customer-managed keys imported into KMS</li>
</ul>
<p>Customer-managed keys cost $1/month. Imported keys are also charged per API call. Keys are automatically rotated.</p>
<p>KMS keys are per region and cannot be copied across regions. If copying an encrypted EBS volume to another region, you re-encrypt it with a key from the destination region.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="copy_encrypted_snapshot_across_regions.png" class="img-fluid figure-img"></p>
<figcaption>Copying Snapshots Across Regions</figcaption>
</figure>
</div>
</section>
<section id="kms-key-policies" class="level3">
<h3 class="anchored" data-anchor-id="kms-key-policies">23.2.2. KMS Key Policies</h3>
<p>You can control access to your KMS keys. This is similar to S3 bucket policies.</p>
<p>The default KMS key policy gives all users access to the default KMS key. You can create a custom KMS key policy to define the roles and users who can use and administer keys.</p>
</section>
<section id="multi-region-keys" class="level3">
<h3 class="anchored" data-anchor-id="multi-region-keys">23.2.3. Multi-region Keys</h3>
<p>You can replicate a primary key across regions, creating a <strong>replica key</strong> with the same key ID in the target region. They are synced so when the primary is rotated the replicas are updated too.</p>
<p>This allows you to use keys interchangeably across regions. You can encrypt in one region and decrypt in other regions. This avoids the need to re-encrypt when moving data across regions, or making cross-region KMS calls.</p>
<p>KMS multi-region keys are NOT global. Each key is managed independently with its own key policy.</p>
<p>Use cases are when you want global client-side encryption, or if you are using encryption on a global database service like DynamoDB or Aurora.</p>
</section>
<section id="s3-replication-encryption-considerations" class="level3">
<h3 class="anchored" data-anchor-id="s3-replication-encryption-considerations">23.3.4. S3 Replication Encryption Considerations</h3>
<p>Unencrypted objects and SSE-S3 encrypted objects are replicated by default. Objects encrypted with SSE-C (customer-provided key) can be replicated.</p>
<p>Objects encrypted with SSE-KMS need to have replication enabled in the options. They are not replicated by default.</p>
<ul>
<li>Specify the KMS Key to encrypt objects in the target bucket</li>
<li>Update the KMS Key Policy for the target key</li>
<li>Appropriate IAM roles with <code>kms:Decrypt</code> permissions for the source key and <code>kms:Encrypt</code> for the target key</li>
</ul>
<p>You may get KMS throttling errors as there are more API calls involved. You can increase your service quota.</p>
<p>You can use multi-region KMS Keys for S3 replication but they are treated as independent keys by S3, so it will still re-encrypt your data with the (replicated) target key.</p>
</section>
<section id="sharing-an-ami-encrypted-with-kms" class="level3">
<h3 class="anchored" data-anchor-id="sharing-an-ami-encrypted-with-kms">23.3.5. Sharing an AMI Encrypted with KMS</h3>
<ol type="1">
<li>The AMI is encrypted in the source account</li>
<li>Modify the Launch Permission image attribute to allow the target account to launch it</li>
<li>Share the KMS key for the target account to use it, with a key policy</li>
<li>The target account must have IAM permissions: DescribeKey, ReEncrypt, CreateGrant, Decrypt</li>
<li>The target account can now launch the AMI and optionally encrypt it using its own KMS key</li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="sharing_encrypted_ami.png" class="img-fluid figure-img"></p>
<figcaption>Sharing an Encrypted AMI</figcaption>
</figure>
</div>
</section>
</section>
<section id="ssm-parameter-store" class="level2">
<h2 class="anchored" data-anchor-id="ssm-parameter-store">23.3. SSM Parameter Store</h2>
<section id="overview-11" class="level3">
<h3 class="anchored" data-anchor-id="overview-11">23.3.1. Overview</h3>
<p><strong>Secure storage for configuration and secrets</strong>. You can optionally encrypt these using KMS.</p>
<p>It allows <em>version tracking</em> of these. Security is through IAM and notifications are through Amazon EventBridge.</p>
<p>You can store parameters in a hierarchy, e.g.&nbsp;<code>my-department/app-name-1/prod/db-url</code></p>
<p>You can reference secrets stored in Secrets Manager through a specific path in Parameter Store: <code>/aws/reference/secretsmanager/&lt;secret-ID-in-Secrets-Manager&gt;</code></p>
<p>There are public parameters issued by AWS that you can access through <code>/aws/service</code> for example the latest Amazon Linux AMI version available in a region.</p>
<p>There are standard and advanced parameter tiers. The differences are in the number and size of parameters you can store, and advance allows parameter policies.</p>
</section>
<section id="parameter-policies" class="level3">
<h3 class="anchored" data-anchor-id="parameter-policies">23.3.2. Parameter Policies</h3>
<p>You can assign a TTL to a parameter to <strong>force updates/deletes</strong> for sensitive data after an expiry date.</p>
</section>
</section>
<section id="aws-secrets-manager" class="level2">
<h2 class="anchored" data-anchor-id="aws-secrets-manager">23.4. AWS Secrets Manager</h2>
<section id="overview-12" class="level3">
<h3 class="anchored" data-anchor-id="overview-12">23.4.1. Overview</h3>
<p>A newer AWS service meant specifically for storing secrets. You can force rotation of secrets every X days, and automate the generation of new secrets using a Lambda. Secrets are encrypted using KMS.</p>
<p>It integrates nicely with Amazon RDS and other services.</p>
</section>
<section id="multi-region-secrets" class="level3">
<h3 class="anchored" data-anchor-id="multi-region-secrets">24.4.2. Multi-region Secrets</h3>
<p>You can replicate secrets across regions. Secrets Manager will keep these in sync.</p>
<p>This is helpful for disaster recovery; if the region of the primary secret becomes unavailable you can promote a replica secret in its place.</p>
</section>
</section>
<section id="aws-certificate-manager-acm" class="level2">
<h2 class="anchored" data-anchor-id="aws-certificate-manager-acm">23.5. AWS Certificate Manager (ACM)</h2>
<section id="overview-13" class="level3">
<h3 class="anchored" data-anchor-id="overview-13">23.5.1. Overview</h3>
<p>ACM allows you to <strong>provision and manage TLS certificates</strong>, which provide in-flight encryption for websites (HTTPS).</p>
<p>You can automatically renew certificates through TLS. There is integration with services like elastic load balancers, CloudFront Distributions, API Gateway. You cannot use ACM with EC2; the certificates cant be extracted.</p>
<p>Free for public TLS certificates.</p>
</section>
<section id="requesting-public-certificates" class="level3">
<h3 class="anchored" data-anchor-id="requesting-public-certificates">23.5.2. Requesting Public Certificates</h3>
<ul>
<li>List domain names to be included in certificate. This can be the fully qualified domain name or wildcard domains <code>*.example.com</code></li>
<li>Select validation method - DNS validation or email validation</li>
<li>It takes a few hours to get verified</li>
</ul>
<p>Once you have a certificate, it is enrolled for automatic renewal. ACM automatically renews any certificates it generates 60 days before expiry.</p>
<p>Certificates which are imported into ACM need to be renewed manually. EventBridge or AWS Config can be used to trigger alerts when a certificate is near expiry.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="acm_import_public_certificates.png" class="img-fluid figure-img"></p>
<figcaption>ACM Public Certificates</figcaption>
</figure>
</div>
</section>
</section>
<section id="web-application-firewall-waf" class="level2">
<h2 class="anchored" data-anchor-id="web-application-firewall-waf">23.6. Web Application Firewall (WAF)</h2>
<section id="overview-14" class="level3">
<h3 class="anchored" data-anchor-id="overview-14">23.6.1. Overview</h3>
<p>Protects your web applications <strong>common web exploits</strong> on layer 7 (HTTP).</p>
<p>WAF can be deployed on: ALB, API Gateway, CloudFront, Cognito User Pool.</p>
</section>
<section id="web-acl" class="level3">
<h3 class="anchored" data-anchor-id="web-acl">23.6.2. Web ACL</h3>
<p>Once WAF is deployed to an application, you can set up a Web ACL (<strong>access control list</strong>) to enforce rules based on:</p>
<ul>
<li>IP address</li>
<li>HTTP headers or body - protect against SQL injection</li>
<li>Geo-match - block certain countries</li>
<li>Rate-based rules - protect against DDoS</li>
</ul>
<p>Web ACL is regional except for CloudFront. A <strong>rule group</strong> is a reusable set of rules that you can add to a web ACL.</p>
<p>A common use case is to get a <em>fixed IP while using WAF with a load balancer</em>. A network load balancer has a fixed IP but operates at level 4 so we cant use a WAF with it. We can use an application load balancer with Global Accelerator to get a fixed IP, then use a WAF with the ALB.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="waf_fixed_ip.png" class="img-fluid figure-img"></p>
<figcaption>WAF with Fixed IP</figcaption>
</figure>
</div>
</section>
</section>
<section id="aws-shield" class="level2">
<h2 class="anchored" data-anchor-id="aws-shield">23.7. AWS Shield</h2>
<p><strong>Protects against DDoS attacks</strong>.</p>
<p>AWS Shield Standard is free and protects against SYN/UDP Floods, Reflection attacks and other layer 3/4 attacks.</p>
<p>AWS Shield Advanced provides optional protection against more sophisticated attacks and includes 24/7 support. It costs $3000 per month per organisation.</p>
</section>
<section id="aws-firewall-manager" class="level2">
<h2 class="anchored" data-anchor-id="aws-firewall-manager">23.8. AWS Firewall Manager</h2>
<p><strong>Manage rules in all accounts</strong> of an AWS Organisation. Rules are applied to new resources as they are created to ensure compliance.</p>
<p>Security policy is a common set of security rules. Policies are created at the region level.</p>
<p>WAF, Shield and Firewall Manager work together: <em>define</em> Web ACL rules in <strong>WAF</strong>, <em>apply</em> them across accounts with <strong>Firewall</strong> Manager, and get <em>additional protections</em> through <strong>Shield</strong>.</p>
</section>
<section id="best-practices-for-ddos-resiliency" class="level2">
<h2 class="anchored" data-anchor-id="best-practices-for-ddos-resiliency">23.9. Best Practices for DDoS Resiliency</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="ddos_resiliency_best_practice.png" class="img-fluid figure-img"></p>
<figcaption>DDoS Resiliency Best Practices</figcaption>
</figure>
</div>
<p>Best practices:</p>
<ul>
<li>BP1: CloudFront protects against common attacks. An alternative is Global Accelerator with AWS Shield.</li>
<li>BP2: Detect and filter malicious requests with WAF. AWS Shield Advanced will automatically create rules for WAF.</li>
<li>BP3: Route 53 has DDoS protection mechanisms.</li>
<li>BP4: Obfuscate AWS resources. CloudFront, API Gateway, ELB means the attacker never knows whether youre using EC2, Fargate, Lambda behind the scenes.</li>
<li>BP5: Security groups and network ACLs filter traffic from specific IPs.</li>
<li>BP6: infrastructure layer defence protects EC2 instances against high traffic. ELB spreads traffic across instances.</li>
<li>BP7: EC2 with auto-scaling</li>
</ul>
</section>
<section id="amazon-guardduty" class="level2">
<h2 class="anchored" data-anchor-id="amazon-guardduty">23.10. Amazon GuardDuty</h2>
<p>Intelligent <strong>threat discovery and anomaly detection</strong> using ML.</p>
<p>Input data includes: CloudTrail Events logs, VPC Flow, DNS logs, other optional logs (EKS, EBS, RDS, S3 Data Events).</p>
<p>You can create EventBridge tiles to be notified of any findings, and those rules can create Lambdas or trigger SNS notifications.</p>
<p>GuardDuty has a specific finding to protect against Cryptocurrency attacks.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="aws_guardduty.png" class="img-fluid figure-img"></p>
<figcaption>AWS GuardDuty</figcaption>
</figure>
</div>
</section>
<section id="amazon-inspector" class="level2">
<h2 class="anchored" data-anchor-id="amazon-inspector">23.11. Amazon Inspector</h2>
<p>Service that allows for <strong>automated security assessments</strong>.</p>
<ul>
<li>Assess EC2 instances for unintended network access, OS vulnerabilities</li>
<li>Assess container images as they are pushed</li>
<li>Assess Lambda functions for vulnerabilities in code and package dependencies</li>
</ul>
<p>Amazon Inspector reports findings to AWS Security and can optionally trigger EventBridge events. It assigns a risk score to each vulnerability found.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="aws_inspector.png" class="img-fluid figure-img"></p>
<figcaption>AWS Inspector</figcaption>
</figure>
</div>
</section>
<section id="amazon-macie" class="level2">
<h2 class="anchored" data-anchor-id="amazon-macie">23.12. Amazon Macie</h2>
<p>Macie is a managed data security and data privacy service that uses ML to <strong>scan for Personally Identifiable Information</strong> (PII) and other sensitive data.</p>
<p>It scans S3 buckets once enabled and will notify via EventBridge.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="aws_macie.png" class="img-fluid figure-img"></p>
<figcaption>Amazon Macie</figcaption>
</figure>
</div>
</section>
</section>
<section id="vpc-1" class="level1">
<h1>24. VPC</h1>
<section id="cidr-private-ip-public-ip" class="level2">
<h2 class="anchored" data-anchor-id="cidr-private-ip-public-ip">24.1. CIDR, Private IP, Public IP</h2>
<section id="cidr" class="level3">
<h3 class="anchored" data-anchor-id="cidr">24.1.1. CIDR</h3>
<p><strong>Classless Inter-Domain Routing (CIDR)</strong> is a method for <strong>allocating IP addresses</strong>. They allow us to define an <strong>IP address range</strong>.</p>
<p>A CIDR consists of two components:</p>
<ul>
<li><strong>Base IP</strong>. Represents an IP address contained in the range. Eg 192.168.0.0</li>
<li><strong>Subnet mask</strong>. Defines how many bits can change in the IP address. Eg /8 corresponds to 255.0.0.0, /32 corresponds to 255.255.255.255</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="subnet_masks.png" class="img-fluid figure-img"></p>
<figcaption>Subnet Masks Example</figcaption>
</figure>
</div>
<p>See <a href="https://www.ipaddressguide.com/cidr">this website</a> for a guide on IP address ranges.</p>
</section>
<section id="public-vs-private-ipv4" class="level3">
<h3 class="anchored" data-anchor-id="public-vs-private-ipv4">24.1.2. Public vs Private IPv4</h3>
<p>The Internet Assigned Numbers Authority (IANA) established blocks for IPv4 addresses for use by private (LAN) and public (internet) addresses.</p>
<p>Private IP can only allow certain values.</p>
<p>This is where CIDR becomes relevant.</p>
</section>
</section>
<section id="default-vpc" class="level2">
<h2 class="anchored" data-anchor-id="default-vpc">24.2. Default VPC</h2>
<section id="overview-15" class="level3">
<h3 class="anchored" data-anchor-id="overview-15">24.2.1. Overview</h3>
<p>All new AWS accounts have a default VPC.</p>
<p>New EC2 instances are launched into the default VPC if no subnet is specified. The default VPC has internet connectivity and all EC2 instances within it have public IPv4 addresses. We also get public and private IPv4 DNS names.</p>
<p>It is <em>best practice to create your own VPC</em> for production processes rather than relying on the default VPC.</p>
</section>
<section id="creating-our-own-vpc" class="level3">
<h3 class="anchored" data-anchor-id="creating-our-own-vpc">24.2.2. Creating Our Own VPC</h3>
<p>VPC is a <strong>Virtual Private Cloud</strong>. We can have multiple VPCs in a region. The max is 5 per region but this is a soft limit that can be increased.</p>
<p>The max CIDR per VPC is 5. For each CIDR, min size is <code>/28</code> and max size is <code>/16</code>.</p>
<p>Because VPCs are private, only IP addresses in the Private IPv4 ranges are allowed.</p>
<p>Your VPC CIDR should NOT overlap with your other networks, e.g.&nbsp;your corporate network. If we want to connect them together, we need to make sure the IP addresses do not overlap.</p>
<p>In the AWS console:</p>
<pre><code>VPC -&gt; Create VPC -&gt; define CIDR block and other details</code></pre>
</section>
<section id="adding-subnets" class="level3">
<h3 class="anchored" data-anchor-id="adding-subnets">24.2.3. Adding Subnets</h3>
<p><strong>A subnet is a sub-range of IP addresses</strong>. Subnets can be public or private.</p>
<p>AWS reserves 5 IP addresses in each subnet, the first 4 and last 1:</p>
<ul>
<li>0 - network address</li>
<li>1 - reserved for VPC router</li>
<li>2 - reserved for mapping to Amazon-provided DNS</li>
<li>3 - reserved for future use</li>
<li>255 - Network Broadcast Address. AWS doesnt support broadcast in a VPC, so this is reserved</li>
</ul>
<p>To create a subnet in AWS console:</p>
<pre><code>VPC -&gt; Subnets -&gt; specify name, region, CIDR block</code></pre>
</section>
<section id="internet-gateway-igw" class="level3">
<h3 class="anchored" data-anchor-id="internet-gateway-igw">24.2.4. Internet Gateway (IGW)</h3>
<p>IGW <strong>allows resources in a VPC to connect to the internet</strong>, e.g.&nbsp;EC2 instances. It is created separately of a subnet. <strong>One VPC can only be attached to one IGW and vice versa</strong>.</p>
<p>It scales horizontally and is highly available and redundant.</p>
<p>IGW on its own does not allow internet access, we <strong>also need to edit the route tables</strong>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="igw_route_tables.png" class="img-fluid figure-img"></p>
<figcaption>Internet Gaetway and Route Tables</figcaption>
</figure>
</div>
<p>There is a default route table that is associated with subnets which dont explicitly specify a route table.</p>
<p>To create our own route table in the AWS console:</p>
<pre><code>VPC -&gt; Route tables -&gt; Create route table -&gt; specify a name and associated VPC</code></pre>
<p>Then we can click on that route table and assign subnets to it. We can edit the routes on a route table and specify destination IP address and target resources that each route applies to.</p>
</section>
<section id="bastion-hosts" class="level3">
<h3 class="anchored" data-anchor-id="bastion-hosts">24.2.3. Bastion Hosts</h3>
<p>Sometimes we may want to <strong>allow users outside of our VPC to access a resource inside a private subnet</strong>.</p>
<p><strong>A bastion host is an EC2 instance inside a public subnet of our VPC that can ssh into an EC2 instance inside the private subnet.</strong></p>
<p>Then a user can ssh into the public subnet EC2 instance, and from there ssh into the private subnet EC2 instance.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="bastion_host.png" class="img-fluid figure-img"></p>
<figcaption>Bastion Host</figcaption>
</figure>
</div>
<p>The bastion host security group must allow access from the internet on port 22. We can restrict this with a CIDR, e.g.&nbsp;the public CIDR of your corporate network, to only allow restricted access.</p>
<p>The private subnet EC2 instance security group must allow access from the private IP address (or security group) of the public EC2 instance.</p>
</section>
</section>
<section id="nat" class="level2">
<h2 class="anchored" data-anchor-id="nat">24.3. NAT</h2>
<p><strong>NAT = Network Address Translation</strong></p>
<section id="nat-instances" class="level3">
<h3 class="anchored" data-anchor-id="nat-instances">24.3.1. NAT Instances</h3>
<blockquote class="blockquote">
<p>(NAT Instances are outdated and NAT Gateway is the preferred solution now.)</p>
</blockquote>
<p><strong>NAT instances allow EC2 instances in private subnets to connect to the internet.</strong> The NAT instance must be launched in a public subnet and have a fixed elastic IP attached. We also need to disable the Source destination check setting on the EC2 instance instance. Route tables must be configured to route traffic from private subnets to the NAT instance.</p>
<p>A pre-configured Amazon Linux AMI is available for NAT instances, although it has reached end of life. NAT instances are not highly available or resilient out of the box, you need to create an ASG.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="nat_instance.png" class="img-fluid figure-img"></p>
<figcaption>NAT Instances</figcaption>
</figure>
</div>
</section>
<section id="nat-gateway" class="level3">
<h3 class="anchored" data-anchor-id="nat-gateway">24.3.2. NAT Gateway</h3>
<p><strong>NAT Gateway is an AWS-managed NAT instance</strong> with higher bandwidth, availability and no admin required. You pay per hour and per bandwidth.</p>
<p>NAT Gateway is created in a specific AZ and uses an Elastic IP. It cant be used by EC2 instances in the same subnet, only from other subnets.</p>
<p>We need multiple NATs in each AZ for fault tolerance.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="nat_gateway.png" class="img-fluid figure-img"></p>
<figcaption>NAT Gateway</figcaption>
</figure>
</div>
</section>
</section>
<section id="security-groups-and-network-acl" class="level2">
<h2 class="anchored" data-anchor-id="security-groups-and-network-acl">24.4. Security Groups and Network ACL</h2>
<section id="overview-16" class="level3">
<h3 class="anchored" data-anchor-id="overview-16">24.4.1. Overview</h3>
<p><strong>A Network ACL sits before the subnet to handle incoming requests according to inbound rules</strong>. It is <strong>like a firewall</strong> which controls traffic to and from subnets.</p>
<p>You can have one NACL per subnet, and new subnets are assigned the default NACL.</p>
<p>NACL rules have a number, and the first rule match (i.e.&nbsp;lowest rule number) takes precedent and drives the decision. The last rule is <code>*</code> which denies any unmatched requests. AWS recommended best practice is to increment rule numbers by 100 so that you can later add rules in between.</p>
<blockquote class="blockquote">
<p>The distinction between security groups and NACLs is subtle but important</p>
</blockquote>
<p><strong>Security Groups are stateful</strong>. If an incoming request is allowed in, the corresponding response will always be allowed out; the security groups outbound rules are ignored.</p>
<p><strong>NACL is stateless</strong>. A request may be allowed in according to the inbound rules, but the response could still be blocked by the NACLs outbound rules.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="security_group_vs_nacl.png" class="img-fluid figure-img"></p>
<figcaption>Security Group vs NACL</figcaption>
</figure>
</div>
<p>If you have multiple subnets, you need to make sure every combination of inbound and outbound rules are allowed.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="nacl_multiple_subnets.png" class="img-fluid figure-img"></p>
<figcaption>NACL for Multiple Subnets</figcaption>
</figure>
</div>
<p>Comparison table: <img src="security_group_vs_nacl_table.png" class="img-fluid" alt="Security Group vs NACL Table"></p>
</section>
<section id="default-nacl" class="level3">
<h3 class="anchored" data-anchor-id="default-nacl">24.4.2. Default NACL</h3>
<p>The default allows everything inbound and outbound for its associated subnets.</p>
<p>It is best practice to not modify the default NACL and instead create a custom NACL.</p>
</section>
<section id="ephemeral-ports" class="level3">
<h3 class="anchored" data-anchor-id="ephemeral-ports">24.4.3. Ephemeral Ports</h3>
<p>For any two endpoints to establish a connection, they must use ports. Clients connect to the server using a fixed port, and expect a response on an <strong>ephemeral port</strong>. This is a temporary port that is open just for this connection.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="ephemeral_ports.png" class="img-fluid figure-img"></p>
<figcaption>Ephemeral Ports</figcaption>
</figure>
</div>
<p>Ephemeral ports are important to consider when dealing with NACLs because we need to configure the rules to allow inbound/outbound requests on the appropriate port range.</p>
</section>
</section>
<section id="vpc-peering" class="level2">
<h2 class="anchored" data-anchor-id="vpc-peering">24.5. VPC Peering</h2>
<p>VPC peering is for when we want to <strong>privately connect two VPCs using AWSs private network</strong>, to make them behave as if they were one network.</p>
<p>You still need to update route tables in each VPCs subnets to ensure EC2 instances can communicate with each other.</p>
<p>They cannot have overlapping CIDRs.</p>
<p>VPC peering is NOT transitive. If we peer from A to B, and B to C, then A will NOT be connected to C unless we also explicitly peer from A to C.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="vpc_peering.png" class="img-fluid figure-img"></p>
<figcaption>VPC Peering</figcaption>
</figure>
</div>
<p>VPC peering can be set up across different AWS accounts and regions. When peering across accounts in the same region, you can reference a security group which is convenient as you do not have to reference the CIDR.</p>
</section>
<section id="vpc-endpoints" class="level2">
<h2 class="anchored" data-anchor-id="vpc-endpoints">24.6. VPC Endpoints</h2>
<p>When you want to <strong>expose AWS resources that are within your VPC to the public internet</strong>.</p>
<p>Every AWS resource has a public IP. A VPC Endpoint allows you to make the resource public but still use AWSs private network (PrivateLink) to access it, which is normally faster.</p>
<p>The alternative would be to use a NAT Gateway + Internet Gateway, but this requires more hops.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="vpc_endpoint_vs_nat_gateway.png" class="img-fluid figure-img"></p>
<figcaption>VPC Endpoint vs NAT Gateway</figcaption>
</figure>
</div>
<p>There are two types of endpoint:</p>
<ul>
<li><strong>Interface Endpoint</strong>. Provisions an ENI with a private IP as an entry point. You must attach an appropriate security group. This works for most AWS resources. You pay per hour and per GB processed.</li>
<li><strong>Gateway Endpoint</strong>. Provisions a gateway and must be used as a target in a route table (no security group required). Can be used for S3 or DynamoDB. This is free.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="vpc_endpoint_types.png" class="img-fluid figure-img"></p>
<figcaption>VPC Endpoint Types</figcaption>
</figure>
</div>
<p>Gateway is generally preferred for S3 and DynamoDB because it is free and easier to set up. The exception is when you want access from on premises or another region or VPC within AWS, in which case an Interface Endpoint is required.</p>
</section>
<section id="vpc-flow-logs" class="level2">
<h2 class="anchored" data-anchor-id="vpc-flow-logs">24.7. VPC Flow Logs</h2>
<p><strong>Capture information about IP traffic going into your interfaces</strong>: VPC Flow Logs, Subnet Flow Logs, ENI Flow Logs. They also capture information from AWS-managed interfaces like ELB, RDS, etc.</p>
<p>Flow logs data can be sent to S3, CloudWatch Logs and Kinesis Data Firehose.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="vpc_flow_logs.png" class="img-fluid figure-img"></p>
<figcaption>VPC Flow Logs Example</figcaption>
</figure>
</div>
<ul>
<li><code>addr</code> helps identify problematic IP</li>
<li><code>port</code> helps identify problematic ports</li>
<li><code>Action</code> identifies success/failure due to security group or NACL.</li>
</ul>
<p>Common architectures: <img src="vpc_flow_logs_architectures.png" class="img-fluid" alt="VPC Flow Logs Architectures"></p>
</section>
<section id="aws-site-to-site-vpn" class="level2">
<h2 class="anchored" data-anchor-id="aws-site-to-site-vpn">24.8. AWS Site-to-Site VPN</h2>
<section id="overview-17" class="level3">
<h3 class="anchored" data-anchor-id="overview-17">24.8.1. Overview</h3>
<p>We might want to <strong>connect our corporate data centre to our VPC</strong>.</p>
<p>They need a Virtual Private Gateway (VGW) on the AWS side of the connection, and a Customer Gateway (CGW) which is a software or physical device on the customer side of the connection.</p>
<p>To make the connection, the CGW may have a public IP address which can be used directly, or it may have a NAT device which has its own IP address that can be used.</p>
<p>You need to enable route propagation for the VGW in the route table. If you need to ping the EC2 instances from in premises, the inbound rule of the security group must allow ICMP protocol.</p>
</section>
<section id="aws-vpn-cloudhub" class="level3">
<h3 class="anchored" data-anchor-id="aws-vpn-cloudhub">24.8.2. AWS VPN CloudHub</h3>
<p>This provides secure <strong>communication between multiple on premises sites and the VPC</strong>; hub and spoke model with AWS as the hub.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="aws_vpn_cloudhub.png" class="img-fluid figure-img"></p>
<figcaption>AWS VPN CloudHub</figcaption>
</figure>
</div>
</section>
</section>
<section id="direct-connect-dx" class="level2">
<h2 class="anchored" data-anchor-id="direct-connect-dx">24.9. Direct Connect (DX)</h2>
<section id="overview-18" class="level3">
<h3 class="anchored" data-anchor-id="overview-18">24.9.1. Overview</h3>
<p>DX provides a dedicated <strong>private</strong> connection from a remote network to your VPC. This allows you to access public resources (e.g.&nbsp;S3) and private resources (e.g.&nbsp;EC2) on the same connection.</p>
<p>The benefits are increased bandwidth and more stable connection.</p>
<p>You need to set up a VGW on your VPC.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="direct_connect.png" class="img-fluid figure-img"></p>
<figcaption>Direct Connect</figcaption>
</figure>
</div>
<p>Connections can be dedicated connections or hosted connections. The lead time to set up DX can be &gt;1 month.</p>
</section>
<section id="encryption-2" class="level3">
<h3 class="anchored" data-anchor-id="encryption-2">24.9.2. Encryption</h3>
<p>Data in transit is not encrypted but is private by virtue of being on a private connection.</p>
<p>You can set up encryption yourself.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="direct_connect_encryption.png" class="img-fluid figure-img"></p>
<figcaption>Direct Connect Encryption</figcaption>
</figure>
</div>
</section>
<section id="resiliency" class="level3">
<h3 class="anchored" data-anchor-id="resiliency">24.9.3. Resiliency</h3>
<p>One option for improved resiliency is to set up <em>multiple Direct Connect connections</em>.</p>
<p>An even more resilient option is to have <strong>multiple DX locations</strong>, each with multiple DX connections.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="direct_connect_resiliency.png" class="img-fluid figure-img"></p>
<figcaption>Direct Connect Resiliency</figcaption>
</figure>
</div>
</section>
<section id="direct-connect-gateway" class="level3">
<h3 class="anchored" data-anchor-id="direct-connect-gateway">24.9.4. Direct Connect Gateway</h3>
<p>If you want to set up a Direct Connect to <strong>multiple VPCs in different regions</strong> (within the same account) use Direct Connect Gateway.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="direct_connect_gateway.png" class="img-fluid figure-img"></p>
<figcaption>Direct Connect Gateway</figcaption>
</figure>
</div>
</section>
<section id="dx-site-to-site-vpn" class="level3">
<h3 class="anchored" data-anchor-id="dx-site-to-site-vpn">24.9.5. DX + Site-to-Site VPN</h3>
<p>Having multiple DX connections is expensive, so a common architecture is to use Site-to-Site VPN as a backup connection if the DX connection goes down.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="dx_backup_site_to_site_vpn.png" class="img-fluid figure-img"></p>
<figcaption>Site-to-Site VPN as a Backup to DX</figcaption>
</figure>
</div>
</section>
</section>
<section id="transit-gateway" class="level2">
<h2 class="anchored" data-anchor-id="transit-gateway">24.10. Transit Gateway</h2>
<p>The network topology can get complicated. Transit Gateway helps to solve this. You <strong>create route tables to limit which VPCs can talk to other VPCs</strong>.</p>
<p>Supports IP multicast.</p>
<p>Another use case of Transit Gateway is to <em>increase the bandwidth of a site-to-site VPN using ECMP</em> (equal cost multi path routing). This creates multiple paths to allow a routing strategy to forward a packet over the best path.</p>
<p>You can <strong>share DX connections between multiple accounts</strong>.</p>
</section>
<section id="vpc-traffic-mirroring" class="level2">
<h2 class="anchored" data-anchor-id="vpc-traffic-mirroring">24.11. VPC Traffic Mirroring</h2>
<p><strong>Capture and inspect network traffic through your VPC</strong>. We capture from a source ENI to a target ENI/load balancer.</p>
</section>
<section id="ipv6-for-vpc" class="level2">
<h2 class="anchored" data-anchor-id="ipv6-for-vpc">24.12. IPv6 for VPC</h2>
<section id="overview-19" class="level3">
<h3 class="anchored" data-anchor-id="overview-19">24.12.1. Overview</h3>
<p>IPv4 maxes out at 4.3 billion addresses - these will be exhausted soon.</p>
<p>IPv6 can provide 3.4x10^38 unique IP addresses.</p>
<p>Every IPv6 address <strong>in AWS</strong> is public and Internet-routable. You can enable them to run in dual-stack mode to be private and connect via Internet Gateway.</p>
</section>
<section id="egress-only-internet-gateway" class="level3">
<h3 class="anchored" data-anchor-id="egress-only-internet-gateway">24.12.2. Egress-only Internet Gateway</h3>
<p>These are only for IPv6 and are similar to NAT gateway. They allow instances in your VPC to have outbound IPv6 connections when preventing inbound IPv6 instances.</p>
<p>You must update route tables to allow this.</p>
</section>
</section>
<section id="aws-network-firewall" class="level2">
<h2 class="anchored" data-anchor-id="aws-network-firewall">24.13. AWS Network Firewall</h2>
<p>Weve already seen the following methods to secure the network on AWS: NACL, VPC security groups, AWS WAF, AWS Shield, AWS Firewall Manager</p>
<p>We can also <strong>protect the entire VPC with a firewall</strong>. This is AWS Network Firewall. Internally, it uses AWS Gateway Load Balancer.</p>
<p>This gives protection for layers 3-7.</p>
<p>It allows for fine-grained control on:</p>
<ul>
<li>IP and port</li>
<li>Protocol</li>
<li>Stateful domain list rule groups</li>
<li>Regex pattern matching</li>
</ul>
<p>We can either allow, drop or alert when these rules are matched. These matches can be sent to S3, CloudWatch Logs, Kinesis Data Firehose.</p>
</section>
</section>
<section id="disaster-recovery-and-migrations" class="level1">
<h1>25. Disaster Recovery and Migrations</h1>
<section id="disaster-recovery-overview" class="level2">
<h2 class="anchored" data-anchor-id="disaster-recovery-overview">25.1. Disaster Recovery Overview</h2>
<p>We can do different types of disaster recovery:</p>
<ul>
<li>On-premises to on premises - traditional DR</li>
<li>On-premises to cloud - hybrid DR</li>
<li>Cloud region A to cloud region B - cloud DR</li>
</ul>
<p><strong>Recovery Point Objective (RPO) is how much data you lose</strong>, and is determined by how often you run backups. The time between backups determines how much data is lost in a disaster.</p>
<p><strong>Recovery Time Objective (RTO) is the time taken to recover</strong> from the disaster once it has happened, ie the downtime.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="rto_rpo.png" class="img-fluid figure-img"></p>
<figcaption>RPO and RTO</figcaption>
</figure>
</div>
<p>There are several disaster recovery strategies. In order from slowest to fastest RTO:</p>
<ol type="1">
<li><strong>Backup and restore</strong>. Periodically save to S3 or save snapshots for EBS, Redshift and RDS.</li>
<li><strong>Pilot light</strong>. A small version of the app is always running in the cloud; this is the critical core AKA the pilot light. This is faster to restore as critical systems are already running. E.g. we might just have the RDS database running but not any EC2 instances.</li>
<li><strong>Warm standby</strong>. The <em>full system</em> is up and running but at minimum size, ready to be scaled up in the event of a disaster.</li>
<li><strong>Hot site / multi-site approach</strong>. Full production scale is running on AWS in parallel to the on premises version. If fully in cloud, this would be replicating across multiple regions.</li>
</ol>
</section>
<section id="disaster-recovery---practical-tips" class="level2">
<h2 class="anchored" data-anchor-id="disaster-recovery---practical-tips">25.2. Disaster Recovery - Practical Tips</h2>
<ul>
<li><strong>Backups</strong>. EBS snapshots, RDS automated backups. Push to S3 and use lifecycle policies to move to glacier. Snowball or Storage Gateway to move data from on premises to the cloud.</li>
<li>High <strong>availability</strong>. Route53 can migrate DNS from one region to another. Multi-AZ architecture for services like RDS, ElastiCache, EFS, S3. Direct connection can fall back to site-to-site VPN.</li>
<li><strong>Replication</strong>. Replicate RDS across regions or use Aurora + Global Database.</li>
<li><strong>Automation</strong>. CloudFormation and Elastic Beanstalk can recreate entire environments quickly. Recover or reboot EC2 instances based on CloudWatch alarms.</li>
<li><strong>Chaos</strong>. Test DR readiness by simulating a disaster. Netflix has the idea of a chaos monkey, e.g.&nbsp;terminate EC2 instances randomly in production.</li>
</ul>
</section>
<section id="database-migration-service-dms" class="level2">
<h2 class="anchored" data-anchor-id="database-migration-service-dms">25.3. Database Migration Service (DMS)</h2>
<section id="overview-20" class="level3">
<h3 class="anchored" data-anchor-id="overview-20">25.3.1 Overview</h3>
<p><strong>DMS helps you migrate a database from a source to a target</strong>, e.g.&nbsp;premises to the cloud. The source database remains available. It supports continuous data replication using Change Data Capture (CDC). You create an EC2 instance to perform the replication task.</p>
<p>Migrations can be:</p>
<ul>
<li>Homogeneous e.g.&nbsp;Oracle to Oracle</li>
<li>Heterogeneous e.g.&nbsp;Microsoft SQL Server to Aurora</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="dms.png" class="img-fluid figure-img"></p>
<figcaption>DMS</figcaption>
</figure>
</div>
<p>Sources can be:</p>
<ul>
<li>On-premises</li>
<li>EC2 instance databases</li>
<li>Azure</li>
<li>RDS and Aurora</li>
<li>S3</li>
<li>DocumentDB</li>
</ul>
<p>Targets can be:</p>
<ul>
<li>On-premises</li>
<li>EC2 instances</li>
<li>RDS</li>
<li>Redshift, DynamoDB</li>
<li>OpenSearch service</li>
<li>Kinesis Data Streams</li>
<li>Apache Kafka</li>
<li>Document DB (and Amazon Neptune)</li>
<li>Redis and Babelfish</li>
</ul>
</section>
<section id="aws-schema-conversion-tool-sct" class="level3">
<h3 class="anchored" data-anchor-id="aws-schema-conversion-tool-sct">25.3.2. AWS Schema Conversion Tool (SCT)</h3>
<p>SCT is a tool to <strong>convert your databases schema from one engine to another</strong>. For example, <code>Oracle -&gt; PostgreSQL</code>.</p>
<p>You dont need SCT if you are migrating between databases that use the same engine, e.g.&nbsp;<code>on-premises PostgreSQL -&gt; RDS PostgreSQL</code>.</p>
</section>
<section id="continuous-replication" class="level3">
<h3 class="anchored" data-anchor-id="continuous-replication">25.3.3. Continuous Replication</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="dms_continuous_replication.png" class="img-fluid figure-img"></p>
<figcaption>DMS Continuous Replication</figcaption>
</figure>
</div>
</section>
<section id="multi-az-deployment" class="level3">
<h3 class="anchored" data-anchor-id="multi-az-deployment">25.3.4. Multi-AZ Deployment</h3>
<p>When enabled, DMS provisions a replica in a different AZ and keeps it in sync.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="dms_multi_az.png" class="img-fluid figure-img"></p>
<figcaption>DMS Multi-AZ Deployment</figcaption>
</figure>
</div>
</section>
<section id="rds-and-aurora-mysql-migrations" class="level3">
<h3 class="anchored" data-anchor-id="rds-and-aurora-mysql-migrations">25.3.5. RDS and Aurora MySQL Migrations</h3>
<p>This is a specific example/gotcha when using DMS. If we want to migrate RDS MySQL to Aurora MySQL, we have several options:</p>
<ol type="1">
<li>Take RDS snapshots and restore them as Aurora DB</li>
<li>Create an Aurora read replica from RDS, and eventually promote it as its own cluster once fully copied.</li>
<li>Use Percona XtraBackup to create a backup dump in S3 and create an Aurora database from this</li>
<li>Use the mysqldump utility to migrate MySQL to Aurora.</li>
<li>Use DMS if both databases are running to do continuous replication.</li>
</ol>
<p>The same options apply to PostgreSQL migrations.</p>
</section>
</section>
<section id="on-premises-strategy-with-aws" class="level2">
<h2 class="anchored" data-anchor-id="on-premises-strategy-with-aws">25.4. On-Premises Strategy with AWS</h2>
<p>You can download the Amazon Linux 2 AMI as a <code>.iso</code> file to run locally as a VM.</p>
<p>VM Import/Export allows you to migrate existing applications to EC2, create a DR plan for your on-premises VMs and export the VM back.</p>
<p>AWS Application Discovery Service gathers information about your on premises servers to help plan a migration. It tracks server utilisation, dependency mappings, etc and can be viewed in AWS Migration Hub.</p>
<p>DMS can then be used to do the database migration.</p>
<p>AWS Server Migration Service (SMS) incrementally replicates on premises servers to AWS. The equivalent of DMS but for servers instead of databases.</p>
</section>
<section id="aws-backup" class="level2">
<h2 class="anchored" data-anchor-id="aws-backup">25.5. AWS Backup</h2>
<p><strong>A fully managed service to centrally manage and automate backups across AWS services</strong>: EC2 / EBS, S3, RDS, Aurora, DynamoDB, DocumentDB / Neptune, EFS, Storage Gateway. It backs up everything to an internal S3 bucket specific to AWS Backup.</p>
<p>It supports cross-region backups and cross-account backups. This is helpful for DR.</p>
<p>It supports PITR for supported services. Backups can be on-demand or scheduled. You create tag-based backup policies called Backup Plans, specifying the frequency, window, transition lifecycle to cold storage, retention period, etc.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="aws_backup.png" class="img-fluid figure-img"></p>
<figcaption>AWS Backup</figcaption>
</figure>
</div>
<p><strong>AWS Backup Vault Lock</strong> enforces a Write Once Read Many (WORM) state. It ensures that backups cannot be deleted, even by the root user.</p>
</section>
<section id="aws-migration-service-mgn" class="level2">
<h2 class="anchored" data-anchor-id="aws-migration-service-mgn">25.6. AWS Migration Service (MGN)</h2>
<section id="aws-application-discovery-service" class="level3">
<h3 class="anchored" data-anchor-id="aws-application-discovery-service">25.6.1. AWS Application Discovery Service</h3>
<p><strong>AWS Application Discovery Service gathers information about your on-premises servers to help plan a migration</strong>. It tracks server utilisation, dependency mappings, etc and can be viewed in AWS Migration Hub.</p>
<p>There are two types of discovery:</p>
<ul>
<li>Agentless Discovery. Gives performance history like CPU utilisation, memory usage, disk usage.</li>
<li>Agent-based Discovery. Gives more details about system configuration, running processes, network connections, etc.</li>
</ul>
</section>
<section id="aws-migration-service" class="level3">
<h3 class="anchored" data-anchor-id="aws-migration-service">25.6.2. AWS Migration Service</h3>
<p>AWS Migration Service (MGN) does the actual migration. It can lift and shift physical, virtual and cloud-based servers to run natively on AWS.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="aws_mgn.png" class="img-fluid figure-img"></p>
<figcaption>AWS MGN</figcaption>
</figure>
</div>
</section>
<section id="transfer-large-amounts-of-data-into-aws" class="level3">
<h3 class="anchored" data-anchor-id="transfer-large-amounts-of-data-into-aws">25.6.3. Transfer Large Amounts of Data into AWS</h3>
<p>This is a refresher/recap of services already covered.</p>
<p>There are several options:</p>
<ul>
<li>Site-to-Site VPN. Transfer data over the Internet. Immediate to setup but limited by your bandwidth.</li>
<li>Direct Connect. Initial set up takes about 1 month but bandwidth is generally higher and connection is more stable.</li>
<li>Snowball. Takes about 1 week for the Snowball to be delivered, but the transfer itself is fast since its local. Can be combined with DMS.</li>
</ul>
<p>For ongoing replication / transfers we can use Site-to-Site VPN or DX.</p>
</section>
<section id="vmware-cloud-on-aws" class="level3">
<h3 class="anchored" data-anchor-id="vmware-cloud-on-aws">25.6.4 VMWare Cloud on AWS</h3>
<p>People who manage on premises data centres often use VMWare Cloud. They may want to extend the data centre to AWS but keep using VMWare Cloud to manage it all.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="vmware_cloud.png" class="img-fluid figure-img"></p>
<figcaption>VMWare Cloud</figcaption>
</figure>
</div>
</section>
</section>
</section>
<section id="more-solution-architectures" class="level1">
<h1>26. More Solution Architectures</h1>
<section id="event-processing" class="level2">
<h2 class="anchored" data-anchor-id="event-processing">26.1. Event Processing</h2>
<p>Using SNS, SQS, Lambda</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="event_architecture_sqs.png" class="img-fluid figure-img"></p>
<figcaption>Event Processing with SNS, SQS, Lambda</figcaption>
</figure>
</div>
<p>Fan out pattern. Rather than having the application sending directly to each consumer (Option 1), which requires a code change for each new/modified consumer, we can publish to an SNS topic and fan out (Option 2)</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="event_architecture_fan_out.png" class="img-fluid figure-img"></p>
<figcaption>Event Architecture Fan Out</figcaption>
</figure>
</div>
<p>S3 Event Notifications. Use this to react to changes in an S3 bucket, e.g.&nbsp;a user uploading a video.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="event_architecture_s3_events.png" class="img-fluid figure-img"></p>
<figcaption>Event Architecture S3 Events</figcaption>
</figure>
</div>
<p>We can also do this via EventBridge. The benefit of EventBridge is it allows for more advanced filtering options, fanning out to multiple destinations, archive and replay events.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="event_architecture_eventbridge.png" class="img-fluid figure-img"></p>
<figcaption>Event Architecture EventBridge</figcaption>
</figure>
</div>
</section>
<section id="caching-strategies" class="level2">
<h2 class="anchored" data-anchor-id="caching-strategies">26.2. Caching Strategies</h2>
<p>We can cache at different stages of the pipelines, with trade offs in latency vs potential staleness.</p>
<p>S3 has no caching option.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="caching_architecture.png" class="img-fluid figure-img"></p>
<figcaption>Caching Architecture</figcaption>
</figure>
</div>
</section>
<section id="blocking-an-ip-address" class="level2">
<h2 class="anchored" data-anchor-id="blocking-an-ip-address">26.3. Blocking an IP Address</h2>
<ul>
<li>CloudFront. Geo restrictions and other filtering options.</li>
<li>NACL. Deny and allow rules.</li>
<li>ALB. Can manage security in the ALB.</li>
<li>WAF with ALB or CloudFront. Set IP address filtering.</li>
<li>Security group on EC2 instance. Allow rules.</li>
<li>Firewall running on the EC2 instance</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="blocking_an_ip_architecture.png" class="img-fluid figure-img"></p>
<figcaption>Blocking an IP Address Architecture - ALB, CF, WAF</figcaption>
</figure>
</div>
</section>
<section id="high-performance-computing" class="level2">
<h2 class="anchored" data-anchor-id="high-performance-computing">26.4. High Performance Computing</h2>
<p>A summary of services that are useful for HPC.</p>
<p>Data management and transfer:</p>
<ul>
<li>DX</li>
<li>Snowball</li>
<li>DataSync</li>
</ul>
<p>Compute and networking:</p>
<ul>
<li>EC2 instances (CPU- or GPU-optimised)</li>
<li>EC2 Placement Groups (cluster type) for low latency networking</li>
<li>EC2 Enhanced Networking. Higher bandwidth and lower latency. Use Elastic Network Adapter (ENA). Elastic Fabric Adapter (EFA) is an improved ENA for tightly coupled workloads on Linux, and uses Message Passing Interface (MPI) to bypass the Linux OS.</li>
</ul>
<p>Storage:</p>
<ul>
<li>Instance-attached storage. EBS or Instance Store</li>
<li>Network storage. S3, EFS, FSx for Lustre.</li>
</ul>
<p>Automation and orchestration:</p>
<ul>
<li>AWS Batch. Supports multi-node parallel jobs, where a single job can span multiple EC2 instances.</li>
<li>AWS ParallelCluster. Open-source cluster management tool to deploy HPC on AWS. You can enable EFA on the cluster.</li>
</ul>
</section>
<section id="creating-a-highly-available-ec2-instance" class="level2">
<h2 class="anchored" data-anchor-id="creating-a-highly-available-ec2-instance">26.5. Creating a Highly Available EC2 Instance</h2>
<p>An EC2 instance launches in a specific AZ so isnt highly available by default. But we can create architectures that improve availability.</p>
<p>We can have an EC2 instance with an Elastic IP. When the instance fails, a CloudWatch Alarm triggers a Lambda function which starts a backup instance (if not already running) and attaches the Elastic IP to this new instance.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="highly_available_ec2.png" class="img-fluid figure-img"></p>
<figcaption>Highly Available EC2 Instance</figcaption>
</figure>
</div>
<p>Another option is to use an auto scaling group (ASG). We can configure the ASG to specify 1 min, 1 max, 1 desired, &gt;=2 AZ. This will create a new instance in a different AZ when the first instance goes down. EC2 User Data attaches the Elastic IP based on a tag; this requires an EC2 instance role with permissions to attach an Elastic IP.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="highly_available_ec2_asg.png" class="img-fluid figure-img"></p>
<figcaption>Highly Available EC2 Instance - ASG</figcaption>
</figure>
</div>
<p>We can extend this to have an EBS as well as an ASG. The EBS volume exists only in one AZ, so when we create our backup EC2 instance in a new AZ we need to move the EBS volume too. We can do this with a <strong>lifecycle hook</strong>; on ASG termination, the lifecycle hook can take an EBS Snapshot with appropriate tags. Then we can have an ASG launch lifecycle hook to create a new EBS volume from the snapshot and attach it to our new instance.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="highly_available_ec2_ebs.png" class="img-fluid figure-img"></p>
<figcaption>Highly Available EC2 Instance - ASG + EBS</figcaption>
</figure>
</div>
</section>
</section>
<section id="other-services" class="level1">
<h1>27. Other Services</h1>
<p>This section is a high level overview of miscellaneous AWS services that are less commonly used.</p>
<section id="cloudformation" class="level2">
<h2 class="anchored" data-anchor-id="cloudformation">27.1. CloudFormation</h2>
<section id="overview-21" class="level3">
<h3 class="anchored" data-anchor-id="overview-21">27.1.1. Overview</h3>
<p>CloudFormation is used to <strong>deploy and manage infrastructure at scale</strong>. It is a declarative way to define your AWS infrastructure for any resources. CloudFormation will create the resources <em>in the right order</em> using your config.</p>
<p>Benefits:</p>
<ul>
<li><strong>Infrastructure as code</strong>. No manual steps, can version control and review changes.</li>
<li>CloudFormation template gives you cost estimates for the resources youre using, and tags all resources within a given stack for easier cost monitoring.</li>
<li>CloudFormation generates a system diagram for your templates.</li>
<li>Can reuse and share templates (find them online)</li>
</ul>
<p>The Infrastructure Composer service allows you to visualise the relations between resources.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="cloudformation.png" class="img-fluid figure-img"></p>
<figcaption>CloudFormation + Infrastructure Composer</figcaption>
</figure>
</div>
</section>
<section id="cloudformation-service-roles" class="level3">
<h3 class="anchored" data-anchor-id="cloudformation-service-roles">27.1.2. CloudFormation Service Roles</h3>
<p>These are IAM roles specifically for CloudFormation that give the ability to create/update/delete stack resources, even if they dont have the permission to <em>use</em> those resources.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="cloudformation_service_role.png" class="img-fluid figure-img"></p>
<figcaption>CloudFormation Service Role</figcaption>
</figure>
</div>
</section>
</section>
<section id="simple-email-service-ses" class="level2">
<h2 class="anchored" data-anchor-id="simple-email-service-ses">27.2. Simple Email Service (SES)</h2>
<p>Fully managed service to <strong>send and receive emails</strong>.</p>
<p>Provides email statistics (deliveries, opens) and reputation insights (did it get marked as spam).</p>
<p>There is a choice of IP addresses to send from: shared, dedicated, customer-owned. It supports DomainKeys Identified Mail (DKIM) and Sender Policy Framework (SPF) protocols.</p>
</section>
<section id="amazon-pinpoint" class="level2">
<h2 class="anchored" data-anchor-id="amazon-pinpoint">27.3. Amazon Pinpoint</h2>
<p>Pinpoint is a two-way (inbound and outbound) <strong>marketing communication service</strong>. You can send/receive emails, SMS, push notifications, voice chat, in-app messaging.</p>
<p>You can segment and personalise messages.</p>
<p>Replies can be sent to SNS, Kinesis Data Firehose, CloudWatch Logs. Downstream automations can be triggered from here.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="pinpoint.png" class="img-fluid figure-img"></p>
<figcaption>Amazon Pinpoint</figcaption>
</figure>
</div>
<p>The difference vs SNS or SES is that you dont have to manually manage each messages audience, content, delivery schedule, etc. Pinpoint handles all of this. Essentially a <em>more managed service version of SES/SNS</em>.</p>
</section>
<section id="system-manager-ssm" class="level2">
<h2 class="anchored" data-anchor-id="system-manager-ssm">27.4. System Manager (SSM)</h2>
<section id="ssm-session-manager" class="level3">
<h3 class="anchored" data-anchor-id="ssm-session-manager">27.4.1. SSM Session Manager</h3>
<p>SSM Session Manager allows you to <strong>start a secure shell on your EC2</strong> and on-premises servers. No SSH access, bastion hosts, or SSH keys needed, and no port 22 needed, which is better for security.</p>
<p>You can send session log data to S3 or CloudWatch Logs.</p>
<p>There are therefore three ways to access an EC2 instance:</p>
<ol type="1">
<li>SSH via port 22. Requires ssh keys to be added on instance creation.</li>
<li>EC2 Instance Connect. Requires ssh keys and port 22 inbound rules allowed.</li>
<li>Using SSM Session Manager</li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="ssm_session_manager.png" class="img-fluid figure-img"></p>
<figcaption>SSM Session Manager</figcaption>
</figure>
</div>
</section>
<section id="other-ssm-commands" class="level3">
<h3 class="anchored" data-anchor-id="other-ssm-commands">27.4.2. Other SSM Commands</h3>
<p>Run command: run a script across multiple instances.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="ssm_run_command.png" class="img-fluid figure-img"></p>
<figcaption>SSM Run Command</figcaption>
</figure>
</div>
<p>Patch manager: automate patching, security updates etc.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="ssm_patch.png" class="img-fluid figure-img"></p>
<figcaption>SSM Patch</figcaption>
</figure>
</div>
<p>Patches can be run on-demand or using maintenance windows.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="ssm_maintenance_windows.png" class="img-fluid figure-img"></p>
<figcaption>SSM Maintenance Window</figcaption>
</figure>
</div>
<p>Common repeated tasks can be specific using an <strong>Automation Runbook</strong>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="ssm_automation.png" class="img-fluid figure-img"></p>
<figcaption>SSM Automation</figcaption>
</figure>
</div>
</section>
</section>
</section>
<section id="references" class="level1">
<h1>References</h1>
<ul>
<li><a href="https://www.udemy.com/course/aws-certified-solutions-architect-associate-saa-c03">Stephane Maarek Ultimate AWS Certified Solutions Architect Associate 2025 Udemy course</a></li>
</ul>


</section>

<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>