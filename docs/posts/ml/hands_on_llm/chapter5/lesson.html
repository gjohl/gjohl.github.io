<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Gurpreet Johl">
<meta name="dcterms.date" content="2025-01-15">
<meta name="description" content="Part 5: Hot Topics">

<title>Gurpreet Johl - Hands-On LLMs: Text Clustering and Topic Modeling</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="../../../../site_libs/quarto-diagram/mermaid.min.js"></script>
<script src="../../../../site_libs/quarto-diagram/mermaid-init.js"></script>
<link href="../../../../site_libs/quarto-diagram/mermaid.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js" crossorigin="anonymous"></script>


<link rel="stylesheet" href="../../../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../../index.html">
    <span class="navbar-title">Gurpreet Johl</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../../projects.html"> 
<span class="menu-text">Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../blog.html"> 
<span class="menu-text">Notes</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/gjohl"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/gurpreetjohl"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/gurpreetjohl"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Hands-On LLMs: Text Clustering and Topic Modeling</h1>
                  <div>
        <div class="description">
          Part 5: Hot Topics
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">AI</div>
                <div class="quarto-category">Engineering</div>
                <div class="quarto-category">GenerativeAI</div>
                <div class="quarto-category">LLM</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Gurpreet Johl </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">January 15, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#text-clustering-and-topic-modeling" id="toc-text-clustering-and-topic-modeling" class="nav-link active" data-scroll-target="#text-clustering-and-topic-modeling">Text Clustering and Topic Modeling</a></li>
  <li><a href="#text-clustering" id="toc-text-clustering" class="nav-link" data-scroll-target="#text-clustering">1. Text Clustering</a>
  <ul class="collapse">
  <li><a href="#the-goal" id="toc-the-goal" class="nav-link" data-scroll-target="#the-goal">1.1 The goal</a></li>
  <li><a href="#text-clustering-pipeline" id="toc-text-clustering-pipeline" class="nav-link" data-scroll-target="#text-clustering-pipeline">1.2. Text clustering pipeline</a>
  <ul class="collapse">
  <li><a href="#the-embedding-model" id="toc-the-embedding-model" class="nav-link" data-scroll-target="#the-embedding-model">1.2.1. The embedding model</a></li>
  <li><a href="#the-dimensionality-reduction-model" id="toc-the-dimensionality-reduction-model" class="nav-link" data-scroll-target="#the-dimensionality-reduction-model">1.2.2. The dimensionality reduction model</a></li>
  <li><a href="#the-cluster-model" id="toc-the-cluster-model" class="nav-link" data-scroll-target="#the-cluster-model">1.2.3. The cluster model</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#topic-modelling" id="toc-topic-modelling" class="nav-link" data-scroll-target="#topic-modelling">2. Topic Modelling</a>
  <ul class="collapse">
  <li><a href="#bertopic" id="toc-bertopic" class="nav-link" data-scroll-target="#bertopic">2.1. BERTopic</a>
  <ul class="collapse">
  <li><a href="#create-a-bertopic-model" id="toc-create-a-bertopic-model" class="nav-link" data-scroll-target="#create-a-bertopic-model">2.1.1. Create a BERTopic model</a></li>
  <li><a href="#explore-the-topics" id="toc-explore-the-topics" class="nav-link" data-scroll-target="#explore-the-topics">2.1.2. Explore the topics</a></li>
  <li><a href="#visualise-the-topics" id="toc-visualise-the-topics" class="nav-link" data-scroll-target="#visualise-the-topics">2.1.3. Visualise the topics</a></li>
  </ul></li>
  <li><a href="#re-ranking" id="toc-re-ranking" class="nav-link" data-scroll-target="#re-ranking">2.2. Re-ranking</a>
  <ul class="collapse">
  <li><a href="#keybertinspired" id="toc-keybertinspired" class="nav-link" data-scroll-target="#keybertinspired">2.2.1. KeyBERTInspired</a></li>
  <li><a href="#maximal-marginal-relevance" id="toc-maximal-marginal-relevance" class="nav-link" data-scroll-target="#maximal-marginal-relevance">2.2.2. Maximal Marginal Relevance</a></li>
  </ul></li>
  <li><a href="#text-generation" id="toc-text-generation" class="nav-link" data-scroll-target="#text-generation">2.3. Text Generation</a></li>
  </ul></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="text-clustering-and-topic-modeling" class="level1">
<h1>Text Clustering and Topic Modeling</h1>
</section>
<section id="text-clustering" class="level1">
<h1>1. Text Clustering</h1>
<section id="the-goal" class="level2">
<h2 class="anchored" data-anchor-id="the-goal">1.1 The goal</h2>
<p>Text clustering is an unsupervised technique that aims to group similar texts based on their content, meaning and relationships.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="lesson_files/figure-html/cell-1-1-image.png" class="img-fluid figure-img"></p>
<figcaption>Clusters in embedding space</figcaption>
</figure>
</div>
<p>The clusters can the be used for applications such as outlier detection, speeding up labelling and finding mislabelled data.</p>
<p>It also has applications in <strong>topic modelling</strong>, where we assign a label or keywords to a cluster describing its constituents.</p>
<p>We apply this to an example data set of Arxiv articles. Let’s load the Arxiv data we’ll use for this:</p>
<div id="cell-2" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> datasets <span class="im">import</span> load_dataset</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> load_dataset(<span class="st">"maartengr/arxiv_nlp"</span>)[<span class="st">"train"</span>]</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>abstracts <span class="op">=</span> dataset[<span class="st">"Abstracts"</span>]</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>titles <span class="op">=</span> dataset[<span class="st">"Titles"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"867d708a464c4698b1113f2cf8589fe6","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"f80aaa453f8f4295bc036eebe03636c6","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"b1da8ca9ffc14821a85f01c7cec8cd02","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
</div>
</section>
<section id="text-clustering-pipeline" class="level2">
<h2 class="anchored" data-anchor-id="text-clustering-pipeline">1.2. Text clustering pipeline</h2>
<p>There are many approaches to text clustering, including GNNs and centroid-based clustering. A common approach is:</p>
<ol type="1">
<li>Convert input documents to <strong>embeddings</strong>, using an <em>embedding model</em></li>
<li><strong>Reduce the dimensionality</strong> of those embeddings, using a <em>dimensionality reduction model</em></li>
<li><strong>Group similar documents</strong>, using a <em>cluster model</em></li>
</ol>
<section id="the-embedding-model" class="level3">
<h3 class="anchored" data-anchor-id="the-embedding-model">1.2.1. The embedding model</h3>
<p>We convert our text to embedding vectors using an embedding model. We should choose one that was trained to optimise <em>semantic similarity</em> (which most are). We can use the <a href="https://huggingface.co/spaces/mteb/leaderboard">MTEB leaderboard</a> to help select a good model.</p>
<p>We can load a pre-trained model and create our embeddings.</p>
<div id="cell-4" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sentence_transformers <span class="im">import</span> SentenceTransformer </span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>embedding_model <span class="op">=</span> SentenceTransformer(<span class="st">"thenlper/gte-small"</span>) </span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>embeddings <span class="op">=</span> embedding_model.encode(abstracts, show_progress_bar<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"4bc1748f1e0f44dc9f1815768c97e393","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"9aa83e6bcc344962aa9e0d8555ad9ec0","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"188752bdd92a442ea6d3fb79be0bd2e2","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/Users/gurpreetjohl/miniconda3/envs/thellmbook/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1477965dbae64036b2355ff98bbc6f08","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"563bc55573614ce28957929c571c1456","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"2197e4eb995546289f530c2bdd67e01c","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ae34c86faee74f488ff58f89c536356e","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"7fb4bf6922f44994a08cbb644ddda700","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"1b18fe1ce1204a2380662193cedb282a","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"6ae4cd993057485c81737442007b2c3d","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"82a6931700134d18b5c091a514bacf1e","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
</div>
</section>
<section id="the-dimensionality-reduction-model" class="level3">
<h3 class="anchored" data-anchor-id="the-dimensionality-reduction-model">1.2.2. The dimensionality reduction model</h3>
<p>High-dimensional data can suffer from the <strong>curse of dimensionality</strong>, making it difficult to find meaningful clusters.</p>
<p>We can use a dimensionality reduction model to <em>compress</em> (not remove) dimensions which makes the downstream clustering easier.</p>
<p>This is, by it’s nature, a lossy transformation. But we hope that <em>enough</em> of the information is retained to be useful.</p>
<p>Standard dimensionality reduction techniques include Principal Component Anaylsis (PCA) and Uniform Manifold Approximation (UMAP). We’ll use UMAP as it tends to handle nonlinear relationships better.</p>
<p>The following code reduces our embeddings from 384 -&gt; 5 dimensions. We set <code>min_dist=0</code> as this allows embedded points to be arbitrarily close together, which results in tighter clusters, and <code>metric=‘cosine’</code> generally performs better than Euclidean methods for high-dimensional data.</p>
<div id="cell-6" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> umap <span class="im">import</span> UMAP</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>umap_model <span class="op">=</span> UMAP(n_components<span class="op">=</span><span class="dv">5</span>, min_dist<span class="op">=</span><span class="fl">0.0</span>, metric<span class="op">=</span><span class="st">'cosine'</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>reduced_embeddings <span class="op">=</span> umap_model.fit_transform(embeddings)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/Users/gurpreetjohl/miniconda3/envs/thellmbook/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(
OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.</code></pre>
</div>
</div>
</section>
<section id="the-cluster-model" class="level3">
<h3 class="anchored" data-anchor-id="the-cluster-model">1.2.3. The cluster model</h3>
<p><strong>Centroid-based</strong> algorithms like K-Nearest Neighbours (KNN) are popular in other settings but require us to specify the number of clusters ahead of time (which we don’t know) and forces all data points to be part of a cluster (there can’t be unassigned points). This makes them less useful for our use case.</p>
<p><strong>Density-based</strong> algorithms calculate the number of clusters freely and do not force all points into a cluster. We’ll use HDBSCAN for our case.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="lesson_files/figure-html/cell-7-1-image.png" class="img-fluid figure-img"></p>
<figcaption>Centroid vs density approaches</figcaption>
</figure>
</div>
<p>We can cluster the data with the following code. We can vary <code>min_cluster_size</code> to change the number of clusters produced.</p>
<div id="cell-8" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> hdbscan <span class="im">import</span> HDBSCAN </span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>hdbscan_model <span class="op">=</span> HDBSCAN(min_cluster_size<span class="op">=</span><span class="dv">50</span>, metric<span class="op">=</span><span class="st">"euclidean"</span>, cluster_selection_method<span class="op">=</span><span class="st">"eom"</span>).fit(reduced_embeddings)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>clusters <span class="op">=</span> hdbscan_model.labels_</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
    - Avoid using `tokenizers` before the fork if possible
    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
    - Avoid using `tokenizers` before the fork if possible
    - Explicitly set the environment variable huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
To disable this warning, you can either:
    - Avoid using `tokenizers` before the fork if possible
    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
    - Avoid using `tokenizers` before the fork if possible
    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
    - Avoid using `tokenizers` before the fork if possible
    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)</code></pre>
</div>
</div>
<p>We can inspect the clusters and plot the data in the reduced dimension space. Although helpful, it’s worth remembering that this is just an approximation of the real embeddings, some information is lost.</p>
<p>First, let’s observe a selection of 3 documents from the first cluster to see if they seem similar:</p>
<div id="cell-11" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np </span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Print first three documents in cluster 0 </span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>cluster <span class="op">=</span> <span class="dv">0</span> </span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> index <span class="kw">in</span> np.where(clusters<span class="op">==</span>cluster)[<span class="dv">0</span>][:<span class="dv">3</span>]:</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(abstracts[index][:<span class="dv">300</span>] <span class="op">+</span> <span class="st">"... </span><span class="ch">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  This works aims to design a statistical machine translation from English text
to American Sign Language (ASL). The system is based on Moses tool with some
modifications and the results are synthesized through a 3D avatar for
interpretation. First, we translate the input text to gloss, a written fo... 

  Researches on signed languages still strongly dissociate lin- guistic issues
related on phonological and phonetic aspects, and gesture studies for
recognition and synthesis purposes. This paper focuses on the imbrication of
motion and meaning for the analysis, synthesis and evaluation of sign lang... 

  Modern computational linguistic software cannot produce important aspects of
sign language translation. Using some researches we deduce that the majority of
automatic sign language translation systems ignore many aspects when they
generate animation; therefore the interpretation lost the truth inf... 
</code></pre>
</div>
</div>
<p>Now we can plot the data in the reduced embedding space:</p>
<div id="cell-13" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd </span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Reduce 384-dimensional embeddings to two dimensions for easier visualization </span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>reduced_embeddings <span class="op">=</span> UMAP(n_components<span class="op">=</span><span class="dv">2</span>, min_dist<span class="op">=</span><span class="fl">0.0</span>, metric<span class="op">=</span><span class="st">"cosine"</span>, random_state<span class="op">=</span><span class="dv">42</span> ).fit_transform(embeddings) </span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(reduced_embeddings, columns<span class="op">=</span>[<span class="st">"x"</span>, <span class="st">"y"</span>]) </span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"title"</span>] <span class="op">=</span> titles </span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"cluster"</span>] <span class="op">=</span> [<span class="bu">str</span>(c) <span class="cf">for</span> c <span class="kw">in</span> clusters] </span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Select outliers and non-outliers (clusters) </span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>to_plot <span class="op">=</span> df.loc[df.cluster <span class="op">!=</span> <span class="st">"-1"</span>, :] </span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>outliers <span class="op">=</span> df.loc[df.cluster <span class="op">==</span> <span class="st">"-1"</span>, :]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/Users/gurpreetjohl/miniconda3/envs/thellmbook/lib/python3.10/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.
  warn(</code></pre>
</div>
</div>
<div id="cell-14" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt </span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot outliers and non-outliers separately </span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>plt.scatter(outliers.x, outliers.y, alpha<span class="op">=</span><span class="fl">0.05</span>, s<span class="op">=</span><span class="dv">2</span>, c<span class="op">=</span><span class="st">"grey"</span>) </span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>plt.scatter(to_plot.x, to_plot.y, c<span class="op">=</span>to_plot.cluster.astype(<span class="bu">int</span>), alpha<span class="op">=</span><span class="fl">0.6</span>, s<span class="op">=</span><span class="dv">2</span>, cmap<span class="op">=</span><span class="st">"tab20b"</span> ) </span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>plt.axis(<span class="st">"off"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>(-7.562705826759339,
 10.960084271430969,
 -3.4470335602760316,
 18.276195919513704)</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="lesson_files/figure-html/cell-8-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="topic-modelling" class="level1">
<h1>2. Topic Modelling</h1>
<p>This is where we find themes or latent topics in a cluster; we want to find keywords or phrases that best represent the topic.</p>
<p>Classical approaches to topic modelling include latent Dirichlet allocation (LDA), where it’s assumed that each topic is characterised by a probability distribution of words in a corpus. These are generally <em>bag-of-words</em> approaches that do not account for context or meaning.</p>
<p>An LLM-based approach is the modular <strong>BERTopic</strong>.</p>
<section id="bertopic" class="level2">
<h2 class="anchored" data-anchor-id="bertopic">2.1. BERTopic</h2>
<p>The first step is to perform text clustering using the same 3 steps outlined in the previous section.</p>
<p>We then use a bag-of-words approach <em>per cluster</em> (instead of per document as would usually be the case) to model a distribution over words per class. This is the <strong>CountVectorizer</strong> step.</p>
<p>We similarly use a class-specific variant of term-frequency inverse document-frequency called <strong>c-TF-IDF</strong>, which puts more weight on the meaningful words of that cluster.</p>
<p>We now have a generic <strong>text clustering pipeline</strong>:</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart LR

  A(Embeddings) --&gt; B(Dimensionality Reduction) --&gt; C(Clustering)
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>And a <strong>topic modeling pipeline</strong>:</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart LR

  D(Cluster Bag-of-Words) --&gt; E(Keyword Selection)
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>Putting this all together with our choice of components:</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart LR

  A(SBERT) --&gt; B(UMAP) --&gt; C(HDBSCAN) --&gt; D(CountVectorizer) --&gt; E(c-TF-IDF)
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>The idea behind BERTopic is that these components are codular, so each can be swapped out like lego blocks. For example, if you prefer k-means clusters or PCA over UMAP, just swap it.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="lesson_files/figure-html/cell-15-1-image.png" class="img-fluid figure-img"></p>
<figcaption>BERTopic modular components</figcaption>
</figure>
</div>
<p>This modularity also means the same base model can be used and adapted for different tasks and use cases by adding/removing components downstream of the base model.</p>
<section id="create-a-bertopic-model" class="level3">
<h3 class="anchored" data-anchor-id="create-a-bertopic-model">2.1.1. Create a BERTopic model</h3>
<p>We can run this end-to-end pipeline using the previously defined models in BERTopic:</p>
<div id="cell-18" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> bertopic <span class="im">import</span> BERTopic </span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Train our model with our previously defined models </span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>topic_model <span class="op">=</span> (BERTopic(embedding_model<span class="op">=</span>embedding_model, </span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>                        umap_model<span class="op">=</span>umap_model,</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>                        hdbscan_model<span class="op">=</span>hdbscan_model,</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>                        verbose<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>               .fit(abstracts, embeddings))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
    - Avoid using `tokenizers` before the fork if possible
    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
    - Avoid using `tokenizers` before the fork if possible
    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-01-15 11:48:19,327 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm
2025-01-15 11:48:47,848 - BERTopic - Dimensionality - Completed ✓
2025-01-15 11:48:47,851 - BERTopic - Cluster - Start clustering the reduced embeddings
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
    - Avoid using `tokenizers` before the fork if possible
    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
    - Avoid using `tokenizers` before the fork if possible
    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
    - Avoid using `tokenizers` before the fork if possible
    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
    - Avoid using `tokenizers` before the fork if possible
    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
2025-01-15 11:48:49,745 - BERTopic - Cluster - Completed ✓
2025-01-15 11:48:49,757 - BERTopic - Representation - Extracting topics from clusters using representation models.
2025-01-15 11:48:51,583 - BERTopic - Representation - Completed ✓</code></pre>
</div>
</div>
</section>
<section id="explore-the-topics" class="level3">
<h3 class="anchored" data-anchor-id="explore-the-topics">2.1.2. Explore the topics</h3>
<p>We can then explore the topics found by the model.</p>
<p>Note that the topic labelled <code>-1</code> is a bucket for outliers that do not fit in any other cluster.</p>
<div id="cell-21" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>topic_model.get_topic_info()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Topic</th>
<th data-quarto-table-cell-role="th">Count</th>
<th data-quarto-table-cell-role="th">Name</th>
<th data-quarto-table-cell-role="th">Representation</th>
<th data-quarto-table-cell-role="th">Representative_Docs</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>-1</td>
<td>13779</td>
<td>-1_of_the_and_to</td>
<td>[of, the, and, to, in, we, language, that, for...</td>
<td>[ Language models have emerged as a central c...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0</td>
<td>2224</td>
<td>0_speech_asr_recognition_end</td>
<td>[speech, asr, recognition, end, acoustic, spea...</td>
<td>[ The amount of labeled data to train models ...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>1</td>
<td>2104</td>
<td>1_question_qa_questions_answer</td>
<td>[question, qa, questions, answer, answering, a...</td>
<td>[ Multi-hop question answering (QA) requires ...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>2</td>
<td>1428</td>
<td>2_medical_clinical_biomedical_patient</td>
<td>[medical, clinical, biomedical, patient, healt...</td>
<td>[ Clinical texts, such as admission notes, di...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>3</td>
<td>986</td>
<td>3_translation_nmt_machine_neural</td>
<td>[translation, nmt, machine, neural, bleu, engl...</td>
<td>[ In this paper, we introduce a hybrid search...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">146</td>
<td>145</td>
<td>54</td>
<td>145_gans_gan_adversarial_generation</td>
<td>[gans, gan, adversarial, generation, generativ...</td>
<td>[ Text generation is of particular interest i...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">147</td>
<td>146</td>
<td>54</td>
<td>146_emoji_emojis_emoticons_sentiment</td>
<td>[emoji, emojis, emoticons, sentiment, twitter,...</td>
<td>[ The frequent use of Emojis on social media ...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">148</td>
<td>147</td>
<td>51</td>
<td>147_prompt_prompts_optimization_prompting</td>
<td>[prompt, prompts, optimization, prompting, llm...</td>
<td>[ Prompt optimization aims to find the best p...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">149</td>
<td>148</td>
<td>51</td>
<td>148_coherence_discourse_paragraph_text</td>
<td>[coherence, discourse, paragraph, text, cohesi...</td>
<td>[ While there has been significant progress t...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">150</td>
<td>149</td>
<td>51</td>
<td>149_long_context_window_length</td>
<td>[long, context, window, length, llms, memory, ...</td>
<td>[ We present a series of long-context LLMs th...</td>
</tr>
</tbody>
</table>

<p>151 rows × 5 columns</p>
</div>
</div>
</div>
<p>We can explore a particular topic by its topic number:</p>
<div id="cell-23" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>topic_model.get_topic(<span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>[('medical', 0.0220337946328463),
 ('clinical', 0.02092442350104087),
 ('biomedical', 0.014552038344966458),
 ('patient', 0.010048801098837407),
 ('health', 0.008769124731484461),
 ('notes', 0.008421182820081155),
 ('patients', 0.0067969193810322485),
 ('healthcare', 0.0067470745955792765),
 ('and', 0.006483211946307094),
 ('drug', 0.006111735386306484)]</code></pre>
</div>
</div>
<p>We can also search for clusters which match a given search term:</p>
<div id="cell-25" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>topic_model.find_topics(<span class="st">"rocket science"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>([131, 46, 28, -1, 9], [0.8482957, 0.8474297, 0.8343923, 0.8332416, 0.8269581])</code></pre>
</div>
</div>
<p>Topic number 31 allegedly matches the term, so we can look closer at this topic:</p>
<div id="cell-27" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>topic_model.get_topic(<span class="dv">131</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>[('materials', 0.050279482237225254),
 ('science', 0.02243336305054669),
 ('chemistry', 0.0215702079363354),
 ('chemical', 0.019510674137408444),
 ('scientific', 0.019096261213199146),
 ('material', 0.01734997997000861),
 ('synthesis', 0.013922383987668636),
 ('literature', 0.011377588070962407),
 ('reaction', 0.010392948527677913),
 ('extraction', 0.009880316014163601)]</code></pre>
</div>
</div>
</section>
<section id="visualise-the-topics" class="level3">
<h3 class="anchored" data-anchor-id="visualise-the-topics">2.1.3. Visualise the topics</h3>
<p>As we did in the “manual” example, we can visualise the text clusters. The library provides a handy convenience method for interactive plotting.</p>
<div id="cell-30" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> topic_model.visualize_documents( titles, reduced_embeddings<span class="op">=</span>reduced_embeddings, width<span class="op">=</span><span class="dv">1200</span>, hide_annotations<span class="op">=</span><span class="va">True</span> ) </span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>fig.update_layout(font<span class="op">=</span><span class="bu">dict</span>(size<span class="op">=</span><span class="dv">16</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>Unable to display output for mime type(s): application/vnd.plotly.v1+json</code></pre>
</div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="lesson_files/figure-html/cell-31-1-image.png" class="img-fluid figure-img"></p>
<figcaption>Cluster embedding space</figcaption>
</figure>
</div>
<p>We can also plot keywords per topic:</p>
<div id="cell-33" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>topic_model.visualize_barchart()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>Unable to display output for mime type(s): application/vnd.plotly.v1+json</code></pre>
</div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="lesson_files/figure-html/cell-34-1-image.png" class="img-fluid figure-img"></p>
<figcaption>Topic word scores</figcaption>
</figure>
</div>
<p>We can plot the similarity between topics as a heatmap:</p>
<div id="cell-36" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>topic_model.visualize_heatmap(n_clusters<span class="op">=</span><span class="dv">30</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>Unable to display output for mime type(s): application/vnd.plotly.v1+json</code></pre>
</div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="lesson_files/figure-html/cell-37-1-image.png" class="img-fluid figure-img"></p>
<figcaption>Topic similarity heatmap</figcaption>
</figure>
</div>
<p>We can also see the hierarchies within topics</p>
<div id="cell-39" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>topic_model.visualize_hierarchy()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>Unable to display output for mime type(s): application/vnd.plotly.v1+json</code></pre>
</div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="lesson_files/figure-html/cell-40-1-image.png" class="img-fluid figure-img"></p>
<figcaption>Topic hierarchies</figcaption>
</figure>
</div>
</section>
</section>
<section id="re-ranking" class="level2">
<h2 class="anchored" data-anchor-id="re-ranking">2.2. Re-ranking</h2>
<p>The pipeline so far relied on the bag-of-words (BoW) approach to identify key words. This is fast, but does not take the semantic structure of a sentence into account.</p>
<p>We <em>could</em> swap the bag-of-words “lego block” for something more sophisticated. Another approach is to instead keep it as is but add an extra “re-ranker” block at the end to fine-tune the ordering of the keywords. This can be a slower algorithm, but it only processes the list of words identified by BoW for each topic (tens or hundreds), not the entire dcoument corpus (millions or more).</p>
<p>These re-rankers are referred to as <strong>representation models</strong>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="lesson_files/figure-html/cell-41-2-image.png" class="img-fluid figure-img"></p>
<figcaption>Re-ranker block</figcaption>
</figure>
</div>
<section id="keybertinspired" class="level3">
<h3 class="anchored" data-anchor-id="keybertinspired">2.2.1. KeyBERTInspired</h3>
<p>The idea behind this apporach is to use the similarity between embedding and words vectors to give a score, then order key words by their match score.</p>
<ol type="1">
<li><strong>Average document embedding</strong>: Calculate embeddings for each document, then average</li>
<li>Calculate embeddings for each <strong>keyword</strong></li>
<li>Calculate <strong>cosine similarity</strong> between each keyword and the average document embedding</li>
<li>Order by the most similar</li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="lesson_files/figure-html/cell-41-1-image-2.png" class="img-fluid figure-img"></p>
<figcaption>KeyBERTInspired</figcaption>
</figure>
</div>
<p>We will save the representations from the previousl model so we can compare them to the re-ranked versions</p>
<div id="cell-43" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Save original representations </span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> copy <span class="im">import</span> deepcopy </span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>original_topics <span class="op">=</span> deepcopy(topic_model.topic_representations_)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The following convenience function helps to compare topics between the original and reranked versions.</p>
<div id="cell-45" class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> topic_differences(model, original_topics, num_topics<span class="op">=</span><span class="dv">5</span>):</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Show the differences in topic representations between two models"""</span></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>    topic_words <span class="op">=</span> []</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> topic <span class="kw">in</span> <span class="bu">range</span>(num_topics): </span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Extract top 4 words per topic per model </span></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>        og_words <span class="op">=</span> <span class="st">" | "</span>.join(<span class="bu">list</span>(<span class="bu">zip</span>(<span class="op">*</span>original_topics[topic])) [<span class="dv">0</span>][:<span class="dv">4</span>]) </span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>        reranked_words <span class="op">=</span> <span class="st">" | "</span>.join(<span class="bu">list</span>(<span class="bu">zip</span>(<span class="op">*</span>model.get_topic(topic))) [<span class="dv">0</span>][:<span class="dv">4</span>]) </span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>        topic_words.append((topic, og_words, reranked_words,))</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pd.DataFrame(columns<span class="op">=</span>[<span class="st">"Topic"</span>, <span class="st">"Original"</span>, <span class="st">"Reranked"</span>], data<span class="op">=</span>topic_words)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-46" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> bertopic.representation <span class="im">import</span> KeyBERTInspired </span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Update our topic representations using KeyBERTInspired </span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>representation_model <span class="op">=</span> KeyBERTInspired() </span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>topic_model.update_topics(abstracts, representation_model<span class="op">=</span>representation_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-47" class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Show topic differences </span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>topic_differences(topic_model, original_topics, num_topics<span class="op">=</span><span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="41">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Topic</th>
<th data-quarto-table-cell-role="th">Original</th>
<th data-quarto-table-cell-role="th">Reranked</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0</td>
<td>speech | asr | recognition | end</td>
<td>transcription | phonetic | speech | language</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>1</td>
<td>question | qa | questions | answer</td>
<td>answering | comprehension | retrieval | questions</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>2</td>
<td>medical | clinical | biomedical | patient</td>
<td>nlp | clinical | text | language</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>3</td>
<td>translation | nmt | machine | neural</td>
<td>translation | translate | translations | multi...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>4</td>
<td>summarization | summaries | summary | abstractive</td>
<td>summarization | summarizers | summaries | abst...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>5</td>
<td>hate | offensive | speech | detection</td>
<td>hate | hateful | language | cyberbullying</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>6</td>
<td>gender | bias | biases | debiasing</td>
<td>gendered | gender | bias | biases</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7</td>
<td>7</td>
<td>relation | extraction | relations | re</td>
<td>relation | relations | relational | extracting</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">8</td>
<td>8</td>
<td>ner | entity | named | recognition</td>
<td>entity | entities | labeled | name</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">9</td>
<td>9</td>
<td>agents | agent | game | games</td>
<td>reasoning | ai | game | agents</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="maximal-marginal-relevance" class="level3">
<h3 class="anchored" data-anchor-id="maximal-marginal-relevance">2.2.2. Maximal Marginal Relevance</h3>
</section>
</section>
<section id="text-generation" class="level2">
<h2 class="anchored" data-anchor-id="text-generation">2.3. Text Generation</h2>
</section>
</section>
<section id="references" class="level1">
<h1>References</h1>
<ul>
<li>Chapter 5 of Hands On LLMs</li>
<li><a href="https://huggingface.co/spaces/mteb/leaderboard">MTEB leaderboard</a></li>
<li><a href="https://maartengr.github.io/BERTopic/getting_started/best_practices/best_practices.html">BERT best practices</a></li>
</ul>


</section>

<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>