<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Gurpreet Johl">
<meta name="dcterms.date" content="2023-02-23">
<meta name="description" content="Notes on Tensorflow">

<title>Gurpreet Johl - Tensorflow Notes</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="../../../site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="../../../site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="../../../site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Gurpreet Johl</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../blog.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/gjohl"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/gurpreetjohl"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/gurpreetjohl"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Tensorflow Notes</h1>
                  <div>
        <div class="description">
          Notes on Tensorflow
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">AI</div>
                <div class="quarto-category">Engineering</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Gurpreet Johl </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">February 23, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#machine-learning-notes" id="toc-machine-learning-notes" class="nav-link active" data-scroll-target="#machine-learning-notes">Machine Learning Notes</a>
  <ul class="collapse">
  <li><a href="#end-end-process" id="toc-end-end-process" class="nav-link" data-scroll-target="#end-end-process">1. End-end-process</a></li>
  <li><a href="#machine-learning-categories" id="toc-machine-learning-categories" class="nav-link" data-scroll-target="#machine-learning-categories">2. Machine learning categories</a></li>
  <li><a href="#deep-learning-models" id="toc-deep-learning-models" class="nav-link" data-scroll-target="#deep-learning-models">3. Deep learning models</a>
  <ul class="collapse">
  <li><a href="#ann-artificial-neural-network" id="toc-ann-artificial-neural-network" class="nav-link" data-scroll-target="#ann-artificial-neural-network">3.1 ANN (Artificial Neural Network)</a></li>
  <li><a href="#cnn-convolutional-neural-network" id="toc-cnn-convolutional-neural-network" class="nav-link" data-scroll-target="#cnn-convolutional-neural-network">3.2. CNN (Convolutional Neural Network)</a></li>
  <li><a href="#rnn-recurrent-neural-network" id="toc-rnn-recurrent-neural-network" class="nav-link" data-scroll-target="#rnn-recurrent-neural-network">3.3. RNN (Recurrent Neural Network)</a></li>
  <li><a href="#natural-language-processing-nlp" id="toc-natural-language-processing-nlp" class="nav-link" data-scroll-target="#natural-language-processing-nlp">3.4 Natural Language Processing (NLP)</a></li>
  <li><a href="#autoencoders" id="toc-autoencoders" class="nav-link" data-scroll-target="#autoencoders">3.5 AutoEncoders</a></li>
  <li><a href="#generative-adversarial-networks-gans" id="toc-generative-adversarial-networks-gans" class="nav-link" data-scroll-target="#generative-adversarial-networks-gans">3.6 Generative Adversarial Networks (GANs)</a></li>
  </ul></li>
  <li><a href="#a.-appendix" id="toc-a.-appendix" class="nav-link" data-scroll-target="#a.-appendix">A. Appendix</a>
  <ul class="collapse">
  <li><a href="#a.1.-neural-networks" id="toc-a.1.-neural-networks" class="nav-link" data-scroll-target="#a.1.-neural-networks">A.1. Neural networks</a></li>
  <li><a href="#a.2.-cnns" id="toc-a.2.-cnns" class="nav-link" data-scroll-target="#a.2.-cnns">A.2. CNNs</a></li>
  <li><a href="#a.3.-rnns" id="toc-a.3.-rnns" class="nav-link" data-scroll-target="#a.3.-rnns">A.3. RNNs</a></li>
  <li><a href="#a.4.nlp" id="toc-a.4.nlp" class="nav-link" data-scroll-target="#a.4.nlp">A.4.NLP</a></li>
  <li><a href="#a.5.-gans" id="toc-a.5.-gans" class="nav-link" data-scroll-target="#a.5.-gans">A.5. GANs</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="machine-learning-notes" class="level1">
<h1>Machine Learning Notes</h1>
<p>These are notes taken primarily from the <a href="https://www.udemy.com/course/complete-tensorflow-2-and-keras-deep-learning-bootcamp">Complete Tensorflow and Keras Udemy course</a></p>
<section id="end-end-process" class="level2">
<h2 class="anchored" data-anchor-id="end-end-process">1. End-end-process</h2>
<ol type="1">
<li>Data sourcing - train_test_split</li>
<li>Exploratory data analysis - plot distributions, correlations</li>
<li>Data cleaning - drop redundant columns, handle missing data (drop or impute)</li>
<li>Feature engineering - one hot encoding categories, scaling/normalising numerical values, combining columns, extracting info from columns (e.g.&nbsp;zip code from address)</li>
<li>Model selection and training - model and hyperparameters</li>
<li>Model tuning and evaluation metrics - classification: classification_report, confusion matrix, accuracy, recall, F1. Regression: error (RMSE, MAE, etc)</li>
<li>Predictions</li>
</ol>
</section>
<section id="machine-learning-categories" class="level2">
<h2 class="anchored" data-anchor-id="machine-learning-categories">2. Machine learning categories</h2>
<ul>
<li>Supervised learning
<ul>
<li>Linear regression</li>
<li>SVM</li>
<li>Naive Bayes</li>
<li>KNN</li>
<li>Random forests</li>
</ul></li>
<li>Unsupervised learning
<ul>
<li>Dimensionality reduction</li>
<li>Clustering</li>
</ul></li>
<li>Reinforcement Learning</li>
</ul>
<p>Supervised learning tasks can be broadly broken into:</p>
<ul>
<li>Regression</li>
<li>Classification
<ul>
<li>Single class</li>
<li>Multi class</li>
</ul></li>
</ul>
</section>
<section id="deep-learning-models" class="level2">
<h2 class="anchored" data-anchor-id="deep-learning-models">3. Deep learning models</h2>
<section id="ann-artificial-neural-network" class="level3">
<h3 class="anchored" data-anchor-id="ann-artificial-neural-network">3.1 ANN (Artificial Neural Network)</h3>
<p>General idea of a neural network that can then be extended to specific cases, e.g.&nbsp;CNNs and RNNs.</p>
<ul>
<li>Perceptron: a weighted average of inputs passed through some activation gate function to arrive at an output decision</li>
<li>Network of perceptrons</li>
<li>Activation function: a non-linear transfer function f(wx+b)</li>
<li>Cost function and gradient descent: convex optimisation of a loss function using sub-gradient descent. The optimizer can be set in the compile method of the model.</li>
<li>Backpropagation: use chain rule to determine partial gradients of each weight and bias. This means we only need a single forward pass followed by a single backward pass. Contrast this to if we perturbed each weight or bias to determine each partial gradient: in that case, for each epoch we would need to run a forward pass per weight/bias in the network, which is potentially millions!</li>
<li>Dropout: a technique to avoid overfitting by randomly dropping neurons in each epoch.</li>
</ul>
<p>General structure:</p>
<ol type="1">
<li>Input layer</li>
<li>Hidden layer(s)</li>
<li>Output layer</li>
</ol>
<p>Input and output layers are determined by the problem:</p>
<ul>
<li>Input size: number of features in the data</li>
<li>Output size number of targets to predict, i.e.&nbsp;one for single class classification or single target regression, or multiple for multiclass (one per class)</li>
<li>Output layer activation determined by problem. For single class classification <code>activation='sigmoid'</code>, for multiclass classification <code>activation='softmax'</code></li>
<li>Loss function determined by problem. For single class classification <code>loss='binary_crossentropy'</code>, for multiclass classification <code>loss='categorical_crossentropy'</code></li>
</ul>
<p>Hidden layers are less well-defined. Some heuristics <a href="https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw">here</a>.</p>
<p>Vanishing gradients can be an issue for lower layers in particular, where the partial gradients of individual layers can be very small, so when multiplied together in chain rule the gradient is vanishingly small. Exploding gradients are a similar issue but where gradients get increasingly large when multiplied together. Some techniques to rectify vanishing/exploding gradients:</p>
<ul>
<li>Use different activation functions with larger gradients close to 0 and 1, e.g.&nbsp;leaky ReLU or ELU (exponential linear unit)</li>
<li>Batch normalisation: scale each gradient by the mean and standard deviation of the batch</li>
<li>Different weight initialisation methods, e.g.&nbsp;Xavier initialisation</li>
</ul>
<p>Example model outline</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.models <span class="im">import</span> Sequential</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.layers <span class="im">import</span> Dense, Dropout</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Input layer</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">78</span>, activation<span class="op">=</span><span class="st">'relu'</span>))  <span class="co"># Number of input features</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>model.add(Dropout(<span class="fl">0.2</span>))  <span class="co"># Optional dropout layer after each layer. Omitted for next layers for clarity</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Hidden layers</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">39</span>, activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">19</span>, activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Output layer</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">1</span>, activation<span class="op">=</span><span class="st">'sigmoid'</span>))  <span class="co"># Number of target classes (single class in this case)</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Problem setup</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">'binary_crossentropy'</span>, optimizer<span class="op">=</span><span class="st">'adam'</span>)  <span class="co"># Type of problem (single class classification in this case)</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Training</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>model.fit(</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>    x<span class="op">=</span>X_train,</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>    y<span class="op">=</span>y_train,</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">256</span>,</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>    epochs<span class="op">=</span><span class="dv">30</span>,</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>    validation_data<span class="op">=</span>(X_test, y_test)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Prediction</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>model.predict(new_input)  <span class="co"># The new input needs to be shaped and scaled the sane as the training data</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="cnn-convolutional-neural-network" class="level3">
<h3 class="anchored" data-anchor-id="cnn-convolutional-neural-network">3.2. CNN (Convolutional Neural Network)</h3>
<p>These are used for image classification problems where convolutional filters are useful for extracting features from input arrays.</p>
<ul>
<li>Image kernels/filters
<ul>
<li>Grayscale 2D arrays</li>
<li>RGB 3D tensors</li>
</ul></li>
<li>Convolutional layers</li>
<li>Pooling layers</li>
</ul>
<p>General structure:</p>
<ol type="1">
<li>Input layer</li>
<li>Convolutional layer</li>
<li>Pooling layer</li>
<li>(Optionally more pairs of convolutional and pooling layers)</li>
<li>Flattening layer</li>
<li>Dense hidden layer(s)</li>
<li>Output layer</li>
</ol>
<p>Example model outline</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.models <span class="im">import</span> Sequential</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.layers <span class="im">import</span> Dense, Conv2D, MaxPool2D, Flatten</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.callbacks <span class="im">import</span> EarlyStopping</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Convolutional layer followed by pooling. Deeper networks may have multiple pairs of these.</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>model.add(Conv2D(filters<span class="op">=</span><span class="dv">32</span>, kernel_size<span class="op">=</span>(<span class="dv">4</span>,<span class="dv">4</span>),input_shape<span class="op">=</span>(<span class="dv">28</span>, <span class="dv">28</span>, <span class="dv">1</span>), activation<span class="op">=</span><span class="st">'relu'</span>,))  <span class="co"># Input shape determined by input data size</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>model.add(MaxPool2D(pool_size<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">2</span>)))</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Flatten _images from 2D to 1D before final layer</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>model.add(Flatten())</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Dense hidden layer</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Output layer</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">10</span>, activation<span class="op">=</span><span class="st">'softmax'</span>))  <span class="co"># Size and activation determined by problem; multiclass classification in this case</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Problem setup</span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">'categorical_crossentropy'</span>, optimizer<span class="op">=</span><span class="st">'adam'</span>)  <span class="co"># Loss determined by problem, multiclass classification in this case</span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Training (with optional early stopping)</span></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>early_stop <span class="op">=</span> EarlyStopping(monitor<span class="op">=</span><span class="st">'val_loss'</span>,patience<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>model.fit(x_train,y_cat_train,epochs<span class="op">=</span><span class="dv">10</span>,validation_data<span class="op">=</span>(x_test,y_cat_test),callbacks<span class="op">=</span>[early_stop])</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Prediction</span></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>model.predict(new_input)  <span class="co"># The new input needs to be shaped and scaled the sane as the training data</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="rnn-recurrent-neural-network" class="level3">
<h3 class="anchored" data-anchor-id="rnn-recurrent-neural-network">3.3. RNN (Recurrent Neural Network)</h3>
<p>These are used for modelling sequences with variable lengths of inputs and outputs.</p>
<p>Recurrent neurons take as their input the current data AND the previous epoch’s output. We could try to pass EVERY previous epoch’s output as an input, but would run into issues of vanushing gradients.</p>
<p>LSTMs take this idea a step further by incorporating the previous epochs input AND some longer lookback of epoch where some old outputs are “forgotten”.</p>
<p>A basic RNN:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode tex code-with-copy"><code class="sourceCode latex"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>            --------------------------------</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>            |                              |</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a> H_t-1 ---&gt; |                              |---&gt; H_t</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>            |                              |</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a> X_t   ---&gt; |                              |</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>            |                              |</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>            --------------------------------</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>where:</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>H_t is the neuron's output at current epoch t</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>H_t-1 is the neuron's output from the previous epoch t-1</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>X_t is the input data at current epoch t</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>H_t = tanh(W[H_t-1, X_t] + b)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>An LSTM (Long Short Term Memory) unit:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode tex code-with-copy"><code class="sourceCode latex"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>            --------------------------------</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>            |                              |</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a> H_t-1 ---&gt; |                              |---&gt; H_t</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>            |                              |</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a> C_t-1 ---&gt; |                              |---&gt; C_t</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>            |                              |</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a> X_t   ---&gt; |                              |</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>            |                              |</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>            --------------------------------</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>The `forget gate` determines which part of the old short-term memory and current input is "forgotten" by the new long-term memory.</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>These are a set of weights (between 0 and 1) that get applied to the old long-term memory to downweight it.</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>F_t = sigmoid(W_F[H_t-1, X_t] + b_F)</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>The `input gate` i_t similarly gates the input and old short-term memory.</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>This will later (in the update gate) get combined  with a candidate value for the new long-term memory `C_candidate_t`</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>I_t = sigmoid(W_I[H_t-1, X_t] + b_I)</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>C_candidate_t = tanh(W_C_cand[H_t-1, X_t] + b_C_cand) </span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>The `update gate` for the new long-term memory `C_t` is then calculated as a sum of forgotten old memory and input-weighted candidate memory:</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>C_t = F_t*C_t-1 + I_t*C_candidate_t </span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>The `output gate` O_t is a combination of the old short-term memory and latest input data.</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>This is then combined with the latest long-term memory to produce the output of the recurrent neuron, which is also the updated short-term memory H_t:</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>O_t = sigmoid(W_O[H_t-1, X_t] + b_O)</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>H_t = O_t * tanh(C_t) </span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>where:</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>H_t is short-term memory at epoch t</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>C_t is long-term memory at epoch t</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>X_t is the input data at current epoch t</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>sigmoid is a sigmoid  activation function</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>F_t is an intermediate forget gate weight</span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>I_t is an intermediate input gate weight</span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>O_t is an intermediate output gate weight</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>There are several variants of RNNs. <strong>RNNs with peepholes</strong></p>
<p>This leaks long-term memory into the forget, input and output gates. Note that the forget gate and input gate each get the OLD long-term memory, whereas the output gate gets the NEW long-term memory.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode tex code-with-copy"><code class="sourceCode latex"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>F_t = sigmoid(W_F[C_t-1, H_t-1, X_t] + b_F)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>I_t = sigmoid(W_I[C_t-1, H_t-1, X_t] + b_I)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>O_t = sigmoid(W_O[C_t, H_t-1, X_t] + b_O)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Gated Recurrent Unit (GRU)</strong></p>
<p>This combines the forget and input gates into a single gate. It also has some other changes. This is simpler than a typical LSTM model as it has fewer parameters. This makes it more computationally efficient, and in practice they can have similar performance.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode tex code-with-copy"><code class="sourceCode latex"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>z_t = sigmoid(W_z[H_t-1, X_t])</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>r_t = sigmoid(W_r[H_t-1, X_t])</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>H_candidate_t = tanh(W_H_candidate[r_t*h_t-1, x_t])</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>H_t = (1 - z_t) * H_t-1 + z_t * H_candidate_t</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The sequences modelled with RNNs can be:</p>
<ul>
<li>One-to-many</li>
<li>Many-to-many</li>
<li>Many-to-one</li>
</ul>
<p>Considerations for choosing the input sequence length:</p>
<ul>
<li>It should be long enough to capture any patterns or seasonality in the data</li>
<li>The validation set and test set each need to have a size at least (input_length + output_length), so the longer the input length, the more data is required to be set aside.</li>
</ul>
<p>The validation loss for RNNs/LSTMs can be volatile, so allow a higher patience when using early stopping.</p>
<p>Example model</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.callbacks <span class="im">import</span> EarlyStopping</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.preprocessing.sequence <span class="im">import</span> TimeseriesGenerator</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.models <span class="im">import</span> Sequential</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.layers <span class="im">import</span> Dense,LSTM</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Generators for helper functions to chunk up the input series into an array of pairs of (input_batch, target_output)</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>train_generator <span class="op">=</span> TimeseriesGenerator(scaled_train, scaled_train, length<span class="op">=</span>batch_length, batch_size<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>validation_generator <span class="op">=</span> TimeseriesGenerator(scaled_test, scaled_test, length<span class="op">=</span>batch_length, batch_size<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an LSTM model</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>model.add(LSTM(<span class="dv">100</span>, activation<span class="op">=</span><span class="st">'relu'</span>, input_shape<span class="op">=</span>(batch_length, n_features)))</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>model.add(Dense(<span class="dv">1</span>))  <span class="co"># Output layer</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">'adam'</span>, loss<span class="op">=</span><span class="st">'mse'</span>)  <span class="co"># Problem setup for regression</span></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model</span></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>early_stop <span class="op">=</span> EarlyStopping(monitor<span class="op">=</span><span class="st">'val_loss'</span>, patience<span class="op">=</span><span class="dv">10</span>)  <span class="co"># RNNs can be volatile so if use a higher patience with an early stopping callback</span></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>model.fit(train_generator, epochs<span class="op">=</span><span class="dv">20</span>, validation_data<span class="op">=</span>validation_generator, callbacks<span class="op">=</span>[early_stop])</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate test data</span></span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>test_predictions <span class="op">=</span> []</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>final_batch <span class="op">=</span> scaled_train[<span class="op">-</span>batch_length:, :]</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>current_batch <span class="op">=</span> final_batch.reshape((<span class="dv">1</span>, batch_length, n_features))</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> test_val <span class="kw">in</span> scaled_test:</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>    pred_val <span class="op">=</span> model.predict(current_batch)  <span class="co"># These will later need to use the scaler.inverse_transform of the scaler originally used on the training data</span></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>    test_predictions.append(pred_val[<span class="dv">0</span>])</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>    current_batch <span class="op">=</span> np.append(current_batch[:,<span class="dv">1</span>:,:], pred_val.reshape(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>), axis<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="natural-language-processing-nlp" class="level3">
<h3 class="anchored" data-anchor-id="natural-language-processing-nlp">3.4 Natural Language Processing (NLP)</h3>
<p>Character-based generative NLP: given an input string, e.g.&nbsp;[‘h’, ‘e’, ‘l’, ‘l’], predict the sequence shifted by one character, e.g.&nbsp;[‘e’, ‘l’, ‘l’, ‘o’]</p>
<p>The embedding, GRU and dense layers work on the sequence in the following way: <a href="NLP_layers.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="NLP Layers"><img src="NLP_layers.png" id="fig-nlp-layers" class="img-fluid" alt="NLP Layers"></a></p>
<p>Steps:</p>
<ol type="1">
<li>Read in text data</li>
<li>Text processing and vectorisation - one-hot encoding</li>
<li>Create batches</li>
<li>Create the model</li>
<li>Train the model</li>
<li>Generate new text</li>
</ol>
<p><strong>Step 1: Read in text data</strong></p>
<ul>
<li>A corpus of &gt;1 million characters is a good size</li>
<li>The more distinct the style of your corpus, the more obvious it will be if your model has worked.</li>
</ul>
<p>Given some structured <code>input_text</code> string, we can get the one-hot encoded vocab list of unique characters.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>vocab_list <span class="op">=</span> <span class="bu">sorted</span>(<span class="bu">set</span>(input_text))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Step 2: Text processing</strong></p>
<p>Vectorise the text - create a mapping between character and integer. This is the encoding dictionary used to vectorise the corpus.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Mappings back and forth between characters and their encoded integers</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>char_to_ind <span class="op">=</span> {char: ind <span class="cf">for</span> ind, char <span class="kw">in</span> <span class="bu">enumerate</span>(vocab_list)}</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>ind_to_char <span class="op">=</span> {ind: char <span class="cf">for</span> ind, char <span class="kw">in</span> <span class="bu">enumerate</span>(vocab_list)}</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>encoded_text <span class="op">=</span> np.array([char_to_ind[char] <span class="cf">for</span> char <span class="kw">in</span> input_text])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Step 3: Create batches</strong></p>
<p>The sequence length should be long enough to capture structure, e.g.&nbsp;for poetry with rhyming couplets it should be the number of characters in 3 lines to capture the rhyme and non-rhyme. Too long a sequence makes the model take longer to train and captures too much historical noise.</p>
<p>Create a shuffled dataset where:</p>
<ul>
<li>input sequence is the first n characters</li>
<li>output sequence is n characters lagged by one</li>
</ul>
<p>We want to shuffle these sequence pairs into a random order so the model doesn’t overfit to any section of the text, but can instead generate characters given any seed text.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>seq_len <span class="op">=</span> <span class="dv">120</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>total_num_seq <span class="op">=</span> <span class="bu">len</span>(input_text) <span class="op">//</span> (seq_len <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create Training Sequences</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>char_dataset <span class="op">=</span> tf.data.Dataset.from_tensor_slices(encoded_text)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>sequences <span class="op">=</span> char_dataset.batch(seq_len <span class="op">+</span> <span class="dv">1</span>, drop_remainder<span class="op">=</span><span class="va">True</span>)  <span class="co"># drop_remainder drops the last incomplete sequence</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Create tuples of input and output sequences</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_seq_targets(seq):</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>    input_seq <span class="op">=</span> seq[:<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    output_seq <span class="op">=</span> seq[<span class="op">-</span><span class="dv">1</span>:]</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> input_seq, output_seq</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> sequences.<span class="bu">map</span>(create_seq_targets)</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate training batches</span></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">128</span></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>buffer_size <span class="op">=</span> <span class="dv">10000</span>  <span class="co"># Shuffle this amount of batches rather than shuffling the entire dataset in memory</span></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> dataset.shuffle(buffer_size).batch(batch_size, drop_remainder<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Step 4: Create the model</strong></p>
<p>Set up the loss function and layers.</p>
<p>This model uses 3 layers:</p>
<ol type="1">
<li>Embedding
<ul>
<li>Embed positive integers, e.g.&nbsp;“a”&lt;-&gt;1, as dense vectors of fixed size. This embedding size is a hyperparameter for the user to decide.</li>
<li>Number of layers should be smaller but a similar scale to the vocab size; typically use the power of 2 that is just smaller than the vocab size.</li>
</ul></li>
<li>GRU
<ul>
<li>This is the main thing to vary in the model: number of hidden layers and number of neurons in each, types of neurons (RNN, LSTM, GRU), etc. Typically use lots of layers here.</li>
</ul></li>
<li>Dense
<ul>
<li>One neuron per character (one-hot encoded), so this produces a probability per character. The user can vary the “temperature”, choosing less probable characters more/less often.</li>
</ul></li>
</ol>
<p>Loss function:</p>
<ul>
<li>Sparse categorical cross-entropy</li>
<li>Use <em>sparse</em> categorical cross-entropy because the classes are mutually exclusive. Use regular categorical cross-entropy when one smaple can have multiple classes, or the labels are soft probabilities.</li>
<li>See link in NLP appendix for discussion.</li>
<li>Use logits=True because vocab input is one hot encoded.</li>
</ul>
<div class="sourceCode" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.models <span class="im">import</span> Sequential</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.layers <span class="im">import</span> LSTM, Dense, Embedding, Dropout, GRU</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.losses <span class="im">import</span> sparse_categorical_crossentropy</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Hyperparameters</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>vocab_size <span class="op">=</span> <span class="bu">len</span>(vocab_list)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>embed_dim <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>rnn_neurons <span class="op">=</span> <span class="dv">1026</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Create model </span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential()</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>model.add(Embedding(vocab_size, embed_dim, batch_input_shape<span class="op">=</span>[batch_size, <span class="va">None</span>]))</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>model.add(GRU(rnn_neurons, return_sequences<span class="op">=</span><span class="va">True</span>, stateful<span class="op">=</span><span class="va">True</span>, recurrent_initializer<span class="op">=</span><span class="st">'glorot_uniform'</span>))</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>model.add(Dense(vocab_size))</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>sparse_cat_loss <span class="op">=</span> <span class="kw">lambda</span> y_true,y_pred: sparse_categorical_crossentropy(y_true, y_pred, from_logits<span class="op">=</span><span class="va">True</span>)  <span class="co"># We want a custom loss function with logits=True</span></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">'adam'</span>, loss<span class="op">=</span>sparse_cat_loss) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Step 5: Train the model</strong></p>
<div class="sourceCode" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">30</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>model.fit(dataset,epochs<span class="op">=</span>epochs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Step 6: Generate text</strong></p>
<p>Allow the model to accept a batch size of 1 to allow us to give an input seed text from which to generate text from.</p>
<p>We format the seed text so it can be fed into the network, then loop through generating one character at a time and feeding that back into the model.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>model.build(tf.TensorShape([<span class="dv">1</span>, <span class="va">None</span>]))</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_text(model, input_seed_text, gen_size<span class="op">=</span><span class="dv">100</span>, temperature<span class="op">=</span><span class="fl">1.0</span>):</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="co">    model: tensorflow.model</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="co">    input_seed_text: str</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="co">    gen_size: int</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="co">    temperature: float</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>    generated_text_result <span class="op">=</span> []</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>    vectorised_seed <span class="op">=</span> tf.expand_dims([char_to_ind[s] <span class="cf">for</span> s <span class="kw">in</span> input_seed_text], <span class="dv">0</span>)</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>    model.reset_states()</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(gen_size):</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>        raw_predictions <span class="op">=</span> model(vectorised_seed)</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>        predictions <span class="op">=</span> tf.squeeze(raw_predictions, <span class="dv">0</span>) <span class="op">/</span> temperature</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>        predicted_index <span class="op">=</span> tf.random.categorical(predictions, num_samples<span class="op">=</span><span class="dv">1</span>)[<span class="op">-</span><span class="dv">1</span>,<span class="dv">0</span>].numpy()</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>        generated_text_result.append(ind_to_char[predicted_index])</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Set a new vectorised seed to generate the next character in the loop</span></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>        vectorised_seed <span class="op">=</span> tf.expand_dims([predicted_index], <span class="dv">0</span>)</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (input_seed_text <span class="op">+</span> <span class="st">''</span>.join(generated_text_result))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="autoencoders" class="level3">
<h3 class="anchored" data-anchor-id="autoencoders">3.5 AutoEncoders</h3>
<p>This is an unsupervised learning problem, therefore evaluation metrics are different. Sometimes called semi-supervised as labels may be used in training the model, but not available when it’s used to predict new values.</p>
<p>Applications:</p>
<ul>
<li>Dimensionality reduction</li>
<li>Noise removal</li>
</ul>
<p>Designed to reproduce its input in the output layer. Number of input neurons is the same as the number of output layers. The encoder reduces dimensionality to the hidden layer. The hidden layer should contain the most relevant information required to reconstruct the input. The decoder reconstructs a high dimensional output from a low dimensional input.</p>
<ul>
<li>Encoder: Input layer -&gt; Hidden layer</li>
<li>Decoder: Hidden layer -&gt; Output</li>
</ul>
<p>Stacked autoencoders include multiple hidden layers.</p>
<p><strong>Autoencoder for dimensionality reduction</strong></p>
<p>Let’s try to reduce an input dataset from 3 dimensions to 2. We want to train an autoencoder to go from 3 -&gt; 2 -&gt; 3.</p>
<p>When we scale data, we fit and transform on the entire dataset rather than a train/test split, because there is no ground truth for the “correct” dimensionality reduction.</p>
<p>Using SGD in Autoencoders allows the learning rate to be varied as a hyperparameter to affect how well the hidden layer learns. Larger values will train quicker but potentially perform worse.</p>
<p>To retrieve the lower dimensionality representation, use <em>just the encoder</em> half of the trained autoencoder to predict the input.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Scale data</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> MinMaxScaler()</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>scaled_data <span class="op">=</span> scaler.fit_transform(input_features)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create model</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>encoder <span class="op">=</span> Sequential()</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>encoder.add(Dense(units<span class="op">=</span><span class="dv">2</span>, acivation<span class="op">=</span><span class="st">'relu'</span>, input_shape<span class="op">=</span>[<span class="dv">3</span>]))</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>decoder <span class="op">=</span> Sequential()</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>decoder.add(Dense(units<span class="op">=</span><span class="dv">3</span>, acivation<span class="op">=</span><span class="st">'relu'</span>, input_shape<span class="op">=</span>[<span class="dv">2</span>]))</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>autoencoder <span class="op">=</span> Sequential([encoder, decoder])</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>autoencoder.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">'mse'</span>, optimizer<span class="op">=</span>SGD(lr<span class="op">=</span><span class="fl">1.5</span>))</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the full autoencoder model</span></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>autoencoder.fit(scaled_data, scaled_data, epochs<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Reduce dimensionality by using just the encoder part of the trained model</span></span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>encoded_2dim <span class="op">=</span> encoder.predict(scaled_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Autoencoder for noise removal</strong></p>
<p>Starting with clean images, we want to train an autoencoder to learn to remove noise. We create a noisy dataset by adding noise to our clean images. We then try to reconstruct that input, and compare to the original clean images as the ground truth.</p>
<p>Starting with 28x28 images (e.g.&nbsp;MNIST dataset), this gives 784 input features when flattened. Use multiple hidden layers as there are a large number of input features that would be difficult to learn in one layer. The numbers of layers and number of neurons in each are hyperparameters to tune; decreasing in powers of 2 is a good rule of thumb.</p>
<p>Add a Gaussian noise layer to train the model to remove noise. Without the Gaussian layer, the model would be used for dimensionality reduction rather than noise removal.</p>
<p>The final layer uses a sigmoid activation because it is a binary classification problem - does the output match the input?</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>encoder <span class="op">=</span> Sequential()</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>encoder.add(Flatten(input_shape<span class="op">=</span>[<span class="dv">28</span>, <span class="dv">28</span>]))</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>encoder.add(Gaussian(<span class="fl">0.2</span>))  <span class="co"># Optional layer if training for noise removal rather than dimensionality reduction</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>encoder.add(Dense(<span class="dv">400</span>, activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>encoder.add(Dense(<span class="dv">200</span>, activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>encoder.add(Dense(<span class="dv">100</span>, activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>encoder.add(Dense(<span class="dv">50</span>, activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>encoder.add(Dense(<span class="dv">25</span>, activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>decoder <span class="op">=</span> Sequential()</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>decoder.add(Dense(<span class="dv">50</span>, input_shape<span class="op">=</span>[<span class="dv">25</span>], activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>decoder.add(Dense(<span class="dv">100</span>, activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>decoder.add(Dense(<span class="dv">200</span>, activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>decoder.add(Dense(<span class="dv">400</span>, activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>decoder.add(Dense(<span class="dv">28</span><span class="op">*</span><span class="dv">28</span>, activation<span class="op">=</span><span class="st">'sigmoid'</span>))</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>autoencoder <span class="op">=</span> Sequential([encoder, decoder])</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>autoencoder.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">'binary_crossentropy'</span>, optimizer<span class="op">=</span>SGD(lr<span class="op">=</span><span class="fl">1.5</span>), metrics<span class="op">=</span>[<span class="st">'accuracy'</span>])</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>autoencoder.fit(X_train, X_train, epochs<span class="op">=</span><span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="generative-adversarial-networks-gans" class="level3">
<h3 class="anchored" data-anchor-id="generative-adversarial-networks-gans">3.6 Generative Adversarial Networks (GANs)</h3>
<p>Use 2 networks competing against each other to generate data - counterfeiter (generator) vs detective (discriminator).</p>
<ul>
<li>Generator: recieves random noise</li>
<li>Discriminator: receives data set containing real data and fake generated data, and attempts to calssify real vs fake (binary classificaiton).</li>
</ul>
<p>Two training phases, each only training one of the networks:</p>
<ol type="1">
<li>Train discriminator - real images (labeled 1) and generated images (labeled 0) are fed to the discriminator network.</li>
<li>Train generator - only feed generated images to discriminator, ALL labeled 1.</li>
</ol>
<p>The generator never sees real images, it creates images based only off of the gradients flowing back from the discriminator.</p>
<p>Difficulties with GANs:</p>
<ol type="1">
<li>Training resources - GPUs generally required</li>
<li>Mode collapse - generator learns an image that fools the discriminator, then only produces this image. Deep convolutional GANs and mini-batch discrimination are two solution to this problem.</li>
<li>Instability - True performance is hard to measure; just because the discriminator was fooled, it doesn’t mean that the generated image was actually realistic.</li>
</ol>
<p><strong>Creating the model</strong></p>
<p>We create the generator and discriminator as separate models, then join them into a GAN object. This is analogous to how we joined an encoder and decoder into an autoencoder.</p>
<p>The discriminator is trained on a binary classification problem, real or fake, so uses a binary cross entropy loss function. Backpropagation only alters the weights of the discriminator in the first phase, not the generator.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>discriminator <span class="op">=</span> Sequential()</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Flatten the image</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>discriminator.add(Flatten(input_shape<span class="op">=</span>[<span class="dv">28</span>,<span class="dv">28</span>]))</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Some hidden layers</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>discriminator.add(Dense(<span class="dv">150</span>,activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>discriminator.add(Dense(<span class="dv">100</span>,activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Binary classification - real vs fake</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>discriminator.add(Dense(<span class="dv">1</span>,activation<span class="op">=</span><span class="st">"sigmoid"</span>))</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>discriminator.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">"binary_crossentropy"</span>, optimizer<span class="op">=</span><span class="st">"adam"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The generator is trained in the second phase.</p>
<p>We set a codings_size, which is the size of the latent representation from which the generator will create a full image. For example, if we want to create a 28x28 image (784 pixels), we may want to generate this from a 100 element input. This is analogous to the decoder part of an autoencoder.</p>
<p>The codings_size should be smaller than the total number of features but large enough so that there is something to learn from.</p>
<p>The generator is NOT compiled at this step, it is compiled in the combined GAN later so that it is only trained at that step.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>codings_size <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>generator <span class="op">=</span> Sequential()</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Input shape of first layer is the codings_size</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>generator.add(Dense(<span class="dv">150</span>, activation<span class="op">=</span><span class="st">"relu"</span>, input_shape<span class="op">=</span>[codings_size]))</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Some hidden layers</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>generator.add(Dense(<span class="dv">200</span>,activation<span class="op">=</span><span class="st">'relu'</span>))</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Output is the size of the image we want to create</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>generator.add(Dense(<span class="dv">784</span>, activation<span class="op">=</span><span class="st">"sigmoid"</span>))</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>generator.add(Reshape([<span class="dv">28</span>,<span class="dv">28</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The GAN combines the generator and discriminator.</p>
<p>The discriminator is only trained in the first phase, not the second phase.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>GAN <span class="op">=</span> Sequential([generator, discriminator])</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>discriminator.trainable <span class="op">=</span> <span class="va">False</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>GAN.<span class="bu">compile</span>(loss<span class="op">=</span><span class="st">"binary_crossentropy"</span>, optimizer<span class="op">=</span><span class="st">"adam"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Training the model</strong></p>
<p>We first create batches of images from our input data, similarly to previous models.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">32</span>  <span class="co"># Size of training input batches</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>buffer_size <span class="op">=</span> <span class="dv">1000</span>  <span class="co"># Don't load the entire dataset into memory</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>epochs <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>raw_dataset <span class="op">=</span> tf.data.Dataset.from_tensor_slices(X_train).shuffle(buffer_size<span class="op">=</span>buffer_size)</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>batched_dataset <span class="op">=</span> raw_dataset.batch(batch_size, drop_remainder<span class="op">=</span><span class="va">True</span>).prefetch(<span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The training loop for each epoch trains the discriminator to distinguish real vs fake images (binary classification). Then it trains the generator to generate fake images using ONLY the gradients learned in the discriminator training step; the generator NEVER sees any real images.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>generator, discriminator <span class="op">=</span> GAN.layers</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> index, X_batch <span class="kw">in</span> <span class="bu">enumerate</span>(batched_dataset):</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Phase 1: Train the discriminator</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>        noise <span class="op">=</span> tf.random.normal(shape<span class="op">=</span>[batch_size, codings_size])</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>        generated_images <span class="op">=</span> generator(noise)</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>        real_images <span class="op">=</span> tf.dtypes.cast(X_batch,tf.float32)</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>        X_train_discriminator <span class="op">=</span> tf.concat([generated_images, real_images], axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>        y_train_discriminator <span class="op">=</span> tf.constant([[<span class="fl">0.</span>]] <span class="op">*</span> batch_size <span class="op">+</span> [[<span class="fl">1.</span>]] <span class="op">*</span> batch_size)  <span class="co"># Targets set to zero for fake _images and 1 for real _images</span></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>        discriminator.trainable <span class="op">=</span> <span class="va">True</span></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>        discriminator.train_on_batch(X_train_discriminator, y_train_discriminator)</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Phase 2: Train the generator</span></span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>        noise <span class="op">=</span> tf.random.normal(shape<span class="op">=</span>[batch_size, codings_size])</span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>        y_train_generator <span class="op">=</span> tf.constant([[<span class="fl">1.</span>]] <span class="op">*</span> batch_size)  <span class="co"># We want discriminator to believe that fake _images are real</span></span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>        discriminator.trainable <span class="op">=</span> <span class="va">False</span></span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>        GAN.train_on_batch(noise, y_train_generator)    </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Deep convolutional GANs</strong></p>
<p>These are GANs which use convolutional layers inside the discriminator and generator models.</p>
<p>The models are almost identical to the models above, just with additional Conv2D, Conv2DTranspose and BatchNormalization layers.</p>
<p>Changes compared to regular GANs:</p>
<ul>
<li>Additional convolutional layers in model.</li>
<li>Reshape the training set to match the images.</li>
<li>Rescale the training data to be between -1 and 1 so that tanh activation function works.</li>
<li>Activation of discriminator output layer is tanh rather than sigmoid.</li>
</ul>
</section>
</section>
<section id="a.-appendix" class="level2">
<h2 class="anchored" data-anchor-id="a.-appendix">A. Appendix</h2>
<section id="a.1.-neural-networks" class="level3">
<h3 class="anchored" data-anchor-id="a.1.-neural-networks">A.1. Neural networks</h3>
<ul>
<li><a href="https://www.udemy.com/course/complete-tensorflow-2-and-keras-deep-learning-bootcamp">Complete Tensorflow and Keras Udemy course</a></li>
<li><a href="http://neuralnetworksanddeeplearning.com/">Intuition behind neural networks</a></li>
<li><a href="https://www.deeplearningbook.org/">The deep learning bible (with lectures)</a></li>
<li><a href="https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw">Heuristics for choosing hidden layers</a></li>
<li><a href="https://stackoverflow.com/questions/68776790/model-predict-classes-is-deprecated-what-to-use-instead">Alternatives to the deprecated model predict for different classification problems</a></li>
<li><a href="https://openlearninglibrary.mit.edu/courses/course-v1:MITx+6.036+1T2019/course/">MIT course</a></li>
</ul>
</section>
<section id="a.2.-cnns" class="level3">
<h3 class="anchored" data-anchor-id="a.2.-cnns">A.2. CNNs</h3>
<ul>
<li><a href="https://setosa.io/ev/image-kernels/">Image kernels explained</a></li>
<li><a href="https://stats.stackexchange.com/questions/148139/rules-for-selecting-convolutional-neural-network-hyperparameters">Choosing CNN layers</a></li>
</ul>
</section>
<section id="a.3.-rnns" class="level3">
<h3 class="anchored" data-anchor-id="a.3.-rnns">A.3. RNNs</h3>
<ul>
<li><a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">Overview of RNNs</a></li>
<li><a href="https://en.wikipedia.org/wiki/Long_short-term_memory">Wikipedia page contains the equations of LSTMs and peepholes</a></li>
<li><a href="https://datascience.stackexchange.com/questions/14581/when-to-use-gru-over-lstm">LSTMs vs GRUs</a></li>
<li><a href="http://blog.echen.me/2017/05/30/exploring-lstms/">Worked example of LSTM</a></li>
<li><a href="https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks">RNN cheatsheet</a></li>
</ul>
</section>
<section id="a.4.nlp" class="level3">
<h3 class="anchored" data-anchor-id="a.4.nlp">A.4.NLP</h3>
<ul>
<li><a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">The unreasonable effectiveness of RNNs - essay on RNNs applied to NLP</a></li>
<li><a href="https://datascience.stackexchange.com/questions/41921/sparse-categorical-crossentropy-vs-categorical-crossentropy-keras-accuracy">Sparse vs dense categorical crossentropy loss function</a></li>
</ul>
</section>
<section id="a.5.-gans" class="level3">
<h3 class="anchored" data-anchor-id="a.5.-gans">A.5. GANs</h3>
<ul>
<li><a href="https://stackoverflow.com/questions/46444018/meaning-of-buffer-size-in-dataset-map-dataset-prefetch-and-dataset-shuffle">buffer_size argument in tensorflow prefetch and shuffle</a></li>
<li><a href="https://www.quora.com/What-does-it-mean-if-all-produced-images-of-a-GAN-look-the-same">Mode collapse</a></li>
</ul>


</section>
</section>
</section>

<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<script>var lightboxQuarto = GLightbox({"selector":".lightbox","closeEffect":"zoom","loop":false,"descPosition":"bottom","openEffect":"zoom"});
window.onload = () => {
  lightboxQuarto.on('slide_before_load', (data) => {
    const { slideIndex, slideNode, slideConfig, player, trigger } = data;
    const href = trigger.getAttribute('href');
    if (href !== null) {
      const imgEl = window.document.querySelector(`a[href="${href}"] img`);
      if (imgEl !== null) {
        const srcAttr = imgEl.getAttribute("src");
        if (srcAttr && srcAttr.startsWith("data:")) {
          slideConfig.href = srcAttr;
        }
      }
    } 
  });

  lightboxQuarto.on('slide_after_load', (data) => {
    const { slideIndex, slideNode, slideConfig, player, trigger } = data;
    if (window.Quarto?.typesetMath) {
      window.Quarto.typesetMath(slideNode);
    }
  });

};
          </script>




</body></html>