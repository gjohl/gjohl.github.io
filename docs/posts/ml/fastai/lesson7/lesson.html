<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Gurpreet Johl">
<meta name="dcterms.date" content="2024-03-01">
<meta name="description" content="Practical Deep Learning for Coders: Lesson 7">

<title>Gurpreet Johl - FastAI Lesson 7: Collaborative Filtering</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="../../../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../../index.html">
    <span class="navbar-title">Gurpreet Johl</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../../projects.html"> 
<span class="menu-text">Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../blog.html"> 
<span class="menu-text">Notes</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/gjohl"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/gurpreetjohl"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/gurpreetjohl"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">FastAI Lesson 7: Collaborative Filtering</h1>
                  <div>
        <div class="description">
          Practical Deep Learning for Coders: Lesson 7
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">AI</div>
                <div class="quarto-category">Engineering</div>
                <div class="quarto-category">FastAI</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Gurpreet Johl </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">March 1, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#collaborative-filtering" id="toc-collaborative-filtering" class="nav-link active" data-scroll-target="#collaborative-filtering">Collaborative Filtering</a>
  <ul class="collapse">
  <li><a href="#the-intuition-behind-collaborative-filtering" id="toc-the-intuition-behind-collaborative-filtering" class="nav-link" data-scroll-target="#the-intuition-behind-collaborative-filtering">1. The Intuition Behind Collaborative Filtering</a></li>
  <li><a href="#a-deep-learning-spreadsheet" id="toc-a-deep-learning-spreadsheet" class="nav-link" data-scroll-target="#a-deep-learning-spreadsheet">2. A deep learning spreadsheet (!)</a></li>
  <li><a href="#input-data-and-factors" id="toc-input-data-and-factors" class="nav-link" data-scroll-target="#input-data-and-factors">3. Input Data and Factors</a>
  <ul class="collapse">
  <li><a href="#loading-movielens-data" id="toc-loading-movielens-data" class="nav-link" data-scroll-target="#loading-movielens-data">3.1. Loading MovieLens data</a></li>
  <li><a href="#prepare-the-data" id="toc-prepare-the-data" class="nav-link" data-scroll-target="#prepare-the-data">3.2 Prepare the Data</a></li>
  </ul></li>
  <li><a href="#building-a-collaborative-filter-from-scratch" id="toc-building-a-collaborative-filter-from-scratch" class="nav-link" data-scroll-target="#building-a-collaborative-filter-from-scratch">4. Building a Collaborative Filter From Scratch</a>
  <ul class="collapse">
  <li><a href="#adding-a-bias-term" id="toc-adding-a-bias-term" class="nav-link" data-scroll-target="#adding-a-bias-term">4.2. Adding a bias term</a></li>
  <li><a href="#weight-decay" id="toc-weight-decay" class="nav-link" data-scroll-target="#weight-decay">4.3. Weight Decay</a></li>
  <li><a href="#creating-our-own-embedding-module" id="toc-creating-our-own-embedding-module" class="nav-link" data-scroll-target="#creating-our-own-embedding-module">4.3. Creating our own Embedding module</a></li>
  <li><a href="#interpreting-embeddings-and-biases" id="toc-interpreting-embeddings-and-biases" class="nav-link" data-scroll-target="#interpreting-embeddings-and-biases">4.4. Interpreting Embeddings and Biases</a></li>
  </ul></li>
  <li><a href="#building-a-collaborative-filter-with-fastais-library" id="toc-building-a-collaborative-filter-with-fastais-library" class="nav-link" data-scroll-target="#building-a-collaborative-filter-with-fastais-library">5. Building a Collaborative Filter with Fastai’s Library</a></li>
  <li><a href="#bootstrapping-a-collaborative-filtering-model" id="toc-bootstrapping-a-collaborative-filtering-model" class="nav-link" data-scroll-target="#bootstrapping-a-collaborative-filtering-model">6. Bootstrapping a Collaborative Filtering Model</a></li>
  <li><a href="#deep-learning-for-collaborative-filtering" id="toc-deep-learning-for-collaborative-filtering" class="nav-link" data-scroll-target="#deep-learning-for-collaborative-filtering">7. Deep Learning for Collaborative Filtering</a>
  <ul class="collapse">
  <li><a href="#building-a-deep-learning-collaborative-filter-from-scratch" id="toc-building-a-deep-learning-collaborative-filter-from-scratch" class="nav-link" data-scroll-target="#building-a-deep-learning-collaborative-filter-from-scratch">7.1. Building a Deep Learning Collaborative Filter From Scratch</a></li>
  <li><a href="#building-a-deep-learning-collaborative-filter-with-fastais-library" id="toc-building-a-deep-learning-collaborative-filter-with-fastais-library" class="nav-link" data-scroll-target="#building-a-deep-learning-collaborative-filter-with-fastais-library">7.2. Building a Deep Learning Collaborative Filter with Fastai’s Library</a></li>
  </ul></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">8. Summary</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="collaborative-filtering" class="level1">
<h1>Collaborative Filtering</h1>
<p>These are notes from lesson 7 of Fast AI Practical Deep Learning for Coders.</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Homework Task">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Homework Task
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Create a collaborative filtering model in a <a href="https://docs.google.com/spreadsheets/d/1tIzbgwu3qmAJounfKtr4n-uwAkupetmVqkHAWllYRDw/edit?usp=sharing">spreadsheet</a></li>
</ul>
</div>
</div>
<section id="the-intuition-behind-collaborative-filtering" class="level2">
<h2 class="anchored" data-anchor-id="the-intuition-behind-collaborative-filtering">1. The Intuition Behind Collaborative Filtering</h2>
<p>We have users ratings of movies.</p>
<p>Say we had “embeddings” of a set of categories for each. So for a given <strong>movie</strong>, we have a vector of <code>[action, sci-fi, romance]</code> and for a given <strong>user</strong> we have their preference for <code>[action, sci-fi, romance]</code>. Then we could do the dot product between user embedding and movie embedding to get the probability that the user likes that movie. That is, the predicted user rating.</p>
<p>So the problem boils down to:</p>
<ol type="1">
<li>What are the embeddings? i.e.&nbsp;the salient factors (<code>[action, sci-fi, romance]</code> in the example above)</li>
<li>How do we get them?</li>
</ol>
<p>The answer to both questions is: we just let the model learn them.</p>
<p>Let’s just pick a randomised embedding for each movie and each user. Then we have a loss function which is the MAE between predicted user rating for a movie and actual rating. Now we can use SGD to optimise those embeddings to find the best values.</p>
</section>
<section id="a-deep-learning-spreadsheet" class="level2">
<h2 class="anchored" data-anchor-id="a-deep-learning-spreadsheet">2. A deep learning spreadsheet (!)</h2>
<p>To gain an intuition behind the calculations behind a collaborative filter, we can work through a (smaller) example in excel. This allows us to see the logic and dig into the calculations before we create them “for real” in Python.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>This can be found in <a href="https://docs.google.com/spreadsheets/d/1tIzbgwu3qmAJounfKtr4n-uwAkupetmVqkHAWllYRDw/edit?usp=sharing">this spreadsheet</a>.</p>
</div>
</div>
<p>We first look at an example where the results are in a cross-table and we can take the dot product of user embeddings and movie embeddings.</p>
<p>Then we reshape the problem slightly by placing all of the embeddings in a matrix and doing a lookup. This is essentially what pytorch does, although it uses matrix multiplication by one-hot encoded vectors rather than array lookups for computational efficiency.</p>
<p>We then add a bias term to account for some users who love all movies, or hate all movies. And also movies that are universally beloved.</p>
</section>
<section id="input-data-and-factors" class="level2">
<h2 class="anchored" data-anchor-id="input-data-and-factors">3. Input Data and Factors</h2>
<p>The broad idea behind collaborative filtering is:</p>
<ul>
<li>If we could quantify the most salient “latent factors” about a movie, and…</li>
<li>Quantify how much a user cares about that factor, then…</li>
<li>If we multiplied the two (dot product) it would give a measure of their rating.</li>
</ul>
<p>But what are those latent factors? We let the model learn it. 1. We initialise randomised latent factors (called embeddings) 2. We use that to predict the user’s rating for each move. Initially, those randomised weights will give terrible predictions. 3. Our loss function is the MSE of the ground truth actual predictions and the prediction rating. 4. We can optimise the embedding values to minimise this loss function.</p>
<section id="loading-movielens-data" class="level3">
<h3 class="anchored" data-anchor-id="loading-movielens-data">3.1. Loading MovieLens data</h3>
<p>We use data on user ratings of movies sourced from <a href="https://grouplens.org/datasets/movielens/">MovieLens</a>. The <code>ml-latest-small</code> data set is downloaded and saved in the <code>DATA_DIR</code> folder.</p>
<div id="cell-4" class="cell" data-execution_count="68">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastai.collab <span class="im">import</span> CollabDataLoaders, Module, Embedding, collab_learner</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastai.tabular.<span class="bu">all</span> <span class="im">import</span> one_hot, sigmoid_range, MSELossFlat, Learner, get_emb_sz</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pyplot <span class="im">as</span> plt</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd </span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>DATA_DIR <span class="op">=</span> Path(<span class="st">"/Users/gurpreetjohl/workspace/python/ml-practice/ml-practice/datasets/ml-latest-small"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Load the <code>ratings</code> data which we will use for this task:</p>
<div id="cell-6" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>ratings <span class="op">=</span> pd.read_csv(DATA_DIR <span class="op">/</span> <span class="st">'ratings.csv'</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>ratings</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">userId</th>
<th data-quarto-table-cell-role="th">movieId</th>
<th data-quarto-table-cell-role="th">rating</th>
<th data-quarto-table-cell-role="th">timestamp</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1</td>
<td>1</td>
<td>4.0</td>
<td>964982703</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>1</td>
<td>3</td>
<td>4.0</td>
<td>964981247</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>1</td>
<td>6</td>
<td>4.0</td>
<td>964982224</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1</td>
<td>47</td>
<td>5.0</td>
<td>964983815</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>1</td>
<td>50</td>
<td>5.0</td>
<td>964982931</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">100831</td>
<td>610</td>
<td>166534</td>
<td>4.0</td>
<td>1493848402</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">100832</td>
<td>610</td>
<td>168248</td>
<td>5.0</td>
<td>1493850091</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">100833</td>
<td>610</td>
<td>168250</td>
<td>5.0</td>
<td>1494273047</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">100834</td>
<td>610</td>
<td>168252</td>
<td>5.0</td>
<td>1493846352</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">100835</td>
<td>610</td>
<td>170875</td>
<td>3.0</td>
<td>1493846415</td>
</tr>
</tbody>
</table>

<p>100836 rows × 4 columns</p>
</div>
</div>
</div>
<p>The users and movies are encoded as integers.</p>
<p>For reference, we can load the <code>movies</code> data to see what each <code>movieId</code> corresponds to:</p>
<div id="cell-8" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>movies <span class="op">=</span> pd.read_csv(DATA_DIR <span class="op">/</span> <span class="st">'movies.csv'</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>movies</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">movieId</th>
<th data-quarto-table-cell-role="th">title</th>
<th data-quarto-table-cell-role="th">genres</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1</td>
<td>Toy Story (1995)</td>
<td>Adventure|Animation|Children|Comedy|Fantasy</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>2</td>
<td>Jumanji (1995)</td>
<td>Adventure|Children|Fantasy</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>3</td>
<td>Grumpier Old Men (1995)</td>
<td>Comedy|Romance</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>4</td>
<td>Waiting to Exhale (1995)</td>
<td>Comedy|Drama|Romance</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>5</td>
<td>Father of the Bride Part II (1995)</td>
<td>Comedy</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">9737</td>
<td>193581</td>
<td>Black Butler: Book of the Atlantic (2017)</td>
<td>Action|Animation|Comedy|Fantasy</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">9738</td>
<td>193583</td>
<td>No Game No Life: Zero (2017)</td>
<td>Animation|Comedy|Fantasy</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">9739</td>
<td>193585</td>
<td>Flint (2017)</td>
<td>Drama</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">9740</td>
<td>193587</td>
<td>Bungo Stray Dogs: Dead Apple (2018)</td>
<td>Action|Animation</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">9741</td>
<td>193609</td>
<td>Andrew Dice Clay: Dice Rules (1991)</td>
<td>Comedy</td>
</tr>
</tbody>
</table>

<p>9742 rows × 3 columns</p>
</div>
</div>
</div>
<p>We’ll merge the two for easier human readability.</p>
<div id="cell-10" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>ratings <span class="op">=</span> ratings.merge(movies)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>ratings</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">userId</th>
<th data-quarto-table-cell-role="th">movieId</th>
<th data-quarto-table-cell-role="th">rating</th>
<th data-quarto-table-cell-role="th">timestamp</th>
<th data-quarto-table-cell-role="th">title</th>
<th data-quarto-table-cell-role="th">genres</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1</td>
<td>1</td>
<td>4.0</td>
<td>964982703</td>
<td>Toy Story (1995)</td>
<td>Adventure|Animation|Children|Comedy|Fantasy</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>1</td>
<td>3</td>
<td>4.0</td>
<td>964981247</td>
<td>Grumpier Old Men (1995)</td>
<td>Comedy|Romance</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>1</td>
<td>6</td>
<td>4.0</td>
<td>964982224</td>
<td>Heat (1995)</td>
<td>Action|Crime|Thriller</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1</td>
<td>47</td>
<td>5.0</td>
<td>964983815</td>
<td>Seven (a.k.a. Se7en) (1995)</td>
<td>Mystery|Thriller</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>1</td>
<td>50</td>
<td>5.0</td>
<td>964982931</td>
<td>Usual Suspects, The (1995)</td>
<td>Crime|Mystery|Thriller</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">100831</td>
<td>610</td>
<td>166534</td>
<td>4.0</td>
<td>1493848402</td>
<td>Split (2017)</td>
<td>Drama|Horror|Thriller</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">100832</td>
<td>610</td>
<td>168248</td>
<td>5.0</td>
<td>1493850091</td>
<td>John Wick: Chapter Two (2017)</td>
<td>Action|Crime|Thriller</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">100833</td>
<td>610</td>
<td>168250</td>
<td>5.0</td>
<td>1494273047</td>
<td>Get Out (2017)</td>
<td>Horror</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">100834</td>
<td>610</td>
<td>168252</td>
<td>5.0</td>
<td>1493846352</td>
<td>Logan (2017)</td>
<td>Action|Sci-Fi</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">100835</td>
<td>610</td>
<td>170875</td>
<td>3.0</td>
<td>1493846415</td>
<td>The Fate of the Furious (2017)</td>
<td>Action|Crime|Drama|Thriller</td>
</tr>
</tbody>
</table>

<p>100836 rows × 6 columns</p>
</div>
</div>
</div>
</section>
<section id="prepare-the-data" class="level3">
<h3 class="anchored" data-anchor-id="prepare-the-data">3.2 Prepare the Data</h3>
<div id="cell-12" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>dls <span class="op">=</span> CollabDataLoaders.from_df(ratings, item_name<span class="op">=</span><span class="st">'title'</span>, bs<span class="op">=</span><span class="dv">64</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>dls.show_batch()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">userId</th>
<th data-quarto-table-cell-role="th">title</th>
<th data-quarto-table-cell-role="th">rating</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>4</td>
<td>Mighty Aphrodite (1995)</td>
<td>3.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>573</td>
<td>Dark Knight, The (2008)</td>
<td>5.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>116</td>
<td>Amadeus (1984)</td>
<td>3.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>380</td>
<td>Addams Family, The (1991)</td>
<td>5.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>353</td>
<td>Brothers McMullen, The (1995)</td>
<td>4.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5</td>
<td>37</td>
<td>Fugitive, The (1993)</td>
<td>4.0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">6</td>
<td>356</td>
<td>Unbreakable (2000)</td>
<td>4.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">7</td>
<td>489</td>
<td>Alien³ (a.k.a. Alien 3) (1992)</td>
<td>3.5</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">8</td>
<td>174</td>
<td>Nell (1994)</td>
<td>5.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">9</td>
<td>287</td>
<td>Panic Room (2002)</td>
<td>2.5</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Initialise randomised 5-dimensional embeddings.</p>
<p>How should we choose the number of latent factors? (5 in the example above). Jeremy wrote down some ballpark values for models of different sizes in excel, then fit a function to it to get a heuristic measure. This is the default used by fast AI.</p>
<div id="cell-14" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>n_users  <span class="op">=</span> <span class="bu">len</span>(dls.classes[<span class="st">'userId'</span>])</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>n_movies <span class="op">=</span> <span class="bu">len</span>(dls.classes[<span class="st">'title'</span>])</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>n_factors <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>user_factors <span class="op">=</span> torch.randn(n_users, n_factors)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>movie_factors <span class="op">=</span> torch.randn(n_movies, n_factors)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Doing a matrix multiply by a one hot encoded vector is the same as doing a lookup in an array, just in a more computationally efficient way. Recall the softmax example.</p>
<p>An embedding is essentially just “look up in an array”.</p>
</section>
</section>
<section id="building-a-collaborative-filter-from-scratch" class="level2">
<h2 class="anchored" data-anchor-id="building-a-collaborative-filter-from-scratch">4. Building a Collaborative Filter From Scratch</h2>
<p>Putting a sigmoid_range on the final layer to squish ratings to fit 0 to 5 means “the model doesn’t have to work as hard” to get movies in the right range. In practice we use 5.5 as the sigmoid scale value as a sigmoid can never hit 1, but we want ratings to be able to hit 5.</p>
<div id="cell-17" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastai.collab <span class="im">import</span> CollabDataLoaders, Module, Embedding</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastai.tabular.<span class="bu">all</span> <span class="im">import</span> one_hot, sigmoid_range, MSELossFlat, Learner</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-18" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> DotProduct(Module):</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_users, n_movies, n_factors, y_range<span class="op">=</span>(<span class="dv">0</span>,<span class="fl">5.5</span>)):</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.user_factors <span class="op">=</span> Embedding(n_users, n_factors)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.movie_factors <span class="op">=</span> Embedding(n_movies, n_factors)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y_range <span class="op">=</span> y_range</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>        users <span class="op">=</span> <span class="va">self</span>.user_factors(x[:, <span class="dv">0</span>])</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>        movies <span class="op">=</span> <span class="va">self</span>.movie_factors(x[:, <span class="dv">1</span>])</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Apply a sigmoid to the raw_output</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>        raw_output <span class="op">=</span> (users <span class="op">*</span> movies).<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> sigmoid_range(raw_output, <span class="op">*</span><span class="va">self</span>.y_range)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can now fit a model</p>
<div id="cell-20" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>embedding_dim <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>num_epochs <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>max_learning_rate <span class="op">=</span> <span class="fl">5e-3</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> DotProduct(n_users, n_movies, embedding_dim)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> Learner(dls, model, loss_func<span class="op">=</span>MSELossFlat())</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>learn.fit_one_cycle(num_epochs, max_learning_rate)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="0" class="" max="5" style="width:300px; height:20px; vertical-align: middle;"></progress>
      
    </div>
    
</div>
</div>
<section id="adding-a-bias-term" class="level3">
<h3 class="anchored" data-anchor-id="adding-a-bias-term">4.2. Adding a bias term</h3>
<p>Adding a user bias term and a movie bias term to the prediction call helps account for the fact that some users always rate high (4 or 5) but other users always rate low. And similarly for movies if everyone always rates it a 5 or a 1.</p>
<div id="cell-22" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> DotProductBias(Module):</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_users, n_movies, n_factors, y_range<span class="op">=</span>(<span class="dv">0</span>,<span class="fl">5.5</span>)):</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.user_factors <span class="op">=</span> Embedding(n_users, n_factors)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.user_bias <span class="op">=</span> Embedding(n_users, <span class="dv">1</span>)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.movie_factors <span class="op">=</span> Embedding(n_movies, n_factors)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.movie_bias <span class="op">=</span> Embedding(n_movies, <span class="dv">1</span>)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y_range <span class="op">=</span> y_range</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>        users <span class="op">=</span> <span class="va">self</span>.user_factors(x[:,<span class="dv">0</span>])</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>        movies <span class="op">=</span> <span class="va">self</span>.movie_factors(x[:,<span class="dv">1</span>])</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>        raw_output <span class="op">=</span> (users <span class="op">*</span> movies).<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>        raw_output <span class="op">+=</span> <span class="va">self</span>.user_bias(x[:,<span class="dv">0</span>]) <span class="op">+</span> <span class="va">self</span>.movie_bias(x[:,<span class="dv">1</span>])</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> sigmoid_range(raw_output, <span class="op">*</span><span class="va">self</span>.y_range)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-23" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> DotProductBias(n_users, n_movies, embedding_dim)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> Learner(dls, model, loss_func<span class="op">=</span>MSELossFlat())</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>learn.fit_one_cycle(num_epochs, max_learning_rate)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="0" class="" max="5" style="width:300px; height:20px; vertical-align: middle;"></progress>
      0.00% [0/5 00:00&lt;?]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">train_loss</th>
<th data-quarto-table-cell-role="th">valid_loss</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
</tbody>
</table>
<p>

    </p><div>
      <progress value="0" class="" max="1260" style="width:300px; height:20px; vertical-align: middle;"></progress>
      0.00% [0/1260 00:00&lt;?]
    </div>
    
</div>
</div>
</section>
<section id="weight-decay" class="level3">
<h3 class="anchored" data-anchor-id="weight-decay">4.3. Weight Decay</h3>
<p>The validation loss in the previous model decreases then icnreases, which is a clear indication of overfitting.</p>
<p>We want to avoid overfitting, but data augmentation isn’t possible here. One approach is to use <strong>weight decay</strong> AKA L2 regularisation. We add sum of weights squared to the loss function.</p>
<p>How does this prevent overfitting? The larger the coefficients, the sharper the canyons the model is able to produce, which allows it to fit individual data points. By penalising larger weights, it will only produce sharp changes if this causes the model to fit many points well, so it should generalise better.</p>
<p>We essentially want to modify our loss function with an additional term dependent on the magnitude of the weights:</p>
<pre><code>loss_with_weight_decay = loss + weight_decay * (parameters**2).sum()</code></pre>
<p>In practice, these values would be large and numerically unstable. We only actually care about the <em>gradient</em> of the loss, so we can add the gradient of the additional term to the existing gradient.</p>
<pre><code>parameters.grad += weight_decay * 2 * parameters</code></pre>
<p>But <code>weight_decay</code> is just a constant that we choose, so we can fold the <code>2*</code> term into it.</p>
<div id="cell-25" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>weight_decay <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> DotProductBias(n_users, n_movies, embedding_dim)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> Learner(dls, model, loss_func<span class="op">=</span>MSELossFlat())</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>learn.fit_one_cycle(num_epochs, max_learning_rate, wd<span class="op">=</span>weight_decay)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="0" class="" max="5" style="width:300px; height:20px; vertical-align: middle;"></progress>
      0.00% [0/5 00:00&lt;?]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">train_loss</th>
<th data-quarto-table-cell-role="th">valid_loss</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
</tbody>
</table>
<p>

    </p><div>
      <progress value="2" class="" max="1260" style="width:300px; height:20px; vertical-align: middle;"></progress>
      0.16% [2/1260 00:00&lt;00:20 1.4480]
    </div>
    
</div>
</div>
</section>
<section id="creating-our-own-embedding-module" class="level3">
<h3 class="anchored" data-anchor-id="creating-our-own-embedding-module">4.3. Creating our own Embedding module</h3>
<p>In the previous section, we used that pytorch (technically the fastai version) Embedding module.</p>
<p>Let’s briefly take a look at this and create our own Embedding module from scratch.</p>
<section id="parameters" class="level4">
<h4 class="anchored" data-anchor-id="parameters">4.3.1. Parameters</h4>
<p>The way pytorch knows if a tensor is a parameter (and therefore can calculate gradients on it) is if it inherits from <code>nn.Parameter</code>. Then a Module’s <code>.parameters()</code> method will list this tensor.</p>
<p>As an example of this behaviour, let’s create a module with some parameters but WITHOUT declaring these as Parameters:</p>
<div id="cell-28" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MyModule(Module):</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>): </span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.a <span class="op">=</span> torch.ones(<span class="dv">3</span>)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>mm <span class="op">=</span> MyModule()</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="bu">list</span>(mm.parameters())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>[]</code></pre>
</div>
</div>
<p>We declared a tensor <code>a</code> in MyModule but we don’t see it! Which means it wouldn’t be trained by Pytorch.</p>
<p>Instead, let’s declare is as a Parameter:</p>
<div id="cell-30" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MyModuleWithParams(Module):</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>): </span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.a <span class="op">=</span> torch.nn.Parameter(torch.ones(<span class="dv">3</span>))</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>mm_params <span class="op">=</span> MyModuleWithParams()</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="bu">list</span>(mm_params.parameters())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>[Parameter containing:
 tensor([1., 1., 1.], requires_grad=True)]</code></pre>
</div>
</div>
<p>Pytorch’s builtin modules all use <code>Parameter</code> for any trainable parameters, so we haven’t needed to explicitly declare this.</p>
<p>As an example, if we use Pytorch’s <code>Linear</code> layer, it will automatically appear as a parameter:</p>
<div id="cell-32" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MyModuleWithLinear(Module):</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>): </span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.a <span class="op">=</span> torch.nn.Linear(<span class="dv">1</span>, <span class="dv">3</span>, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>mm_linear <span class="op">=</span> MyModuleWithLinear()</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="bu">list</span>(mm_linear.parameters())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>[Parameter containing:
 tensor([[-0.6689],
         [-0.0181],
         [ 0.8172]], requires_grad=True)]</code></pre>
</div>
</div>
<div id="cell-33" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="bu">type</span>(mm_linear.a.weight)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>torch.nn.parameter.Parameter</code></pre>
</div>
</div>
</section>
<section id="the-embedding-module" class="level4">
<h4 class="anchored" data-anchor-id="the-embedding-module">4.3.2. The <code>Embedding</code> module</h4>
<p>An <code>Embedding</code> object essentially instantiates a tensor of random weights of the given dimensions and declares this as a <code>Parameter</code>. Pytorch can then modify the weights when training.</p>
<div id="cell-35" class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_params(tensor_dims):</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Create a tensor of the required size and fill it with random values."""</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>    embedding_tensor <span class="op">=</span> torch.zeros(<span class="op">*</span>tensor_dims).normal_(<span class="dv">0</span>, <span class="fl">0.01</span>)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> torch.nn.Parameter(embedding_tensor)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now we can replace the import <code>Embedding</code> module with our custom implementation <code>create_params</code> in the <code>DotProductBias</code> module:</p>
<div id="cell-38" class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> DotProductBiasCustomEmbedding(Module):</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_users, n_movies, n_factors, y_range<span class="op">=</span>(<span class="dv">0</span>,<span class="fl">5.5</span>)):</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.user_factors <span class="op">=</span> create_params([n_users, n_factors])</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.user_bias <span class="op">=</span> create_params([n_users])</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.movie_factors <span class="op">=</span> create_params([n_movies, n_factors])</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.movie_bias <span class="op">=</span> create_params([n_movies])</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y_range <span class="op">=</span> y_range</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>        users <span class="op">=</span> <span class="va">self</span>.user_factors[x[:,<span class="dv">0</span>]]</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>        movies <span class="op">=</span> <span class="va">self</span>.movie_factors[x[:,<span class="dv">1</span>]]</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>        raw_output <span class="op">=</span> (users <span class="op">*</span> movies).<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>        raw_output <span class="op">+=</span> <span class="va">self</span>.user_bias[x[:,<span class="dv">0</span>]] <span class="op">+</span> <span class="va">self</span>.movie_bias[x[:,<span class="dv">1</span>]]</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> sigmoid_range(raw_output, <span class="op">*</span><span class="va">self</span>.y_range)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-39" class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> DotProductBiasCustomEmbedding(n_users, n_movies, embedding_dim)</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> Learner(dls, model, loss_func<span class="op">=</span>MSELossFlat())</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>learn.fit_one_cycle(num_epochs, max_learning_rate, wd<span class="op">=</span>weight_decay)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">
<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">train_loss</th>
<th data-quarto-table-cell-role="th">valid_loss</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>0.795456</td>
<td>0.787701</td>
<td>00:07</td>
</tr>
<tr class="even">
<td>1</td>
<td>0.693971</td>
<td>0.728376</td>
<td>00:06</td>
</tr>
<tr class="odd">
<td>2</td>
<td>0.546227</td>
<td>0.711909</td>
<td>00:07</td>
</tr>
<tr class="even">
<td>3</td>
<td>0.402994</td>
<td>0.707349</td>
<td>00:06</td>
</tr>
<tr class="odd">
<td>4</td>
<td>0.282765</td>
<td>0.708693</td>
<td>00:06</td>
</tr>
</tbody>
</table>
</div>
</div>
</section>
</section>
<section id="interpreting-embeddings-and-biases" class="level3">
<h3 class="anchored" data-anchor-id="interpreting-embeddings-and-biases">4.4. Interpreting Embeddings and Biases</h3>
<p>We can interrogate the model to learn more about these embeddings it has learned.</p>
<section id="biases" class="level4">
<h4 class="anchored" data-anchor-id="biases">4.4.1. Biases</h4>
<p>We can visualise the biases of our collaborative filter model to see:</p>
<ul>
<li><strong>Movie biases</strong>: Which movies are bad even compared to other similar movies of that type? Lawnmower man 2 is crap even compared to similar action movies. But people love titanic even if they don’t normally like romance dramas.</li>
<li><strong>User biases</strong>: Which users love any and all movies? Users who give a high rating to all movies.</li>
</ul>
<p>According to our biases, these movies are crap even for those who like that style of movie:</p>
<div id="cell-41" class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>movie_bias <span class="op">=</span> learn.model.movie_bias.squeeze()</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>idxs <span class="op">=</span> movie_bias.argsort()[:<span class="dv">5</span>]</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>[dls.classes[<span class="st">'title'</span>][i] <span class="cf">for</span> i <span class="kw">in</span> idxs]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="41">
<pre><code>['Karate Kid, Part III, The (1989)',
 'Catwoman (2004)',
 'Stuart Saves His Family (1995)',
 'Speed 2: Cruise Control (1997)',
 'Dungeons &amp; Dragons (2000)']</code></pre>
</div>
</div>
<p>Whereas these are highly rated, even when users don’t normally like that type of movie:</p>
<div id="cell-43" class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>idxs <span class="op">=</span> movie_bias.argsort()[<span class="op">-</span><span class="dv">5</span>:]</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>[dls.classes[<span class="st">'title'</span>][i] <span class="cf">for</span> i <span class="kw">in</span> idxs]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="42">
<pre><code>['Star Wars: Episode IV - A New Hope (1977)',
 'Dark Knight, The (2008)',
 'Green Mile, The (1999)',
 'Forrest Gump (1994)',
 'Shawshank Redemption, The (1994)']</code></pre>
</div>
</div>
</section>
<section id="weights" class="level4">
<h4 class="anchored" data-anchor-id="weights">4.4.2. Weights</h4>
<p>We can visualise the weights to see what human-interpretable features the model is learning.</p>
<p>We can condense our embedding to 2 axes with PCA. we get a <code>critically-acclaimed -&gt; popular</code> x-axis and a action-dialog y-axis.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>For more details on PCA and related methods, see <a href="https://github.com/fastai/numerical-linear-algebra">computational linear algebra fastai course</a></p>
</div>
</div>
<div id="cell-45" class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> ratings.groupby(<span class="st">'title'</span>)[<span class="st">'rating'</span>].count()</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>top_movies <span class="op">=</span> g.sort_values(ascending<span class="op">=</span><span class="va">False</span>).index.values[:<span class="dv">1000</span>]</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>top_idxs <span class="op">=</span> torch.tensor([learn.dls.classes[<span class="st">'title'</span>].o2i[m] <span class="cf">for</span> m <span class="kw">in</span> top_movies])</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>movie_w <span class="op">=</span> learn.model.movie_factors[top_idxs].cpu().detach()</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>movie_pca <span class="op">=</span> movie_w.pca(<span class="dv">3</span>)</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>fac0,fac1,fac2 <span class="op">=</span> movie_pca.t()</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>idxs <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">50</span>))</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> fac0[idxs]</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> fac2[idxs]</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>,<span class="dv">12</span>))</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>plt.scatter(X, Y)</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, x, y <span class="kw">in</span> <span class="bu">zip</span>(top_movies[idxs], X, Y):</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>    plt.text(x,y,i, color<span class="op">=</span>np.random.rand(<span class="dv">3</span>)<span class="op">*</span><span class="fl">0.7</span>, fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="lesson_files/figure-html/cell-23-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="embedding-distance" class="level4">
<h4 class="anchored" data-anchor-id="embedding-distance">4.4.3. Embedding Distance</h4>
<p>We can also use the “embedding distance” (distance in the latent space) to see when two movies are similar. We use cosine similarity to determine this distance, which is similar in principle to Euclidean distance but normalised.</p>
<p>In the example below, we start with the movie <em>Forrest Gump</em> and find the closest movie to it in our embedding:</p>
<div id="cell-47" class="cell" data-execution_count="66">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>movie_idx <span class="op">=</span> dls.classes[<span class="st">'title'</span>].o2i[<span class="st">'Forrest Gump (1994)'</span>]</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>movie_factors <span class="op">=</span> learn.model.movie_factors</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>distances <span class="op">=</span> torch.nn.CosineSimilarity(dim<span class="op">=</span><span class="dv">1</span>)(movie_factors, movie_factors[movie_idx][<span class="va">None</span>])</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>closest_distance_idx <span class="op">=</span> distances.argsort(descending<span class="op">=</span><span class="va">True</span>)[<span class="dv">1</span>]</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>dls.classes[<span class="st">'title'</span>][closest_distance_idx]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="66">
<pre><code>'Beautiful Mind, A (2001)'</code></pre>
</div>
</div>
</section>
</section>
</section>
<section id="building-a-collaborative-filter-with-fastais-library" class="level2">
<h2 class="anchored" data-anchor-id="building-a-collaborative-filter-with-fastais-library">5. Building a Collaborative Filter with Fastai’s Library</h2>
<p>We can repeat the same exercise using the collaborative filter from the fastai library to see how it compares to our from-scratch implementation.</p>
<div id="cell-49" class="cell" data-execution_count="69">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>learn_fast <span class="op">=</span> collab_learner(dls, n_factors<span class="op">=</span>embedding_dim, y_range<span class="op">=</span>(<span class="dv">0</span>, <span class="fl">5.5</span>))</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>learn_fast.fit_one_cycle(num_epochs, max_learning_rate, wd<span class="op">=</span>weight_decay)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="0" class="" max="5" style="width:300px; height:20px; vertical-align: middle;"></progress>
      0.00% [0/5 00:00&lt;?]
    </div>
    

<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">train_loss</th>
<th data-quarto-table-cell-role="th">valid_loss</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
</tbody>
</table>
<p>

    </p><div>
      <progress value="5" class="" max="1260" style="width:300px; height:20px; vertical-align: middle;"></progress>
      0.40% [5/1260 00:00&lt;00:20 1.5528]
    </div>
    
</div>
</div>
<p>We can repeat any of the analysis of our from-scratch model. For example, the movies with the highest bias:</p>
<div id="cell-51" class="cell" data-execution_count="70">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>movie_bias <span class="op">=</span> learn_fast.model.i_bias.weight.squeeze()</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>idxs <span class="op">=</span> movie_bias.argsort(descending<span class="op">=</span><span class="va">True</span>)[:<span class="dv">5</span>]</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>[dls.classes[<span class="st">'title'</span>][i] <span class="cf">for</span> i <span class="kw">in</span> idxs]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="70">
<pre><code>['Shawshank Redemption, The (1994)',
 'Forrest Gump (1994)',
 'Green Mile, The (1999)',
 'Star Wars: Episode IV - A New Hope (1977)',
 'Dark Knight, The (2008)']</code></pre>
</div>
</div>
</section>
<section id="bootstrapping-a-collaborative-filtering-model" class="level2">
<h2 class="anchored" data-anchor-id="bootstrapping-a-collaborative-filtering-model">6. Bootstrapping a Collaborative Filtering Model</h2>
<p>How do you start off a collaborative filtering model? For example, when you first start out, you have no data on users or items.</p>
<p>Or even for established companies, what happens when we have a new user or a new item, so the entire row or column is null?</p>
<p>There is no hard and fast solution, they all boil down to “use common sense”.</p>
<ul>
<li>A tempting option is to fill NaNs with the <em>median latent vectors</em>. But this might result in an odd combination that doesn’t exist in practice, i.e.&nbsp;the latent space isn’t continuous so this could be where a gap in the latent space lies. For example, a medium action, medium sci-fi film with medium romance and medium comedy that is medium popular and medium critically acclaimed.</li>
<li>Another option is to pick a user/item that is representative of the <em>average</em> taste.</li>
<li>Create a <em>tabular model</em> using answers to a new user survey. Ask the user some questions when they sign up, then create a model where the user’s embedding vector is the dependent variable and their answers, along with any other relevant signup metadata, are the independent variables.</li>
</ul>
<p>It is important to be careful of a small number of extremely enthusiastic users dominating the recommendations. For example, people who watch anime watch a LOT of it, and rate a lot of it highly. So this could end up getting recommended to users outside of this niche.</p>
<p>This can create positive feedback loops that change the behaviour of your product in unexpected ways.</p>
</section>
<section id="deep-learning-for-collaborative-filtering" class="level2">
<h2 class="anchored" data-anchor-id="deep-learning-for-collaborative-filtering">7. Deep Learning for Collaborative Filtering</h2>
<p>The matrix completion approach used previously is known as <strong>Probabilistic Matrix Factorization (PMF)</strong>. An alternative approach is to use <strong>deep learning</strong>.</p>
<p>In practice the two approaches are often stacked in an ensemble.</p>
<p>This section explores the deep learning collaborative filtering approach from scratch, then recreates it using fastai’s library.</p>
<section id="building-a-deep-learning-collaborative-filter-from-scratch" class="level3">
<h3 class="anchored" data-anchor-id="building-a-deep-learning-collaborative-filter-from-scratch">7.1. Building a Deep Learning Collaborative Filter From Scratch</h3>
<p>We are concatenating the embedding matrices together, rather than taking the dot product, so that we can pass it through a dense ANN.</p>
<p>These matrices can be different sizes, and the size of embedding to use for each depends on the number of classes in the data. Fastai has a heuristic method for this which we use here:</p>
<div id="cell-54" class="cell" data-execution_count="77">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>(user_num_classes, user_num_embeddings), (item_num_classes, item_num_embeddings) <span class="op">=</span> get_emb_sz(dls)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can then use this in a simple neural network with one hidden layer:</p>
<div id="cell-56" class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> CollabNN(Module):</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, user_embedding_size, item_embedding_size, y_range<span class="op">=</span>(<span class="dv">0</span>, <span class="fl">5.5</span>), n_activations<span class="op">=</span><span class="dv">100</span>):</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.user_factors <span class="op">=</span> Embedding(<span class="op">*</span>user_embedding_size)</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.item_factors <span class="op">=</span> Embedding(<span class="op">*</span>item_embedding_size)</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layers <span class="op">=</span> torch.nn.Sequential(</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>            torch.nn.Linear(user_embedding_size[<span class="dv">1</span>] <span class="op">+</span> item_embedding_size[<span class="dv">1</span>], n_activations),</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>            torch.nn.ReLU(),</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>            torch.nn.Linear(n_activations, <span class="dv">1</span>))</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.y_range <span class="op">=</span> y_range</span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a>        embs <span class="op">=</span> <span class="va">self</span>.user_factors(x[:, <span class="dv">0</span>]), <span class="va">self</span>.item_factors(x[:, <span class="dv">1</span>])</span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.layers(torch.cat(embs, dim<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> sigmoid_range(x, <span class="op">*</span><span class="va">self</span>.y_range)</span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a>collab_nn_model <span class="op">=</span> CollabNN(user_embedding_size<span class="op">=</span>(user_num_classes, user_num_embeddings),</span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a>                           item_embedding_size<span class="op">=</span>(item_num_classes, item_num_embeddings))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now train this model on the data:</p>
<div id="cell-58" class="cell" data-execution_count="95">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>learn_nn <span class="op">=</span> Learner(dls, collab_nn_model, loss_func<span class="op">=</span>MSELossFlat())</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>learn_nn.fit_one_cycle(num_epochs, max_learning_rate, wd<span class="op">=</span>weight_decay)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">
<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">train_loss</th>
<th data-quarto-table-cell-role="th">valid_loss</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>0.799004</td>
<td>0.792579</td>
<td>00:10</td>
</tr>
<tr class="even">
<td>1</td>
<td>0.747623</td>
<td>0.755708</td>
<td>00:10</td>
</tr>
<tr class="odd">
<td>2</td>
<td>0.706981</td>
<td>0.723887</td>
<td>00:10</td>
</tr>
<tr class="even">
<td>3</td>
<td>0.650337</td>
<td>0.719642</td>
<td>00:10</td>
</tr>
<tr class="odd">
<td>4</td>
<td>0.569418</td>
<td>0.734302</td>
<td>00:10</td>
</tr>
</tbody>
</table>
</div>
</div>
</section>
<section id="building-a-deep-learning-collaborative-filter-with-fastais-library" class="level3">
<h3 class="anchored" data-anchor-id="building-a-deep-learning-collaborative-filter-with-fastais-library">7.2. Building a Deep Learning Collaborative Filter with Fastai’s Library</h3>
<p>We can repeat the same exercise using fastai’s implementation.</p>
<p>This is almost identical to the PMF approach, simply with an additional argument <code>use_nn=True</code>.</p>
<div id="cell-60" class="cell" data-execution_count="96">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>learn_nn_fast <span class="op">=</span> collab_learner(dls, use_nn<span class="op">=</span><span class="va">True</span>, y_range<span class="op">=</span>(<span class="dv">0</span>, <span class="fl">5.5</span>), layers<span class="op">=</span>[<span class="dv">100</span>, <span class="dv">50</span>])</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>learn_nn_fast.fit_one_cycle(num_epochs, max_learning_rate, wd<span class="op">=</span>weight_decay)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">
<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">train_loss</th>
<th data-quarto-table-cell-role="th">valid_loss</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>0.838047</td>
<td>0.801519</td>
<td>00:14</td>
</tr>
<tr class="even">
<td>1</td>
<td>0.761085</td>
<td>0.744033</td>
<td>00:12</td>
</tr>
<tr class="odd">
<td>2</td>
<td>0.709788</td>
<td>0.734091</td>
<td>00:13</td>
</tr>
<tr class="even">
<td>3</td>
<td>0.653415</td>
<td>0.728950</td>
<td>00:13</td>
</tr>
<tr class="odd">
<td>4</td>
<td>0.545074</td>
<td>0.743957</td>
<td>00:12</td>
</tr>
</tbody>
</table>
</div>
</div>
</section>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">8. Summary</h2>
<p>The recommender problem is one where we have some users and their ratings of some items. We want to know which unseen items a user may like.</p>
<p>We implemented two approaches to collaborative filtering:</p>
<ol type="1">
<li>Probabilistic Matrix Factorization (PMF)</li>
<li>A neural network</li>
</ol>
<p>For each approach, we build a model from scratch in Pytorch, then compared that with fastai’s implementation. For the PMF approach, we even gained some intuition by creating a spreadsheet implementation first!</p>
<p>In practice, both approaches can be stacked for improved recommendations.</p>
<p>The idea we explored here of user some (initially random) <strong>embeddings</strong> to represent an entity and then letting our model learn them is a powerful one and it is not limited to collaborative learning. NLP uses embeddings to represent each unique token (i.e.&nbsp;each word with word-level tokenisation). It can then understand relationships between similar words, much like we were able to use embedding distances to identify similar movies.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li><a href="https://course.fast.ai/Lessons/lesson7.html">Course lesson page</a></li>
<li><a href="https://www.kaggle.com/code/jhoward/collaborative-filtering-deep-dive/notebook">Collaborative filtering notebook</a></li>
<li><a href="https://github.com/fastai/numerical-linear-algebra">Computational linear algebra fastai course</a></li>
</ul>


</section>
</section>

<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>