<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Gurpreet Johl">
<meta name="dcterms.date" content="2025-08-05">
<meta name="description" content="Fun with Latex ;)">

<title>Gurpreet Johl - Mathematical Statistics</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="../../../site_libs/quarto-diagram/mermaid.min.js"></script>
<script src="../../../site_libs/quarto-diagram/mermaid-init.js"></script>
<link href="../../../site_libs/quarto-diagram/mermaid.css" rel="stylesheet">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Gurpreet Johl</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../projects.html"> 
<span class="menu-text">Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../blog.html"> 
<span class="menu-text">Notes</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/gjohl"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/gurpreetjohl"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/gurpreetjohl"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Mathematical Statistics</h1>
                  <div>
        <div class="description">
          Fun with Latex ;)
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">Maths</div>
                <div class="quarto-category">Statistics</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Gurpreet Johl </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">August 5, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#probability-distribution" id="toc-probability-distribution" class="nav-link active" data-scroll-target="#probability-distribution">1. Probability Distribution</a></li>
  <li><a href="#distributions" id="toc-distributions" class="nav-link" data-scroll-target="#distributions">2. Distributions</a>
  <ul class="collapse">
  <li><a href="#bernoulli-distribution" id="toc-bernoulli-distribution" class="nav-link" data-scroll-target="#bernoulli-distribution">2.1. Bernoulli Distribution</a></li>
  <li><a href="#uniform-distribution" id="toc-uniform-distribution" class="nav-link" data-scroll-target="#uniform-distribution">2.2. Uniform Distribution</a></li>
  <li><a href="#normal-distribution" id="toc-normal-distribution" class="nav-link" data-scroll-target="#normal-distribution">2.3. Normal Distribution</a></li>
  </ul></li>
  <li><a href="#expected-value" id="toc-expected-value" class="nav-link" data-scroll-target="#expected-value">3. Expected Value</a>
  <ul class="collapse">
  <li><a href="#expected-value-of-a-bernoulli-random-variable" id="toc-expected-value-of-a-bernoulli-random-variable" class="nav-link" data-scroll-target="#expected-value-of-a-bernoulli-random-variable">3.1. Expected Value of a Bernoulli Random Variable</a></li>
  <li><a href="#expected-value-of-a-uniform-random-variable" id="toc-expected-value-of-a-uniform-random-variable" class="nav-link" data-scroll-target="#expected-value-of-a-uniform-random-variable">3.2. Expected Value of a Uniform Random Variable</a></li>
  <li><a href="#expected-value-for-a-normal-random-variable" id="toc-expected-value-for-a-normal-random-variable" class="nav-link" data-scroll-target="#expected-value-for-a-normal-random-variable">3.3. Expected Value for a Normal Random Variable</a></li>
  </ul></li>
  <li><a href="#estimators-and-method-of-moments" id="toc-estimators-and-method-of-moments" class="nav-link" data-scroll-target="#estimators-and-method-of-moments">4. Estimators and Method of Moments</a>
  <ul class="collapse">
  <li><a href="#method-of-moments-estimator-for-a-bernoulli-distribution" id="toc-method-of-moments-estimator-for-a-bernoulli-distribution" class="nav-link" data-scroll-target="#method-of-moments-estimator-for-a-bernoulli-distribution">4.1. Method of Moments Estimator for a Bernoulli Distribution</a></li>
  <li><a href="#method-of-moments-estimator-for-a-uniform-distribution" id="toc-method-of-moments-estimator-for-a-uniform-distribution" class="nav-link" data-scroll-target="#method-of-moments-estimator-for-a-uniform-distribution">4.2. Method of Moments Estimator for a Uniform Distribution</a></li>
  <li><a href="#method-of-moments-estimator-for-a-normal-distribution" id="toc-method-of-moments-estimator-for-a-normal-distribution" class="nav-link" data-scroll-target="#method-of-moments-estimator-for-a-normal-distribution">4.3 Method of Moments Estimator for a Normal Distribution</a></li>
  </ul></li>
  <li><a href="#unbiased-estimators" id="toc-unbiased-estimators" class="nav-link" data-scroll-target="#unbiased-estimators">5. Unbiased Estimators</a>
  <ul class="collapse">
  <li><a href="#background-on-estimators" id="toc-background-on-estimators" class="nav-link" data-scroll-target="#background-on-estimators">5.0. Background on Estimators</a>
  <ul class="collapse">
  <li><a href="#distribution-of-estimators" id="toc-distribution-of-estimators" class="nav-link" data-scroll-target="#distribution-of-estimators">5.0.1. Distribution of Estimators</a></li>
  </ul></li>
  <li><a href="#properties-of-expected-value" id="toc-properties-of-expected-value" class="nav-link" data-scroll-target="#properties-of-expected-value">5.0.2. Properties of Expected Value</a></li>
  <li><a href="#the-bias-of-a-mom-estimator-for-a-bernoulli-distribution" id="toc-the-bias-of-a-mom-estimator-for-a-bernoulli-distribution" class="nav-link" data-scroll-target="#the-bias-of-a-mom-estimator-for-a-bernoulli-distribution">5.1. The Bias of a MoM Estimator for a Bernoulli Distribution</a></li>
  <li><a href="#the-bias-of-a-mom-estimator-for-a-uniform-distribution" id="toc-the-bias-of-a-mom-estimator-for-a-uniform-distribution" class="nav-link" data-scroll-target="#the-bias-of-a-mom-estimator-for-a-uniform-distribution">5.2. The Bias of a MoM Estimator for a Uniform Distribution</a></li>
  <li><a href="#the-bias-of-a-mom-estimator-for-a-normal-distribution" id="toc-the-bias-of-a-mom-estimator-for-a-normal-distribution" class="nav-link" data-scroll-target="#the-bias-of-a-mom-estimator-for-a-normal-distribution">5.3. The Bias of a MoM Estimator for a Normal Distribution</a></li>
  </ul></li>
  <li><a href="#variance-of-distributions" id="toc-variance-of-distributions" class="nav-link" data-scroll-target="#variance-of-distributions">6. Variance of Distributions</a>
  <ul class="collapse">
  <li><a href="#variance-of-a-bernoulli-distribution" id="toc-variance-of-a-bernoulli-distribution" class="nav-link" data-scroll-target="#variance-of-a-bernoulli-distribution">6.1. Variance of a Bernoulli Distribution</a></li>
  <li><a href="#variance-of-a-uniform-distribution" id="toc-variance-of-a-uniform-distribution" class="nav-link" data-scroll-target="#variance-of-a-uniform-distribution">6.2. Variance of a Uniform Distribution</a></li>
  <li><a href="#variance-of-a-normal-distribution" id="toc-variance-of-a-normal-distribution" class="nav-link" data-scroll-target="#variance-of-a-normal-distribution">6.3. Variance of a Normal Distribution</a></li>
  </ul></li>
  <li><a href="#variance-of-estimators" id="toc-variance-of-estimators" class="nav-link" data-scroll-target="#variance-of-estimators">7. Variance of Estimators</a>
  <ul class="collapse">
  <li><a href="#background-on-variance" id="toc-background-on-variance" class="nav-link" data-scroll-target="#background-on-variance">7.0. Background on Variance</a>
  <ul class="collapse">
  <li><a href="#why-the-variance-of-an-estimator-matters" id="toc-why-the-variance-of-an-estimator-matters" class="nav-link" data-scroll-target="#why-the-variance-of-an-estimator-matters">7.0.1. Why the Variance of an Estimator Matters</a></li>
  <li><a href="#properties-of-variance" id="toc-properties-of-variance" class="nav-link" data-scroll-target="#properties-of-variance">7.0.2. Properties of Variance</a></li>
  </ul></li>
  <li><a href="#variance-of-the-mom-estimator-of-a-bernoulli-distribution" id="toc-variance-of-the-mom-estimator-of-a-bernoulli-distribution" class="nav-link" data-scroll-target="#variance-of-the-mom-estimator-of-a-bernoulli-distribution">7.1. Variance of the MoM Estimator of a Bernoulli Distribution</a></li>
  <li><a href="#variance-of-the-mom-estimator-of-a-uniform-distribution" id="toc-variance-of-the-mom-estimator-of-a-uniform-distribution" class="nav-link" data-scroll-target="#variance-of-the-mom-estimator-of-a-uniform-distribution">7.2. Variance of the MoM Estimator of a Uniform Distribution</a></li>
  <li><a href="#variance-of-the-mom-estimator-of-a-normal-distribution" id="toc-variance-of-the-mom-estimator-of-a-normal-distribution" class="nav-link" data-scroll-target="#variance-of-the-mom-estimator-of-a-normal-distribution">7.3. Variance of the MoM Estimator of a Normal Distribution</a></li>
  </ul></li>
  <li><a href="#maximum-likelihood-estimation" id="toc-maximum-likelihood-estimation" class="nav-link" data-scroll-target="#maximum-likelihood-estimation">8. Maximum Likelihood Estimation</a>
  <ul class="collapse">
  <li><a href="#background-on-mle" id="toc-background-on-mle" class="nav-link" data-scroll-target="#background-on-mle">8.0. Background on MLE</a>
  <ul class="collapse">
  <li><a href="#intuition" id="toc-intuition" class="nav-link" data-scroll-target="#intuition">8.0.1 Intuition</a></li>
  <li><a href="#joint-pdf" id="toc-joint-pdf" class="nav-link" data-scroll-target="#joint-pdf">8.0.2 Joint PDF</a></li>
  <li><a href="#finding-the-mle" id="toc-finding-the-mle" class="nav-link" data-scroll-target="#finding-the-mle">8.0.3. Finding the MLE</a></li>
  </ul></li>
  <li><a href="#properties-of-logarithms" id="toc-properties-of-logarithms" class="nav-link" data-scroll-target="#properties-of-logarithms">8.0.4 Properties of Logarithms</a>
  <ul class="collapse">
  <li><a href="#mean-squared-error" id="toc-mean-squared-error" class="nav-link" data-scroll-target="#mean-squared-error">8.0.5. Mean Squared Error</a></li>
  </ul></li>
  <li><a href="#mle-estimator-for-a-bernoulli-distribution" id="toc-mle-estimator-for-a-bernoulli-distribution" class="nav-link" data-scroll-target="#mle-estimator-for-a-bernoulli-distribution">8.1. MLE Estimator for a Bernoulli Distribution</a></li>
  <li><a href="#mle-estimator-for-a-uniform-distribution" id="toc-mle-estimator-for-a-uniform-distribution" class="nav-link" data-scroll-target="#mle-estimator-for-a-uniform-distribution">8.2. MLE Estimator for a Uniform Distribution</a></li>
  <li><a href="#mle-estimator-for-a-normal-distribution" id="toc-mle-estimator-for-a-normal-distribution" class="nav-link" data-scroll-target="#mle-estimator-for-a-normal-distribution">8.3. MLE Estimator for a Normal Distribution</a></li>
  </ul></li>
  <li><a href="#fisher-information-and-cramer-rao-lower-bound-crlb" id="toc-fisher-information-and-cramer-rao-lower-bound-crlb" class="nav-link" data-scroll-target="#fisher-information-and-cramer-rao-lower-bound-crlb">9. Fisher Information and Cramer Rao Lower Bound (CRLB)</a>
  <ul class="collapse">
  <li><a href="#crlb-for-a-bernoulli-distribution" id="toc-crlb-for-a-bernoulli-distribution" class="nav-link" data-scroll-target="#crlb-for-a-bernoulli-distribution">9.1. CRLB for a Bernoulli Distribution</a></li>
  <li><a href="#crlb-for-a-uniform-distribution" id="toc-crlb-for-a-uniform-distribution" class="nav-link" data-scroll-target="#crlb-for-a-uniform-distribution">9.2. CRLB for a Uniform Distribution</a></li>
  <li><a href="#crlb-for-a-normal-distribution" id="toc-crlb-for-a-normal-distribution" class="nav-link" data-scroll-target="#crlb-for-a-normal-distribution">9.3. CRLB for a Normal Distribution</a></li>
  <li><a href="#efficiency" id="toc-efficiency" class="nav-link" data-scroll-target="#efficiency">9.4. Efficiency</a></li>
  </ul></li>
  <li><a href="#central-limit-theorem" id="toc-central-limit-theorem" class="nav-link" data-scroll-target="#central-limit-theorem">10. Central Limit Theorem</a>
  <ul class="collapse">
  <li><a href="#clt-for-a-bernoulli-distribution" id="toc-clt-for-a-bernoulli-distribution" class="nav-link" data-scroll-target="#clt-for-a-bernoulli-distribution">10.1. CLT for a Bernoulli Distribution</a></li>
  <li><a href="#clt-for-a-uniform-distribution" id="toc-clt-for-a-uniform-distribution" class="nav-link" data-scroll-target="#clt-for-a-uniform-distribution">10.2. CLT for a Uniform Distribution</a></li>
  <li><a href="#clt-for-a-normal-distribution" id="toc-clt-for-a-normal-distribution" class="nav-link" data-scroll-target="#clt-for-a-normal-distribution">10.3. CLT for a Normal Distribution</a></li>
  <li><a href="#consistency" id="toc-consistency" class="nav-link" data-scroll-target="#consistency">10.4. Consistency</a></li>
  </ul></li>
  <li><a href="#confidence-intervals" id="toc-confidence-intervals" class="nav-link" data-scroll-target="#confidence-intervals">11. Confidence Intervals</a>
  <ul class="collapse">
  <li><a href="#background" id="toc-background" class="nav-link" data-scroll-target="#background">11.0. Background</a>
  <ul class="collapse">
  <li><a href="#the-pivot-from-probability-to-statistics" id="toc-the-pivot-from-probability-to-statistics" class="nav-link" data-scroll-target="#the-pivot-from-probability-to-statistics">11.0.1 The Pivot from Probability to Statistics</a></li>
  <li><a href="#some-useful-terms" id="toc-some-useful-terms" class="nav-link" data-scroll-target="#some-useful-terms">11.0.2. Some Useful Terms</a></li>
  </ul></li>
  <li><a href="#bernoulli-confidence-intervals" id="toc-bernoulli-confidence-intervals" class="nav-link" data-scroll-target="#bernoulli-confidence-intervals">11.1 Bernoulli Confidence Intervals</a></li>
  <li><a href="#uniform-distribution-confidence-intervals" id="toc-uniform-distribution-confidence-intervals" class="nav-link" data-scroll-target="#uniform-distribution-confidence-intervals">11.2. Uniform Distribution Confidence Intervals</a></li>
  <li><a href="#normal-distribution-confidence-intervals" id="toc-normal-distribution-confidence-intervals" class="nav-link" data-scroll-target="#normal-distribution-confidence-intervals">11.3. Normal Distribution Confidence Intervals</a></li>
  </ul></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="probability-distribution" class="level1">
<h1>1. Probability Distribution</h1>
<p>A <strong>random variable</strong> is a quantity that is random. It has a probability distribution.</p>
<p>E.g. <code>X = roll of a dice</code></p>
<p>The <strong>sample space</strong> is the set of all possible outcomes of a random variable. This is also called the <strong>support</strong> of a function.</p>
<p><span class="math display">\[
S = {1,2,3,4,5,6}
\]</span></p>
<p>Different values occur with different probabilities. We can describe this with a <strong>probability distribution</strong>.</p>
<pre><code>P(X=1) = 1/6
P(X=2) = 1/6
P(X=3) = 1/6
…</code></pre>
<p>A common way to describe this is with a function as above. We give an input (e.g.&nbsp;<span class="math inline">\(X=1\)</span>) and get an output (<span class="math inline">\(\frac{1}{6}\)</span>). This is a <strong>probability mass function</strong>. We can represent this graphically.</p>
<p>In this case, a dice roll is a discrete random variable.</p>
<p>With a continuous random variable, we have a continuous distribution. The probability of any specific value is infinitesimally small, so we consider ranges and call the distribution the <strong>probability density function</strong>.</p>
<p>A <strong>parameter</strong> is a number that controls the properties of a probability distribution.</p>
</section>
<section id="distributions" class="level1">
<h1>2. Distributions</h1>
<p>A distribution is the list of possible values a random variable can take. We will look at three important distributions: Bernoulli, Uniform and Normal.</p>
<section id="bernoulli-distribution" class="level2">
<h2 class="anchored" data-anchor-id="bernoulli-distribution">2.1. Bernoulli Distribution</h2>
<p>A Bernoulli distribution describes an experiment that has two possible outcomes, i.e.&nbsp;success/failure, heads/tails, etc.</p>
<p><span class="math display">\[
X \sim \text{Bernoulli}(p)
\]</span></p>
<p>The probability of the successful and unsuccessful outcomes are: <span class="math display">\[
P(X=1) = p
\]</span> <span class="math display">\[
P(X=0) = 1-p
\]</span></p>
<p>The sample space is: <span class="math display">\[
P \in [0,1]
\]</span></p>
<p>The sample space is also known as the <strong>support</strong>.</p>
<p>We can alternatively write this as a probability mass function (PMF):</p>
<p><span class="math display">\[
f(x) =
\begin{cases}
p &amp; x = 1 \\[6pt]
1-p &amp; x = 0 \\[6pt]
0 &amp; \text{otherwise}
\end{cases}
\]</span></p>
<p>A way of rewriting this is: <span class="math display">\[
f(x) = p^{x} (1-p)^{\,1-x}
\]</span></p>
</section>
<section id="uniform-distribution" class="level2">
<h2 class="anchored" data-anchor-id="uniform-distribution">2.2. Uniform Distribution</h2>
<p>This is a continuous distribution where every value between and min and a max value is equally likely.</p>
<p><span class="math display">\[
X \sim \text{Uniform}(a,b)
\]</span></p>
<p>As this is a continuous distribution, the <em>mass</em> of any point is infinitesimally small, so we have a probability density function (PDF) rather than a probability mass function (PMF).</p>
<p><span class="math display">\[
f(x) =
\begin{cases}
\dfrac{1}{b-a} &amp; a \leq x \leq b \\[6pt]
0 &amp; \text{otherwise}
\end{cases}
\]</span></p>
<p>The sample space is: <span class="math display">\[
S = (a, b)
\]</span></p>
</section>
<section id="normal-distribution" class="level2">
<h2 class="anchored" data-anchor-id="normal-distribution">2.3. Normal Distribution</h2>
<p>Centred on the mean <span class="math inline">\(\mu\)</span>. The spread is defined the standard deviation <span class="math inline">\(\sigma\)</span>.</p>
<p><span class="math display">\[
X \sim \mathcal{N}(\mu, \sigma^{2})
\]</span></p>
<p>It is defined by these two parameters.</p>
<p><span class="math display">\[
f(x) = \frac{1}{\sqrt{2\pi\sigma^{2}}} \exp\!\left( -\frac{(x-\mu)^{2}}{2\sigma^{2}} \right),
\quad -\infty &lt; x &lt; \infty
\]</span></p>
</section>
</section>
<section id="expected-value" class="level1">
<h1>3. Expected Value</h1>
<p>For a sample, we have a sample mean depending on our observations. It changes each time we observe more data. <span class="math display">\[
\bar{x} = \frac{\sum_{i=1}^{n} x_i}{n}
\]</span></p>
<p>The aim is to collect enough data that this is a reasonable approximation of the true population mean.</p>
<p>For a population, we have the expected value: <span class="math display">\[
\begin{aligned}
E[X] &amp;= \mu \\[6pt]
     &amp;= \sum_{x \in S} x \, P(X = x)
\end{aligned}
\]</span></p>
<p>Or for a continuous distribution: <span class="math display">\[
E[X] = \int_{x \in S} x f(x) \, dx
\]</span></p>
<section id="expected-value-of-a-bernoulli-random-variable" class="level2">
<h2 class="anchored" data-anchor-id="expected-value-of-a-bernoulli-random-variable">3.1. Expected Value of a Bernoulli Random Variable</h2>
<p>Recall the PMF: <span class="math display">\[
f(x) =
\begin{cases}
p &amp; x = 1 \\[6pt]
1-p &amp; x = 0 \\[6pt]
0 &amp; \text{otherwise}
\end{cases}
\]</span></p>
<p>And the definition of expectation: <span class="math display">\[
E[X] = \mu = \sum_{x \in S} xP(X=x)
\]</span></p>
<p>Substituting the first into the second equation, we get: <span class="math display">\[
E[X] = 0 \cdot (1-p) + 1 \cdot p = p
\]</span></p>
</section>
<section id="expected-value-of-a-uniform-random-variable" class="level2">
<h2 class="anchored" data-anchor-id="expected-value-of-a-uniform-random-variable">3.2. Expected Value of a Uniform Random Variable</h2>
<p>This is continuous, so we integrate the PDF:</p>
<p>Expected value for a continuous distribution <span class="math display">\[
\begin{aligned}
E[X] &amp;= \int_{x \in S} x f(x) \, dx \\[6pt]
     &amp;= \int_{0}^{\theta} x \cdot \frac{1}{\theta} \, dx \\[6pt]
     &amp;= \frac{1}{\theta} \left[ \frac{x^{2}}{2} \right]_{0}^{\theta} \\[6pt]
     &amp;= \frac{1}{\theta} \cdot \frac{\theta^{2}}{2} \\[6pt]
     &amp;= \frac{\theta}{2}.
\end{aligned}
\]</span></p>
</section>
<section id="expected-value-for-a-normal-random-variable" class="level2">
<h2 class="anchored" data-anchor-id="expected-value-for-a-normal-random-variable">3.3. Expected Value for a Normal Random Variable</h2>
<p>Again, this is a continuous distribution, so we can integrate the PDF. See <a href="https://statproofbook.github.io/P/norm-mean.html">here for the integral</a>.</p>
<p>Intuitively, we know that a Normal distribution is symmetric and defined by <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>. So the expected value is <span class="math inline">\(\mu\)</span>.</p>
</section>
</section>
<section id="estimators-and-method-of-moments" class="level1">
<h1>4. Estimators and Method of Moments</h1>
<p>The goal in a lot of statistics is to learn (estimate) some unknown parameters.</p>
<p>Some terminology:</p>
<ul>
<li><strong>Estimand</strong> - the parameter we want to estimate. E.g. <span class="math inline">\(p\)</span>, <span class="math inline">\(\mu\)</span>, <span class="math inline">\(\theta\)</span></li>
<li><strong>Estimate</strong> - a concrete value of our estimand based on the data. E.g. 0.4, 3, 12</li>
<li><strong>Estimator</strong> - how do we get a good estimate for a particular distribution.</li>
</ul>
<p>We want a method that allows us to create a good estimate. A formula/algorithm that allows us to estimate an estimand is an estimator. It takes data as inputs and outputs an estimate of a parameter.</p>
<p>The <strong>method of moments</strong> is one such estimator method. It relies on the 1st moment: the expected value.</p>
<p>We begin with two facts:</p>
<ol type="1">
<li><span class="math inline">\(E[X] = f(\theta)\)</span> - the expected value is some function of the parameters</li>
<li><span class="math inline">\(E[X] \approx \bar{X}\)</span> - the sample mean should be approximately the population mean</li>
</ol>
<p>Therefore we can substitute these: <span class="math display">\[
\bar{X} \approx f(\theta)
\]</span></p>
<p><span class="math inline">\(\bar{X}\)</span> is a known value calculated from our data. So this gives us an equation where <span class="math inline">\(\theta\)</span> is our unknown variable that we solve for.</p>
<section id="method-of-moments-estimator-for-a-bernoulli-distribution" class="level2">
<h2 class="anchored" data-anchor-id="method-of-moments-estimator-for-a-bernoulli-distribution">4.1. Method of Moments Estimator for a Bernoulli Distribution</h2>
<p>We start with our two basic facts:</p>
<ol type="1">
<li><span class="math inline">\(E[X] \approx \bar{X}\)</span> - our sample mean should be close to our population mean</li>
<li><span class="math inline">\(E[X] = p\)</span> - for a Bernoulli distribution, the population mean is <span class="math inline">\(p\)</span></li>
</ol>
<p>Substituting this, we get an estimate of the parameter <span class="math inline">\(p\)</span> using the method of moments: <span class="math display">\[
p ~= \bar{X}
\]</span></p>
<p>Note the approximately equal sign in the equation above. We don’t know the true population parameter so it isn’t equal, only an approximation.</p>
<p>We can define this estimate as <span class="math inline">\(\hat{p}\)</span>, which is defined as being equal to this estimate.</p>
<p><span class="math display">\[
\hat{p} = \bar{X} = \frac{\sum x_i}{n}
\]</span></p>
</section>
<section id="method-of-moments-estimator-for-a-uniform-distribution" class="level2">
<h2 class="anchored" data-anchor-id="method-of-moments-estimator-for-a-uniform-distribution">4.2. Method of Moments Estimator for a Uniform Distribution</h2>
<p>We start with our two basic facts:</p>
<ol type="1">
<li><span class="math inline">\(E[X] ~= \bar{X}\)</span> - our sample mean should be close to our population mean</li>
<li><span class="math inline">\(E[X] = \frac{\theta}{2}\)</span> - population mean for a uniform distribution</li>
</ol>
<p>So we can substitute this to get our method of moments estimator for <span class="math inline">\(\theta\)</span>: <span class="math display">\[
\begin{aligned}
\frac{\theta}{2} &amp;\approx \bar{X} \\[6pt]
\;\;\Rightarrow\;\; \theta &amp;\approx 2\bar{X} \\[6pt]
\;\;\Rightarrow\;\; \hat{\theta} &amp;= 2\bar{X}
\end{aligned}
\]</span></p>
<p><span class="math display">\[
\boxed{\hat{\theta} = 2\bar{X}}
\]</span></p>
</section>
<section id="method-of-moments-estimator-for-a-normal-distribution" class="level2">
<h2 class="anchored" data-anchor-id="method-of-moments-estimator-for-a-normal-distribution">4.3 Method of Moments Estimator for a Normal Distribution</h2>
<p>We start with our two basic facts:</p>
<ol type="1">
<li><span class="math inline">\(E[X] ~= \bar{X}\)</span> - our sample mean should be close to our population mean</li>
<li><span class="math inline">\(E[X] = \mu\)</span> - population mean for a Normal distribution</li>
</ol>
<p>Therefore, we substitute to get our method of moments estimator for <span class="math inline">\(\mu\)</span>: <span class="math display">\[
\begin{aligned}
\mu &amp;\approx \bar{X} \\[2pt]
\hat{\mu} &amp;= \bar{X}
\end{aligned}
\]</span></p>
</section>
</section>
<section id="unbiased-estimators" class="level1">
<h1>5. Unbiased Estimators</h1>
<section id="background-on-estimators" class="level2">
<h2 class="anchored" data-anchor-id="background-on-estimators">5.0. Background on Estimators</h2>
<section id="distribution-of-estimators" class="level3">
<h3 class="anchored" data-anchor-id="distribution-of-estimators">5.0.1. Distribution of Estimators</h3>
<p>Our data is random. It is the input to our estimator, therefore <strong>our estimate is also a random variable</strong>.</p>
<p>The distribution of an estimator is called a <strong>sampling distribution</strong>.</p>
<p>We want the <em>estimator to be centred on the true value</em>. This is an <strong>unbiased estimator</strong>. In other words, <strong>we want the expected value of the estimate to equal its true value</strong>, i.e.&nbsp;we want</p>
<p><span class="math display">\[
E[\hat{\theta}] = \theta
\]</span></p>
<p>We can define the <strong>bias</strong> as the difference between these two: <span class="math display">\[
Bias = E[\hat{\theta}] - \theta
\]</span></p>
<p>If <span class="math inline">\(Bias = 0\)</span> then we have an <strong>unbiased estimator</strong>.</p>
</section>
</section>
<section id="properties-of-expected-value" class="level2">
<h2 class="anchored" data-anchor-id="properties-of-expected-value">5.0.2. Properties of Expected Value</h2>
<p>The linearity of expectation results below help us prove properties of the estimators.</p>
<p><strong>The law of the unconscious statistician</strong>: <span class="math display">\[
E[cX] = c\,E[X], \quad \text{where $c$ is a constant}
\]</span></p>
<p>This follows from the definition of expected value. For example, consider a discrete distribution: <span class="math display">\[
\begin{aligned}
E[X] &amp;= \sum_{x \in S} x\, P(X=x) \\[2pt]
\Rightarrow E[cX] &amp;= \sum_{x \in S} c x \, P(cX = c x) \\[2pt]
&amp;= \sum_{x \in S} c x \, P(X = x) \quad \text{(since } P(cX = c x) = P(X = x)\text{)} \\[2pt]
&amp;= c \sum_{x \in S} x \, P(X = x) \\[2pt]
&amp;= c E[X]
\end{aligned}
\]</span></p>
<p>The <strong>sum of random variables</strong>: <span class="math display">\[
E[X+Y] = E[X] + E(Y)
\]</span></p>
<p>Or more generally, the expected value of any sum equals the sum of expected values. This holds regardless of independence.</p>
<p><span class="math display">\[
E\Bigg[\sum_{i=1}^{n} X_i\Bigg] = \sum_{i=1}^{n} E[X_i]
\]</span></p>
</section>
<section id="the-bias-of-a-mom-estimator-for-a-bernoulli-distribution" class="level2">
<h2 class="anchored" data-anchor-id="the-bias-of-a-mom-estimator-for-a-bernoulli-distribution">5.1. The Bias of a MoM Estimator for a Bernoulli Distribution</h2>
<p>Recall that our method of moments estimator was: <span class="math display">\[
\hat{p} = \bar{X}
\]</span></p>
<p>We want to know if this equals <span class="math inline">\(E(p)\)</span>. This would make it an unbiased estimator.</p>
<p><span class="math display">\[
\begin{aligned}
E[\hat{p}] &amp;= E\Bigg[\frac{1}{n} \sum_{i=1}^{n} X_i \Bigg] \\[2pt]
&amp;= \frac{1}{n} E\Bigg[\sum_{i=1}^{n} X_i \Bigg] \\[2pt]
&amp;= \frac{1}{n} \sum_{i=1}^{n} E[X_i] \quad \text{(using the linearity of expectation)} \\[2pt]
&amp;= \frac{1}{n} \sum_{i=1}^{n} p \\[2pt]
&amp;= p
\end{aligned}
\]</span></p>
<p>The expected value of our estimator is the population value, therefore it is an unbiased estimator.</p>
</section>
<section id="the-bias-of-a-mom-estimator-for-a-uniform-distribution" class="level2">
<h2 class="anchored" data-anchor-id="the-bias-of-a-mom-estimator-for-a-uniform-distribution">5.2. The Bias of a MoM Estimator for a Uniform Distribution</h2>
<p>Recall that our method of moments estimator is: <span class="math display">\[
\hat{\theta} = 2 \bar{X}
\]</span></p>
<p>So the expected value of the estimate is: <span class="math display">\[
\begin{aligned}
E[\hat{\theta}] &amp;= E\Bigg[ 2 \bar{X} \Bigg] \\[2pt]
&amp;= E\Bigg[ 2 \cdot \frac{1}{n} \sum_{i=1}^{n} X_i \Bigg] \\[2pt]
&amp;= \frac{2}{n} E\Bigg[ \sum_{i=1}^{n} X_i \Bigg] \quad \text{(taking constant outside)} \\[2pt]
&amp;= \frac{2}{n} \sum_{i=1}^{n} E[X_i] \quad \text{(linearity of expectation)} \\[2pt]
&amp;= \frac{2}{n} \sum_{i=1}^{n} \frac{\theta}{2} \quad \text{(substitute } E[X_i] = \theta/2 \text{)} \\[2pt]
&amp;= \frac{2}{n} \cdot n \cdot \frac{\theta}{2} \\[2pt]
&amp;= \theta
\end{aligned}
\]</span></p>
<p>Therefore, this is an unbiased estimator, because <span class="math inline">\(E(\hat{\theta}) = \theta\)</span>.</p>
</section>
<section id="the-bias-of-a-mom-estimator-for-a-normal-distribution" class="level2">
<h2 class="anchored" data-anchor-id="the-bias-of-a-mom-estimator-for-a-normal-distribution">5.3. The Bias of a MoM Estimator for a Normal Distribution</h2>
<p>Recall that: <span class="math display">\[
\hat{\mu} = \bar{X}
\]</span></p>
<p>The expected value of this estimator is: <span class="math display">\[
\begin{aligned}
E[\hat{\mu}] &amp;= E[\bar{X}] \\[2pt]
&amp;= E\Bigg[ \frac{1}{n} \sum_{i=1}^{n} X_i \Bigg] \\[2pt]
&amp;= \frac{1}{n} \sum_{i=1}^{n} E[X_i] \quad \text{(Sum of expectations = expectation of sums)} \\[2pt]
&amp;= \frac{1}{n} \sum_{i=1}^{n} \mu \\[2pt]
&amp;= \frac{1}{n} \cdot n \mu \\[2pt]
&amp;= \mu
\end{aligned}
\]</span></p>
<p>Therefore, this is an unbiased estimator, <span class="math inline">\(E(\hat{\mu}) = \mu\)</span></p>
</section>
</section>
<section id="variance-of-distributions" class="level1">
<h1>6. Variance of Distributions</h1>
<p>Variance is a measure of spread. It is the <strong>average squared distance from the mean</strong>. Squared because if we just took a plain average, the pluses and minuses would always cancel out and give 0.</p>
<p>We <em>could</em> take the magnitude, but the discontinuity at <span class="math inline">\(x=0\)</span> makes the maths less nice, so by convention we usually use squared distances. This is the same argument as L1 vs L2 norm.</p>
<p><span class="math display">\[
\begin{aligned}
\mathrm{Var}(X) &amp;= E\Big[(X - E[X])^2\Big] \\[2pt]
&amp;= E[X^2 - 2 X E[X] + (E[X])^2] \quad \text{(Expanding brackets)} \\[2pt]
&amp;= E[X^2] - 2 E[X] E[X] + (E[X])^2 \quad \text{(Linearity of expectation)} \\[2pt]
&amp;= E[X^2] - (E[X])^2
\end{aligned}
\]</span></p>
<section id="variance-of-a-bernoulli-distribution" class="level2">
<h2 class="anchored" data-anchor-id="variance-of-a-bernoulli-distribution">6.1. Variance of a Bernoulli Distribution</h2>
<p>Remember that in the general case, the variance is defined as:</p>
<p><span class="math display">\[
\mathrm{Var}(X) = E[X^2] - (E[X])^2
\]</span></p>
<p>We already know the mean of a Bernoulli distribution is <span class="math inline">\(E[X] = p\)</span> So we just need to find an expression for <span class="math inline">\(E[X^2]\)</span>.</p>
<p>Recall that for a Bernoulli distribution: <span class="math display">\[
f(x) =
\begin{cases}
p &amp; x = 1 \\[6pt]
1-p &amp; x = 0 \\[6pt]
0 &amp; \text{otherwise}
\end{cases}
\]</span></p>
<p>So <span class="math display">\[
\begin{aligned}
E[X^2] &amp;= \sum_{x} x^2 P(X = x) \\[2pt]
&amp;= 0^2 \cdot (1-p) + 1^2 \cdot p \\[2pt]
&amp;= p
\end{aligned}
\]</span></p>
<p>Substituting into our variance formula: <span class="math display">\[
\begin{aligned}
\mathrm{Var}(X) &amp;= E[X^2] - (E[X])^2 \\[2pt]
&amp;= p - p^2 \\[2pt]
&amp;= p(1-p)
\end{aligned}
\]</span></p>
<p>So the variance of a Bernoulli distribution is <span class="math inline">\(\mathrm{Var}(X)  = p(1-p)\)</span>.</p>
</section>
<section id="variance-of-a-uniform-distribution" class="level2">
<h2 class="anchored" data-anchor-id="variance-of-a-uniform-distribution">6.2. Variance of a Uniform Distribution</h2>
<p>Again we start with that general formula for variance <span class="math display">\[
\mathrm{Var}(X) = E[X^2] - (E[X])^2
\]</span></p>
<p>We know the the expected value for a uniform distribution is <span class="math inline">\(\frac{\theta}{2}\)</span> and the PDF is <span class="math inline">\(f(x) = \frac{1}{\theta}\)</span></p>
<p>So <span class="math inline">\((E[X])^2 = \frac{\theta^2}{4}\)</span>. We just need to calculate <span class="math inline">\(E[X^2]\)</span>.</p>
<p><span class="math display">\[
\begin{aligned}
E[X^2] &amp;= \int_{0}^{\theta} x^2 \cdot \frac{1}{\theta} \, dx \\[2pt]
&amp;= \frac{1}{\theta} \int_{0}^{\theta} x^2 \, dx \quad \text{(Pulling constant outside the integral)} \\[2pt]
&amp;= \frac{1}{\theta} \left[ \frac{x^3}{3} \right]_{0}^{\theta} \\[2pt]
&amp;= \frac{1}{\theta} \cdot \frac{\theta^3}{3} \\[2pt]
&amp;= \frac{\theta^2}{3}
\end{aligned}
\]</span></p>
<p>Hence our variance expression is: <span class="math display">\[
\begin{aligned}
\mathrm{Var}(X) &amp;= E[X^2] - (E[X])^2 \\[2pt]
&amp;= \frac{\theta^2}{3} - \frac{\theta^2}{4} \\[2pt]
&amp;= \frac{\theta^2}{12}
\end{aligned}
\]</span></p>
</section>
<section id="variance-of-a-normal-distribution" class="level2">
<h2 class="anchored" data-anchor-id="variance-of-a-normal-distribution">6.3. Variance of a Normal Distribution</h2>
<p>You can grind through the integrals to get an expression for the variance… we know that it will eventually simplify down to <span class="math inline">\(\mathrm{Var}(X) = \sigma ^2\)</span> by the definition of a Normal distribution.</p>
</section>
</section>
<section id="variance-of-estimators" class="level1">
<h1>7. Variance of Estimators</h1>
<section id="background-on-variance" class="level2">
<h2 class="anchored" data-anchor-id="background-on-variance">7.0. Background on Variance</h2>
<section id="why-the-variance-of-an-estimator-matters" class="level3">
<h3 class="anchored" data-anchor-id="why-the-variance-of-an-estimator-matters">7.0.1. Why the Variance of an Estimator Matters</h3>
<p>We want a lower variance for our estimator, i.e.&nbsp;the value we measure is in a tighter range near the true population mean.</p>
<p>An estimator with an unbiased mean but massive variance wouldn’t be very useful. On average, the survey results will reflect the true results, but any given survey may be wildly off the true population mean.</p>
</section>
<section id="properties-of-variance" class="level3">
<h3 class="anchored" data-anchor-id="properties-of-variance">7.0.2. Properties of Variance</h3>
<p>Similarly to the linearity properties of expected value, there are analogous results for variance.</p>
<p>If we scale our random variable by a constant, the variance squares all distances, so: <span class="math display">\[
\mathrm{Var}(cX) = c^2 \mathrm{Var}(X)
\]</span></p>
<p>For i.i.d. random variables: <span class="math display">\[
\mathrm{Var}\Bigg(\sum_{i=1}^{n} X_i\Bigg) = \sum_{i=1}^{n} \mathrm{Var}(X_i)
\]</span></p>
</section>
</section>
<section id="variance-of-the-mom-estimator-of-a-bernoulli-distribution" class="level2">
<h2 class="anchored" data-anchor-id="variance-of-the-mom-estimator-of-a-bernoulli-distribution">7.1. Variance of the MoM Estimator of a Bernoulli Distribution</h2>
<p>Recall that the MoM estimate is: <span class="math display">\[
\hat{p} = \bar{X} = \frac{1}{n} \sum_{i=1}^{n} x_i
\]</span></p>
<p>We want to find the variance, so rewrite it in a form where we can apply some of our variance rules: <span class="math display">\[
\begin{aligned}
\mathrm{Var}(\hat{p}) &amp;= \mathrm{Var}\Bigg( \frac{1}{n} \sum_{i=1}^{n} X_i \Bigg) \\[2pt]
&amp;= \frac{1}{n^2} \, \mathrm{Var}\Bigg( \sum_{i=1}^{n} X_i \Bigg) \quad \text{(using } \mathrm{Var}(cX) = c^2 \mathrm{Var}(X) \text{)} \\[2pt]
&amp;= \frac{1}{n^2} \sum_{i=1}^{n} \mathrm{Var}(X_i) \quad \text{(variance of sum = sum of variances for i.i.d.)} \\[2pt]
&amp;= \frac{1}{n^2} \sum_{i=1}^{n} p(1-p) \quad \text{(using variance of a Bernoulli variable)} \\[2pt]
&amp;= \frac{1}{n^2} \cdot n \, p(1-p) \\[2pt]
&amp;= \frac{p(1-p)}{n}
\end{aligned}
\]</span></p>
<p>So <span class="math inline">\(\mathrm{Var}(\hat{p}) = \frac{p(1-p)}{n}\)</span></p>
<p>This means the variance always decreases with <span class="math inline">\(n\)</span> more samples. The lowest variance is for <span class="math inline">\(p=0.5\)</span>; if positive or negative cases is very likely (e.g.&nbsp;0.99) then we wouldn’t see much variance in our estimate because it is so certain. In the extreme case of <span class="math inline">\(p=0\)</span> or <span class="math inline">\(p=1\)</span>, the variance is 0.</p>
</section>
<section id="variance-of-the-mom-estimator-of-a-uniform-distribution" class="level2">
<h2 class="anchored" data-anchor-id="variance-of-the-mom-estimator-of-a-uniform-distribution">7.2. Variance of the MoM Estimator of a Uniform Distribution</h2>
<p>Recall the the MoM Estimator is: <span class="math display">\[
\hat{\theta} = 2 \bar{X} = \frac{2}{n} \sum_{i=1}^{n} x_i
\]</span></p>
<p>We want to find an expression for the variance: <span class="math display">\[
\begin{aligned}
\mathrm{Var}(\hat{\theta}) &amp;= \mathrm{Var}\Bigg( 2 \cdot \frac{1}{n} \sum_{i=1}^{n} X_i \Bigg) \\[2pt]
&amp;= \frac{4}{n^2} \, \mathrm{Var}\Bigg( \sum_{i=1}^{n} X_i \Bigg) \quad \text{(using } \mathrm{Var}(cX) = c^2 \mathrm{Var}(X) \text{)} \\[2pt]
&amp;= \frac{4}{n^2} \sum_{i=1}^{n} \mathrm{Var}(X_i) \quad \text{(variance of sum = sum of variances for i.i.d.)} \\[2pt]
&amp;= \frac{4}{n^2} \sum_{i=1}^{n} \frac{\theta^2}{12} \quad \text{(variance of a uniform distribution)} \\[2pt]
&amp;= \frac{4}{n^2} \cdot n \cdot \frac{\theta^2}{12} \\[2pt]
&amp;= \frac{\theta^2}{3n}
\end{aligned}
\]</span></p>
<p>This makes intuitive sense. As the distribution gets wider, the variance gets wider. As the number of samples increases, the variance decreases, i.e.&nbsp;we get a more certain estimate.</p>
</section>
<section id="variance-of-the-mom-estimator-of-a-normal-distribution" class="level2">
<h2 class="anchored" data-anchor-id="variance-of-the-mom-estimator-of-a-normal-distribution">7.3. Variance of the MoM Estimator of a Normal Distribution</h2>
<p>Recall that <span class="math display">\[
\hat{\mu} = \bar{X} = \frac{1}{n} \sum_{i=1}^{n} x_i
\]</span></p>
<p>So the variance is: <span class="math display">\[
\begin{aligned}
\mathrm{Var}(\hat{\mu}) &amp;= \mathrm{Var}\Bigg( \frac{1}{n} \sum_{i=1}^{n} X_i \Bigg) \\[2pt]
&amp;= \frac{1}{n^2} \, \mathrm{Var}\Bigg( \sum_{i=1}^{n} X_i \Bigg) \quad \text{(using } \mathrm{Var}(cX) = c^2 \mathrm{Var}(X) \text{)} \\[2pt]
&amp;= \frac{1}{n^2} \sum_{i=1}^{n} \mathrm{Var}(X_i) \quad \text{(variance of sum = sum of variances for i.i.d.)} \\[2pt]
&amp;= \frac{1}{n^2} \sum_{i=1}^{n} \sigma^2 \quad \text{(variance of a Normal distribution)} \\[2pt]
&amp;= \frac{1}{n^2} \cdot n \, \sigma^2 \\[2pt]
&amp;= \frac{\sigma^2}{n}
\end{aligned}
\]</span></p>
<p>This gives the well-known result that for a normally-distributed random variable <span class="math inline">\(X_i ~ N(\mu, \sigma ^ 2)\)</span>, the mean of N such i.i.d. random variables is: <span class="math display">\[
X_i \sim N(\mu, \frac{\sigma^2}{N})
\]</span></p>
<p>This comes up a lot in hypothesis testing because of the central limit theorem.</p>
</section>
</section>
<section id="maximum-likelihood-estimation" class="level1">
<h1>8. Maximum Likelihood Estimation</h1>
<section id="background-on-mle" class="level2">
<h2 class="anchored" data-anchor-id="background-on-mle">8.0. Background on MLE</h2>
<section id="intuition" class="level3">
<h3 class="anchored" data-anchor-id="intuition">8.0.1 Intuition</h3>
<p>Maximum Likelihood Estimation (MLE) is an alternative approach to finding estimators using the Method of Moments (MOM)approach.</p>
<p>The idea is that we shift our perspective so that rather than thinking of PDFs as a function of the data <span class="math inline">\(x\)</span> where parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> are unknown, we treat it as a function of the parameter <span class="math inline">\(\mu\)</span> where our observed data <span class="math inline">\(x\)</span> is known.</p>
<p>Typically we would think of the PDF for some distribution where <span class="math inline">\(\mu = 2\)</span> and <span class="math inline">\(\sigma = 3\)</span> as: <span class="math display">\[
\begin{aligned}
f(x) &amp;= \frac{1}{\sigma \sqrt{2\pi}}
       \exp\left( -\frac{1}{2} \left( \frac{x-\mu}{\sigma} \right)^2 \right) \\[2pt]
     &amp;= \frac{1}{3 \sqrt{2\pi}}
       \exp\left( -\frac{1}{2} \left( \frac{x-2}{3} \right)^2 \right)
\end{aligned}
\]</span></p>
<p>Instead, say we have observed one data point where <span class="math inline">\(x_1 = 4\)</span>. We treat <span class="math inline">\(\mu\)</span> as the unknown and rewrite this as the <strong>likelihood function</strong>: <span class="math display">\[
L(\mu) = \frac{1}{\sigma \sqrt{2\pi}}
         \exp\left( -\frac{1}{2} \left( \frac{4-\mu}{\sigma} \right)^2 \right)
\]</span></p>
<p>Then to find a good estimate of the parameter, we find the maximum of the likelihood function.</p>
<p>In summary:</p>
<ul>
<li>PDF: Known parameters, unknown data</li>
<li>Likelihood: Unknown parameters, known data.</li>
</ul>
</section>
<section id="joint-pdf" class="level3">
<h3 class="anchored" data-anchor-id="joint-pdf">8.0.2 Joint PDF</h3>
<p>The probability of two things happening in succession is the <strong>joint probability</strong>.</p>
<p>For example, the joint probability of flipping two heads is <span class="math display">\[
P(H \cap H) = 0.5 \cdot 0.5 = 0.25
\]</span></p>
<p>This is true of any number of (independent) events. So if we have observed some data <span class="math inline">\((x_1, x_2, ... x_n) = X\)</span> then we can think about the joint probability distribution of all of these events <span class="math inline">\(P(X)\)</span>.</p>
<p><span class="math display">\[
f(X) = \prod_{i=1}^{n} f(x_i)
\]</span></p>
<p>We assume all of the data (<span class="math inline">\(x_i\)</span>s) are i.i.d., i.e.&nbsp;the same distribution parameters, for the following discussions.</p>
<p>For a Bernoulli distribution, the joint PMF is: <span class="math display">\[
\begin{aligned}
f(X) &amp;= \prod_{i=1}^{n} f(x_i) \\[2pt]
     &amp;= \prod_{i=1}^{n} p^{x_i} (1-p)^{1-x_i} \\[2pt]
     &amp;= p^{x_1} (1-p)^{1-x_1} \cdot p^{x_2} (1-p)^{1-x_2} \cdots p^{x_n} (1-p)^{1-x_n}
        \quad \text{(Expanding out)} \\[2pt]
     &amp;= p^{\sum_{i=1}^{n} x_i} (1-p)^{\sum_{i=1}^{n} (1-x_i)}
        \quad \text{(Collecting terms)} \\[2pt]
     &amp;= p^{\sum_{i=1}^{n} x_i} (1-p)^{n - \sum_{i=1}^{n} x_i}
        \quad \text{(Simplifying)}
\end{aligned}
\]</span></p>
<p>For a Uniform distribution, the joint PDF is: <span class="math display">\[
\begin{aligned}
f(X) &amp;= \prod_{i=1}^{n} f(x_i) \\[2pt]
     &amp;= \prod_{i=1}^{n} \frac{1}{\theta} \\[2pt]
     &amp;= \left(\frac{1}{\theta}\right)^{n}
\end{aligned}
\]</span></p>
<p>For a Normal distribution, the joint PDF is: <span class="math display">\[
\begin{aligned}
f(X) &amp;= \prod_{i=1}^{n} f(x_i) \\[2pt]
     &amp;= \prod_{i=1}^{n} (2 \pi \sigma^2)^{-1/2} \,
        \exp\Bigg(-\frac{(x_i - \mu)^2}{2 \sigma^2}\Bigg) \\[2pt]
     &amp;= (2 \pi \sigma^2)^{-n/2} \,
        \exp\Bigg(-\frac{\sum_{i=1}^{n} (x_i - \mu)^2}{2 \sigma^2}\Bigg)
\end{aligned}
\]</span></p>
<p>We often <strong>call the joint PMF/PDF the “joint distribution”</strong>.</p>
<p>Remember that <strong>the “likelihood function” is just this same formula</strong>, but reframing what we see as the knowns vs unknowns. We treat the parameter as an unknown and the data as a known value.</p>
</section>
<section id="finding-the-mle" class="level3">
<h3 class="anchored" data-anchor-id="finding-the-mle">8.0.3. Finding the MLE</h3>
<p>We differentiate the likelihood function to find the maximum.</p>
<p>Because the likelihood function <span class="math inline">\(L(\theta)\)</span> is a joint distribution, it will often contain lots of products and exponentials. It is therefore often more convenient to work with the <strong>log-likelihood function</strong> <span class="math inline">\(\ell(\theta)\)</span> since logs convert products to sums which are easier to differentiate. We use the natural log to deal with the <span class="math inline">\(e\)</span> values that often crop up. <span class="math display">\[
\ell(\theta) = \log L(\theta)
\]</span></p>
<p>The log function is <strong>monotonic</strong>, so the maximum of <span class="math inline">\(\ell(\theta)\)</span> occurs for the same value of <span class="math inline">\(\theta\)</span> as <span class="math inline">\(L(\theta)\)</span>, i.e.&nbsp;we are still maximising our original likelihood function even if we use the log-likelihood in our calculations for tractability.</p>
<p>To find the maximum of the log-likelihood, we set its derivative to 0 and solve for <span class="math inline">\(\theta\)</span>: <span class="math display">\[
\frac{d \ell(\theta)}{d \theta} = 0
\]</span></p>
<p>The derivative function is sometimes called the <strong>“score function”</strong>.</p>
</section>
</section>
<section id="properties-of-logarithms" class="level2">
<h2 class="anchored" data-anchor-id="properties-of-logarithms">8.0.4 Properties of Logarithms</h2>
<p>Log of products = sum of logs <span class="math display">\[
\log(xy) = \log(x) + \log(y)
\]</span></p>
<p>Log of exponents <span class="math display">\[
\log(a^b) = b \log(a)
\]</span></p>
<p>And by extension <span class="math display">\[
\log(1 /a) = \log(a^{-1}) =  -\log(a)
\]</span></p>
<section id="mean-squared-error" class="level3">
<h3 class="anchored" data-anchor-id="mean-squared-error">8.0.5. Mean Squared Error</h3>
<p>We used bias and variance to evaluate the goodness of our estimators.</p>
<p>We may want to compare a biased estimator vs an unbiased estimator. One method for doing so is to compare the mean squared error (MSE); the average squared distance from the true value.</p>
<p><span class="math display">\[
MSE(\hat{\theta}) = E[(\hat{\theta} - \theta)^2]
\]</span></p>
<p>We can work through some algebra to get the identity: <span class="math display">\[
\mathrm{MSE}(\hat{\theta}) = \mathrm{Bias}(\hat{\theta}) ^2 + \mathrm{Var}(\theta)
\]</span></p>
<p>So for an unbiased estimator, the <span class="math inline">\(MSE = Variance\)</span>.</p>
<p>Biased estimators can still be useful. We want estimators which are close to the mean with small variance. We may have an unbiased estimator which has a large variance. An alternative biased estimator with small bias but much tighter variance could be more useful.</p>
</section>
</section>
<section id="mle-estimator-for-a-bernoulli-distribution" class="level2">
<h2 class="anchored" data-anchor-id="mle-estimator-for-a-bernoulli-distribution">8.1. MLE Estimator for a Bernoulli Distribution</h2>
<p>The general process is:</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart LR

  A(PDF) --&gt; B(Joint PDF) --&gt; C(Likelihood Function) --&gt; D(Log-Likelihood Function) --&gt; E(Maximise)
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>Recall that our PDF is: <span class="math display">\[
f(x_i) = p^{x_i} (1-p)^{1-x_i}
\]</span></p>
<p>And our joint PDF when taking the product of multiple random Bernoulli variables is: <span class="math display">\[
f(X) = p^{\sum x_i} (1-p)^{n - \sum x_i}
\]</span></p>
<p>Our likelihood function is just rewriting this joint PDF as a function of the parameters. Just the same thing. <span class="math display">\[
L(p) = p^{\sum x_i} (1-p)^{n - \sum x_i}
\]</span></p>
<p>Our log-likelihood is then: <span class="math display">\[
\ell(p) = \log L(p) = \sum x_i \log(p) + (n - \sum x_i) log(1-p)
\]</span></p>
<p>Now to find the maximum. <span class="math display">\[
\frac{d\ell}{dp}
= \frac{\sum_{i=1}^{n} x_i}{p} - \frac{n - \sum_{i=1}^{n} x_i}{1-p}
= 0
\]</span></p>
<p>The solution to this is <span class="math inline">\(\hat{p}_{MLE}\)</span>.</p>
$$
<span class="math display">\[\begin{aligned}
&amp;\text{Multiply both sides by } p(1-p) \\[6pt]
&amp;\sum_{i=1}^{n} x_i (1-p) - (n - \sum_{i=1}^{n} x_i)\,p = 0 \\[10pt]

&amp;\text{Expand sums} \\[6pt]
&amp;\sum_{i=1}^{n} x_i - p \sum_{i=1}^{n} x_i - np + p \sum_{i=1}^{n} x_i = 0 \\[10pt]

&amp;\text{Collect \(p\) terms} \\[6pt]
&amp;p \big(- \sum_{i=1}^{n} x_i - n + \sum_{i=1}^{n} x_i \big) + \sum_{i=1}^{n} x_i = 0 \\[6pt]
&amp;\implies \sum_{i=1}^{n} x_i = np \\[6pt]
&amp;\implies \hat{p} = \frac{\sum_{i=1}^{n} x_i}{n} = \bar{X}
\end{aligned}\]</span>
<p>$$</p>
<p>So the MLE estimate of p is the same as the MoM estimate: <span class="math inline">\(\bar{X}\)</span>.</p>
</section>
<section id="mle-estimator-for-a-uniform-distribution" class="level2">
<h2 class="anchored" data-anchor-id="mle-estimator-for-a-uniform-distribution">8.2. MLE Estimator for a Uniform Distribution</h2>
<p>The PDF of each observation (random variable) <span class="math inline">\(x_i\)</span> is: <span class="math display">\[
f(x_i) =
\begin{cases}
\dfrac{1}{\theta}, &amp; 0 \leq x_i \leq \theta \\[6pt]
0, &amp; \text{otherwise}
\end{cases}
\]</span></p>
<p>The joint PDF is then the product of these: <span class="math display">\[
f(X) = \prod_{i=1}^{n} f(x_i) =
\begin{cases}
\dfrac{1}{\theta^n}, &amp; 0 \leq x_i \leq \theta \quad \text{for all } i \\[6pt]
0, &amp; \text{otherwise}
\end{cases}
\]</span></p>
<p>The bound is important as it determines when this function is valid, which we need to consider when maximising the likelihood function. Note that <strong>all</strong> of the <span class="math inline">\(x_i\)</span> values need to be in the bound, otherwise the product, i.e.&nbsp;the entire joint PDF, is 0.</p>
The likelihood function is just reframing the joint PDF as a function of <span class="math inline">\(\theta%.\)</span>$ L() =
<span class="math display">\[\begin{cases}
\dfrac{1}{\theta^n}, &amp; 0 \leq x_i \leq \theta \quad \text{for all } i \\[6pt]
0, &amp; \text{otherwise}
\end{cases}\]</span>
<p>$$</p>
<p>We often take the log at this point to make the differentiation more tractable, but in this case we don’t need to.</p>
<p>We can plot <span class="math inline">\(L\)</span>, or differentiate it, to realise that the value of <span class="math inline">\(\theta\)</span> asymptotically approaches infinity as <span class="math inline">\(\theta\)</span> approaches 0. <span class="math display">\[
\frac{dL}{d\theta} = -n \theta^{-n-1}
\]</span></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="likelihood_uniform.png" class="img-fluid figure-img"></p>
<figcaption>Likelihood function for a uniform distribution where the maximum value observed is 3.5</figcaption>
</figure>
</div>
<p>So is <span class="math inline">\(\theta_{MLE} = 0\)</span>? Naively we would think so, but remember the bounds of the PDF; <span class="math inline">\(\theta\)</span> has to be at least as high as the observations we have seen for the PDF to be valid. So the maximum of the observed <span class="math inline">\(x_i\)</span> values is a lower bound. We can write this as <span class="math inline">\(x_{(n)}\)</span>, where the brackets indicate this is the nth element in the sorted list. The smallest allowable value of <span class="math inline">\(\theta\)</span> maximises this function.</p>
<p>Therefore <span class="math inline">\(\hat{\theta}_{\mathrm{MLE}} = \max_{i} x_i\)</span>.</p>
<p>Note that this is different to our MoM estimate, which said that <span class="math inline">\(\theta_{MOM} = 2 \bar{X}\)</span>.</p>
<p>MLE bases the estimate of the upper bound parameter <span class="math inline">\(\theta\)</span> on the maximum value we have seen. MoM says to take the average we have observed, that should be somewhere near the middle, so we double it to get an estimate of the upper bound parameter <span class="math inline">\(\theta\)</span>.</p>
<p>We know that <span class="math inline">\(\theta_{MOM}\)</span> was unbiased, so <span class="math inline">\(\theta_{MLE}\)</span> must be biased.</p>
</section>
<section id="mle-estimator-for-a-normal-distribution" class="level2">
<h2 class="anchored" data-anchor-id="mle-estimator-for-a-normal-distribution">8.3. MLE Estimator for a Normal Distribution</h2>
<p>Recall that for a Normal distribution, the joint PDF is: <span class="math display">\[
f(X) = (2 \pi \sigma^2)^{-n/2} e^{-\sum_{i=1}^{n} \frac{(x-\mu)^2}{2 \sigma^2}}
\]</span></p>
<p>So the likelihood is just reframing this as a function of the parameter <span class="math inline">\(\mu\)</span>: <span class="math display">\[
L(\mu) = (2 \pi \sigma^2)^{-n/2} e^{-\sum_{i=1}^{n} \frac{(x-\mu)^2}{2 \sigma^2}}
\]</span></p>
<p>Since we are taking logs the constant term at the front becomes an addition, and then the derivative of a constant is 0. So we can ignore it. The log-likelihood function is then: <span class="math display">\[
\ell(\mu) = \frac{-1}{2 \sigma^2} \sum_{i=1}^{n} (x-\mu)^2
\]</span></p>
<p>To find the maximum, we take the derivative and set it to 0. <span class="math display">\[
\begin{aligned}
\frac{d l}{d \mu} &amp;= -\frac{1}{2\sigma^2} \sum_{i=1}^{n} 2(x_i - \mu) = 0 \\
\implies \sum_{i=1}^{n} (x_i - \mu) &amp;= 0 \\
\implies \sum_{i=1}^{n} x_i - n \mu &amp;= 0 \\
\implies \hat{\mu} &amp;= \frac{\sum_{i=1}^{n} x_i}{n} \\
&amp;= \boxed{\bar{X}}
\end{aligned}
\]</span></p>
<p>So this is the same as the MoM estimator, <span class="math inline">\(\hat{\mu} = \bar{X}\)</span>.</p>
</section>
</section>
<section id="fisher-information-and-cramer-rao-lower-bound-crlb" class="level1">
<h1>9. Fisher Information and Cramer Rao Lower Bound (CRLB)</h1>
<p>CRLB gives a proven lower bound for the variance of an estimator for certain distributions (in the exponential family). The starting point for this is to consider the information contained in one observation about our parameter <span class="math inline">\(\theta\)</span>. This is encompassed in the <strong>Fisher Information</strong>, defined as: <span class="math display">\[
I_1(\theta) = -\mathbb{E}[\ell''(\theta)]
\]</span></p>
<p>For <span class="math inline">\(n\)</span> observations, this scales as: <span class="math display">\[
I_n(\theta) = n I_1(\theta)
\]</span></p>
<p>The intuition behind this is to think about the distribution for an estimator. For a very informative estimator, it is a tight distribution around the true value. So the curvature of the likelihood is high; it increases and then decreases rapidly either side of the true value. So the second derivative of the likelihood function tells us how tight the estimator is around the true value.</p>
<p>The <strong>Cramer Rao Lower Bound (CRLB)</strong> then tells us that the lower bound for the variance is: <span class="math display">\[
\operatorname{Var}(\hat{\theta}) \ge \frac{1}{I_n(\theta)}
\]</span></p>
<p>So if we can show that this bound is tight for a particular estimator and that the estimator is unbiased, the estimator is <strong>efficient</strong>.</p>
<section id="crlb-for-a-bernoulli-distribution" class="level2">
<h2 class="anchored" data-anchor-id="crlb-for-a-bernoulli-distribution">9.1. CRLB for a Bernoulli Distribution</h2>
<p>Recall that in general for any distribution: <span class="math display">\[
\operatorname{Var}(\hat{\theta}) \ge \frac{1}{\,n \, I_1(\theta)\,}, \qquad
I_1(\theta) = -\mathbb{E}[\ell''(\theta)]
\]</span></p>
<p>For a Bernoulli distribution: <span class="math display">\[
\begin{aligned}
f(x) &amp;= p^x (1-p)^x \\
L(p) &amp;= p^x (1-p)^x \\
\ell(p) &amp;= x \log(p) + (1-x) \log(1-p) \\
\frac{d\ell}{dp} &amp;= \frac{x}{p} - \frac{1-x}{1-p}
\end{aligned}
\]</span></p>
<p>The Fisher Information is then found for a single observation by taking the second derivative and finding its expected value. <span class="math display">\[
\frac{d^2 \ell}{dp^2} = \ell''(p) = -\frac{x}{p^2} - \frac{1-x}{(1-p)^2}
\]</span></p>
<p>The expectation over x, using <span class="math inline">\(\mathbb{E}[x] = p\)</span> for a Bernoulli: <span class="math display">\[
\begin{aligned}
\mathbb{E}[\ell''(p)] &amp;= \mathbb{E}\Bigg[-\frac{x}{p^2} - \frac{1-x}{(1-p)^2}\Bigg] \\
&amp;= -\frac{p}{p^2} - \frac{1-p}{(1-p)^2} \\
&amp;= -\frac{1}{p} - \frac{1}{1-p} \\
&amp;= -\frac{1}{\,p(1-p)\,}
\end{aligned}
\]</span></p>
<p>The Fisher information is the negative of this, i.e.&nbsp;<span class="math inline">\(I_1(p) = -E[l''(p)] = \frac{1}{p(1-p)}\)</span></p>
<p>The CRLB is the reciprocal, i.e.&nbsp;<span class="math inline">\(\text{CRLB} = \frac{1}{\,n I_1(p)\,} = \frac{p(1-p)}{n}\)</span></p>
<p>This is the variance we found for both our MoM and MLE estimators, therefore these estimators are efficient.</p>
</section>
<section id="crlb-for-a-uniform-distribution" class="level2">
<h2 class="anchored" data-anchor-id="crlb-for-a-uniform-distribution">9.2. CRLB for a Uniform Distribution</h2>
<p>The definition of Fisher Information only applies when the support (i.e.&nbsp;the sample space of the distribution) does not depend on the value of <span class="math inline">\(\theta\)</span>. This condition is breached for the uniform distribution.</p>
<p>The uniform distribution is not a member of the exponential family.</p>
</section>
<section id="crlb-for-a-normal-distribution" class="level2">
<h2 class="anchored" data-anchor-id="crlb-for-a-normal-distribution">9.3. CRLB for a Normal Distribution</h2>
<p>As in the general case, we need to find the log-likelihood function, then calculate its second derivative.</p>
<p><span class="math display">\[
\begin{aligned}
\ell(\mu) &amp;= \log\left(\frac{1}{\sqrt{2 \pi \sigma^2}}\right) - \frac{1}{2 \sigma^2} (x-\mu)^2 \\
\frac{d\ell}{d\mu} &amp;= \frac{x-\mu}{\sigma^2} \\
\ell''(\mu) &amp;= -\frac{1}{\sigma^2}
\end{aligned}
\]</span></p>
<p>The Fisher Information for a single observation is therefore: <span class="math display">\[
\begin{aligned}
I_1(\mu) &amp;= -\mathbb{E}\Big[-\frac{1}{\sigma^2}\Big] \\
         &amp;= \frac{1}{\sigma^2} \quad \text{Since none of this expression is random}
\end{aligned}
\]</span></p>
<p>The CRLB is therefore <span class="math display">\[
\operatorname{Var}(\mu) \ge \frac{\sigma^2}{n}
\]</span></p>
<p>So our MOM and MLE estimators are both efficient.</p>
</section>
<section id="efficiency" class="level2">
<h2 class="anchored" data-anchor-id="efficiency">9.4. Efficiency</h2>
<p>We can define the <strong>efficiency</strong> of an estimator as the ratio of its variance and its optimal variance given by the CRLB: <span class="math display">\[
\text{Efficiency}(\hat{\theta}) = \frac{\text{CRLB}}{\operatorname{Var}(\hat{\theta})}
\]</span></p>
<p>We can also compare two different estimators by taking the ratio of their variances. This is the <strong>relative efficiency</strong>. For example, comparing the MOM and MLE estimators: <span class="math display">\[
\text{Relative Efficiency} = \frac{\operatorname{Var}(\hat{\theta}_{\text{MOM}})}{\operatorname{Var}(\hat{\theta}_{\text{MLE}})}
\]</span></p>
<p>This is typically a function of <span class="math inline">\(n\)</span>. We can analyse the **relative asymptotic efficiency by observing the behaviour as <span class="math inline">\(n \to \infty\)</span>.</p>
</section>
</section>
<section id="central-limit-theorem" class="level1">
<h1>10. Central Limit Theorem</h1>
<p>This relates to the <strong>asymptotic distribution</strong> of our estimators.</p>
<p>We previously discussed that the estimator of a random variable is itself a random variable, which meant we could analyse its expected value and variance. We can go a step further; rather than just analyse these summary statistics of the estimator, let’s analyse the whole distribution.</p>
<p>The <em>asymptotic</em> behaviour means the distribution as our sample size <span class="math inline">\(n \to \infty\)</span>. This obviously can never occur in practice, so as a rule of thumb when <span class="math inline">\(n \ge 30\)</span> the CLT is approximately true.</p>
<p>Once we know the distribution of the parameter, we can reason about the probability that the parameter takes a certain value. This is the idea behind hypothesis testing.</p>
<p>The CLT states that for a large enough sample size, the distribution of the parameter is approximately normal. <strong>It applies when the estimator is a sum of average of random variables</strong>. This is true of a lot of estimators. One notable exception is the MLE estimate for a uniform distribution, as this was the <em>maximum</em> of the data points, so the CLT does not apply.</p>
<p>For most distributions, the rule of thumb for CLT to apply is <span class="math inline">\(n \ge 30\)</span>. For a Bernoulli distribution, the condition is <span class="math inline">\(np \ge 10, \quad n(1-p) \ge 10\)</span>. For a Normal distribution, the parameter is <strong>exactly</strong> Normal regardless of sample size, so we don’t need CLT.</p>
<section id="clt-for-a-bernoulli-distribution" class="level2">
<h2 class="anchored" data-anchor-id="clt-for-a-bernoulli-distribution">10.1. CLT for a Bernoulli Distribution</h2>
<p>Recall that both MOM and MLE estimators for a Bernoulli distribution were <span class="math inline">\(\hat{p} = \bar{X}\)</span>.</p>
<p>As this is an <em>average</em> of data points, CLT applies. A general rule of thumb is that CLT applies when the expected number of successes <span class="math inline">\(np \ge 10\)</span> and the expected number of failures <span class="math inline">\(n(1-p) \ge 10\)</span>.</p>
<p>We’ve already established the mean and variance of the estimator <span class="math inline">\(\hat{p}\)</span> in earlier sections: <span class="math display">\[
\begin{aligned}
\mathbb{E}[\hat{p}] &amp;= p \\
\operatorname{Var}[\hat{p}] &amp;= \frac{p(1-p)}{n}
\end{aligned}
\]</span></p>
<p>So the value of the estimator is a Normally distributed random variable with those parameters. We now know the entire distribution and can do interesting things with it, like hypothesis testing.</p>
<p>The CLT approximation is helpful because the Normal distribution can often be easier to compute than the original distribution, so it reduces the computing power (or historically, the number of calculations required by hand), while still giving a good approximation to the true value if we had used the actual distribution.</p>
</section>
<section id="clt-for-a-uniform-distribution" class="level2">
<h2 class="anchored" data-anchor-id="clt-for-a-uniform-distribution">10.2. CLT for a Uniform Distribution</h2>
<p>We only consider the MOM estimate not the MLE estimate, because the MLE estimate was a <strong>maximum</strong> of values, meaning the CLT does not apply.</p>
<p>We can reason about the asymptotic distribution of the MOM estimate for a uniform distribution if our sample size is large enough <span class="math inline">\(n \ge 30\)</span>.</p>
<p>We’ve already established the mean and variance of the estimator <span class="math inline">\(\theta\)</span> in earlier sections: <span class="math display">\[
\begin{aligned}
\mathbb{E}[\hat{\theta}] &amp;= \theta \\
\operatorname{Var}[\hat{p}] &amp;= \frac{\theta^2}{3n}
\end{aligned}
\]</span></p>
<p>So again, our estimate is a Normally-distributed random variable with these parameters.</p>
</section>
<section id="clt-for-a-normal-distribution" class="level2">
<h2 class="anchored" data-anchor-id="clt-for-a-normal-distribution">10.3. CLT for a Normal Distribution</h2>
<p>When we add Gaussians we get another Gaussian, so the actual (rather than asymptotic) distribution of our estimator for a Normal distribution is <strong>exactly</strong> Normal.</p>
<p>We don’t need any specific sample size for this to be true; it is true for <span class="math inline">\(n=1,2,3,...\)</span>, we don’t need our usual rule of <span class="math inline">\(n \ge 30\)</span>.</p>
<p>We’ve already established the mean and variance of the estimator <span class="math inline">\(\mu\)</span> in earlier sections: <span class="math display">\[
\begin{aligned}
\mathbb{E}[\hat{\mu}] &amp;= \mu \\
\operatorname{Var}[\hat{\mu}] &amp;= \frac{\sigma^2}{n}
\end{aligned}
\]</span></p>
<p>So again, our estimate is a Normally-distributed random variable with these parameters.</p>
<p>Note that we don’t need a minimum sample size <span class="math inline">\(n\)</span> for the CLT to apply, but a large <span class="math inline">\(n\)</span> reduces the variance of our estimate, thus reducing our uncertainty.</p>
</section>
<section id="consistency" class="level2">
<h2 class="anchored" data-anchor-id="consistency">10.4. Consistency</h2>
<p>Consistency is another measure of asymptotic behaviour that says that as the number of samples approaches infinity, the estimator converges to the true value of the parameter.</p>
<p>Mathematically <span class="math display">\[
P\big(| \hat{\theta} - \theta | &lt; \epsilon \big) \to 1 \quad \text{as } n \to \infty,
\quad \text{for } \epsilon \text{ arbitrarily small}
\]</span></p>
<p>Unbiased estimators are <strong>consistent</strong> if their variance approaches 0 as <span class="math inline">\(n\)</span> approaches infinity.</p>
</section>
</section>
<section id="confidence-intervals" class="level1">
<h1>11. Confidence Intervals</h1>
<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">11.0. Background</h2>
<p>When we’ve looked at estimators in previous sections, we’ve focused on <strong>point estimates</strong>.</p>
<p>But we know that these are random variables, so we would prefer to make <strong>interval estimates</strong>. Then we can make statements like “we are 95% sure that the mean is between 1.5 to 2.5”.</p>
<p>We can use the results from previous sections for this. Recall that we were able to reason about the distribution of our estimate with CLT. The <em>estimate</em> <span class="math inline">\(\hat{\theta}\)</span> is centred on the true value, and using the <span class="math inline">\(2 \, \sigma(\hat{\theta})\)</span> value, there is a 95% probability that the estimate lies within 2 (sample) standard deviations of the true mean. Mathematically: <span class="math display">\[
P\big(\theta - 2\sigma(\hat{\theta}) \le \hat{\theta} \le \theta + 2\sigma(\hat{\theta})\big) = 0.95
\]</span></p>
<p>Note that we have the population parameter value <span class="math inline">\(\theta\)</span> in the left and right terms and the <em>sample</em> value <span class="math inline">\(\hat{\theta}\)</span> in the middle term.</p>
<p>We want to shift our perspective when going from probability to statistics. In statistics/the real world, we <em>don’t know</em> the TRUE parameter value, but we can gather data so that our ESTIMATED parameter value is known. So we want to make confidence interval statements about the true value, i.e.&nbsp;we want the population value $$ in the middle of the inequality and estimated values <span class="math inline">\(\hat{\theta}\)</span> as the bounds.</p>
<p>We can do this with a bit of algebra. Starting with the equation above, subtract <span class="math inline">\(\theta\)</span> and <span class="math inline">\(\hat{\theta}\)</span> from each term inside the probability. <span class="math display">\[
P\big(-\hat{\theta} - 2\sigma(\hat{\theta}) \le -\theta \le -\hat{\theta} + 2\sigma(\hat{\theta})\big) = 0.95
\]</span></p>
<p>Now multiply all terms by -1 and note that it flips the sign of the inequality when we multiply by a negative value. <span class="math display">\[
P\big(\hat{\theta} - 2\sigma(\hat{\theta}) \le \theta \le \hat{\theta} + 2\sigma(\hat{\theta})\big) = 0.95
\]</span></p>
<p>This was our goal: we now have bounds for the <strong>population</strong> value <span class="math inline">\(\theta\)</span> in terms of the estimated values <span class="math inline">\(\hat{\theta}\)</span> which are known values that we can calculate from the data.</p>
<p>We have <strong>inverted/pivoted</strong> the roles of <span class="math inline">\(\theta\)</span> and <span class="math inline">\(\hat{\theta}\)</span>.</p>
<p>What does it mean to have a 95% confidence interval? Say we have a process:</p>
<ol type="1">
<li>Collect data</li>
<li>Calculate the confidence interval</li>
<li>Theoretically repeat this process over and over</li>
</ol>
<p>So we are doing 20 coin flips. We get a confidence interval <span class="math inline">\([0.4, 0.45]\)</span></p>
<p>Then we do 20 more flips and get a confidence interval <span class="math inline">\([0.48,0.53]\)</span></p>
<p>Then a third time we do 20 flips and get a confidence interval <span class="math inline">\([0.46, 0.55]\)</span></p>
<p>And we keep going… We get a list of confidence intervals: <span class="math display">\[
[0.4, 0.45]
[0.48,0.53]
[0.46, 0.55]
[0.49, 0.56]
[0.42, 0.50]
[0.45, 0.55]
...
\]</span></p>
<p>Our 95% confidence value means <strong>“95% of these hypothetical intervals calculated will contain the true parameter value <span class="math inline">\(\theta\)</span>”</strong>.</p>
<section id="the-pivot-from-probability-to-statistics" class="level3">
<h3 class="anchored" data-anchor-id="the-pivot-from-probability-to-statistics">11.0.1 The Pivot from Probability to Statistics</h3>
<p>The pivot from probability to statistics was mentioned in the previous section but is crucial so bears emphasising.</p>
<p>In probability, we can make statements like “there is 95% probability that <span class="math inline">\(\hat{\theta} \text{ is in } \theta \pm 2 \, \sigma(\theta)\)</span>”.</p>
<p>In statistics, thanks to our pivot (algebraic manipulation of the inequality), we make statements like “we are 95% confidence that <span class="math inline">\(\theta\)</span> is in the interval <span class="math inline">\(\hat{\theta} \pm 2 \times \text{standard error}(\hat{\theta})\)</span>”.</p>
</section>
<section id="some-useful-terms" class="level3">
<h3 class="anchored" data-anchor-id="some-useful-terms">11.0.2. Some Useful Terms</h3>
<p>The sample standard deviation, e.g.&nbsp;<span class="math inline">\(\frac{\hat{\sigma}}{\sqrt{n}}\)</span> is called the <strong>standard error</strong>.</p>
<p>The <strong>margin of error</strong> for a particular confidence interval statement is the standard error multiplied by the number of standard deviations we use. For example, for a 95% confidence interval <span class="math display">\[
\text{Margin of error} = 2 \times \text{Standard error}
\]</span></p>
</section>
</section>
<section id="bernoulli-confidence-intervals" class="level2">
<h2 class="anchored" data-anchor-id="bernoulli-confidence-intervals">11.1 Bernoulli Confidence Intervals</h2>
<p>We’ve already established the mean and standard error of our MOM/MLE estimators (they were the same for Bernoulli).</p>
<p>So our 95% confidence interval is: <span class="math display">\[
\hat{p} \pm 2 \, \sqrt{\frac{\hat{p} (1-\hat{p})}{n}}
\]</span></p>
</section>
<section id="uniform-distribution-confidence-intervals" class="level2">
<h2 class="anchored" data-anchor-id="uniform-distribution-confidence-intervals">11.2. Uniform Distribution Confidence Intervals</h2>
<p>We skip the MLE uniform estimator since it’s a maximum of values, therefore CLT does not apply and we cannot reason in the same way.</p>
<p>For our MOM estimator, the 95% confidence interval is: <span class="math display">\[
\hat{\theta} \pm \frac{2 \, \theta}{\sqrt{3n}}
\]</span></p>
</section>
<section id="normal-distribution-confidence-intervals" class="level2">
<h2 class="anchored" data-anchor-id="normal-distribution-confidence-intervals">11.3. Normal Distribution Confidence Intervals</h2>
<p>For our MOM estimator, the 95% confidence interval is: <span class="math display">\[
\hat{\mu} \pm \frac{2 \, \sigma}{\sqrt{n}}
\]</span></p>
</section>
</section>
<section id="references" class="level1">
<h1>References</h1>
<ul>
<li><a href="https://www.udemy.com/course/mathstat">“Mathematical Statistics for Data Science” Udemy course</a></li>
</ul>


</section>

<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Back to top</a></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>